# -*- coding: utf-8 -*-
"""
Agentic AI System - ê³„ì¸µì  ê²°ê³¼ ê´€ë¦¬ì
ë¶€ì„œ â†’ ì§ë¬´ â†’ ì§ê¸‰ â†’ ì§ì› ê³„ì¸µ êµ¬ì¡°ë¡œ ê²°ê³¼ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê´€ë¦¬
"""

import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import logging
import base64
import io

logger = logging.getLogger(__name__)

class HierarchicalResultManager:
    """ê³„ì¸µì  ì—ì´ì „í‹± AI ì‹œìŠ¤í…œ ê²°ê³¼ ê´€ë¦¬ì"""
    
    def __init__(self, base_output_dir: str = "results"):
        self.base_output_dir = Path(base_output_dir)
        self.setup_directory_structure()
        
    def setup_directory_structure(self):
        """ê°„ì†Œí™”ëœ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        # ê¸°ë³¸ êµ¬ì¡° (ê°„ì†Œí™”)
        directories = [
            "global_reports",      # ì „ì²´ ì¢…í•© ë³´ê³ ì„œ
            "models",             # ì €ì¥ëœ ëª¨ë¸ë“¤
            "temp"                # ì„ì‹œ íŒŒì¼ë“¤
        ]
        
        for directory in directories:
            (self.base_output_dir / directory).mkdir(parents=True, exist_ok=True)
            
        logger.info(f"ê°„ì†Œí™”ëœ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ: {self.base_output_dir}")
    
    def _sanitize_folder_name(self, name: str) -> str:
        """í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë¬¸ìì—´ ì •ë¦¬"""
        if not name:
            return "Unknown"
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
        import re
        sanitized = re.sub(r'[<>:"/\\|?*]', '', str(name))
        sanitized = re.sub(r'\s+', '_', sanitized)
        sanitized = sanitized.strip('_')
        
        return sanitized if sanitized else "Unknown"
    
    def _get_hierarchical_path(self, department: str, job_role: str, position: str, employee_id: str) -> Path:
        """ê°„ì†Œí™”ëœ ê²½ë¡œ ìƒì„±: ë¶€ì„œ/ì§ì›"""
        
        dept_clean = self._sanitize_folder_name(department)
        
        # ê°„ì†Œí™”ëœ êµ¬ì¡°: results/ë¶€ì„œëª…/employee_ID
        hierarchical_path = (
            self.base_output_dir / 
            dept_clean / 
            f"employee_{employee_id}"
        )
        
        return hierarchical_path
    
    def _update_department_index(self, department: str, employee_id: str, job_role: str, position: str):
        """ë¶€ì„œë³„ ì§ì› ì¸ë±ìŠ¤ íŒŒì¼ ì—…ë°ì´íŠ¸"""
        try:
            dept_clean = self._sanitize_folder_name(department)
            index_file = self.base_output_dir / dept_clean / "department_index.json"
            
            # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ
            if index_file.exists():
                with open(index_file, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
            else:
                index_data = {
                    "department": department,
                    "created_at": datetime.now().isoformat(),
                    "structure_version": "simplified_v1.0",
                    "employees": {},
                    "job_roles": {},
                    "positions": {},
                    "statistics": {
                        "total_employees": 0,
                        "job_role_count": {},
                        "position_count": {}
                    }
                }
            
            # ì§ì› ì •ë³´ ì—…ë°ì´íŠ¸
            index_data["employees"][employee_id] = {
                "job_role": job_role,
                "position": position,
                "last_updated": datetime.now().isoformat(),
                "folder_path": f"employee_{employee_id}"
            }
            
            # Job Role ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            if job_role not in index_data["job_roles"]:
                index_data["job_roles"][job_role] = []
            if employee_id not in index_data["job_roles"][job_role]:
                index_data["job_roles"][job_role].append(employee_id)
            
            # Position ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            if position not in index_data["positions"]:
                index_data["positions"][position] = []
            if employee_id not in index_data["positions"][position]:
                index_data["positions"][position].append(employee_id)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            index_data["statistics"]["total_employees"] = len(index_data["employees"])
            index_data["statistics"]["job_role_count"] = {
                role: len(employees) for role, employees in index_data["job_roles"].items()
            }
            index_data["statistics"]["position_count"] = {
                pos: len(employees) for pos, employees in index_data["positions"].items()
            }
            index_data["last_updated"] = datetime.now().isoformat()
            
            # ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ë¶€ì„œ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {department} - {employee_id}")
            
        except Exception as e:
            logger.error(f"ë¶€ì„œ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_employees_by_job_role(self, department: str, job_role: str) -> List[str]:
        """íŠ¹ì • ë¶€ì„œì˜ íŠ¹ì • ì§ë¬´ ì§ì› ëª©ë¡ ì¡°íšŒ"""
        try:
            dept_clean = self._sanitize_folder_name(department)
            index_file = self.base_output_dir / dept_clean / "department_index.json"
            
            if not index_file.exists():
                return []
            
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            return index_data.get("job_roles", {}).get(job_role, [])
        except Exception as e:
            logger.error(f"ì§ë¬´ë³„ ì§ì› ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_employees_by_position(self, department: str, position: str) -> List[str]:
        """íŠ¹ì • ë¶€ì„œì˜ íŠ¹ì • ì§ê¸‰ ì§ì› ëª©ë¡ ì¡°íšŒ"""
        try:
            dept_clean = self._sanitize_folder_name(department)
            index_file = self.base_output_dir / dept_clean / "department_index.json"
            
            if not index_file.exists():
                return []
            
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            return index_data.get("positions", {}).get(position, [])
        except Exception as e:
            logger.error(f"ì§ê¸‰ë³„ ì§ì› ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_department_statistics(self, department: str) -> Dict:
        """ë¶€ì„œ í†µê³„ ì¡°íšŒ"""
        try:
            dept_clean = self._sanitize_folder_name(department)
            index_file = self.base_output_dir / dept_clean / "department_index.json"
            
            if not index_file.exists():
                return {}
            
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            return index_data.get("statistics", {})
        except Exception as e:
            logger.error(f"ë¶€ì„œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def save_employee_result(self, employee_id: str, employee_data: Dict, 
                           worker_results: Dict, department: str = None, 
                           job_role: str = None, position: str = None):
        """ê°œë³„ ì§ì› ê²°ê³¼ë¥¼ ê³„ì¸µì  êµ¬ì¡°ë¡œ ì €ì¥"""
        
        # ì§ì› ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ
        dept = department or employee_data.get('Department', 'Unknown')
        role = job_role or employee_data.get('JobRole', 'Unknown') 
        pos = position or employee_data.get('JobLevel', employee_data.get('Position', 'Unknown'))
        
        # ê³„ì¸µì  ê²½ë¡œ ìƒì„±
        employee_dir = self._get_hierarchical_path(dept, role, pos, employee_id)
        employee_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ì§ì› {employee_id} ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {employee_dir}")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ê¸°ë³¸ ì •ë³´ ì €ì¥ (ê°„ì†Œí™”ëœ êµ¬ì¡°ì—ì„œë„ ìƒì„¸ ì •ë³´ ë³´ì¡´)
        employee_info = {
            "employee_id": employee_id,
            "department": dept,
            "job_role": role,
            "position": pos,
            "analysis_timestamp": timestamp,
            "folder_structure": {
                "simplified_path": f"{dept}/employee_{employee_id}",
                "original_hierarchy": {
                    "department": dept,
                    "job_role": role,
                    "position": pos
                }
            },
            "metadata": {
                "structure_version": "simplified_v1.0",
                "migration_date": timestamp,
                "data_preserved": True
            },
            "employee_data": employee_data
        }
        
        with open(employee_dir / "employee_info.json", 'w', encoding='utf-8') as f:
            json.dump(employee_info, f, ensure_ascii=False, indent=2)
        
        # ë¶€ì„œë³„ ì¸ë±ìŠ¤ íŒŒì¼ ì—…ë°ì´íŠ¸
        self._update_department_index(dept, employee_id, role, pos)
        
        # 2. ê° ì›Œì»¤ ê²°ê³¼ ì €ì¥
        results_summary = {
            'employee_id': employee_id,
            'department': dept,
            'job_role': role,
            'position': pos,
            'analysis_timestamp': timestamp
        }
        
        # ì‹œê°í™” í´ë” ìƒì„±
        viz_dir = employee_dir / "visualizations"
        viz_dir.mkdir(exist_ok=True)
        
        # Structura ê²°ê³¼
        if 'structura' in worker_results:
            structura_result = worker_results['structura']
            results_summary.update({
                'structura_attrition_prob': structura_result.get('attrition_probability', 0),
                'structura_prediction': structura_result.get('prediction', 'Unknown'),
                'structura_confidence': structura_result.get('confidence', 0)
            })
            
            with open(employee_dir / "structura_result.json", 'w', encoding='utf-8') as f:
                json.dump(structura_result, f, ensure_ascii=False, indent=2)
            
            # XAI ì‹œê°í™” ì €ì¥
            self._save_structura_visualizations(employee_id, structura_result, viz_dir)
        
        # Cognita ê²°ê³¼
        if 'cognita' in worker_results:
            cognita_result = worker_results['cognita']
            results_summary.update({
                'cognita_risk_score': cognita_result.get('overall_risk_score', 0),
                'cognita_risk_category': cognita_result.get('risk_category', 'Unknown'),
                'cognita_network_centrality': cognita_result.get('network_centrality', 0)
            })
            
            with open(employee_dir / "cognita_result.json", 'w', encoding='utf-8') as f:
                json.dump(cognita_result, f, ensure_ascii=False, indent=2)
        
        # Chronos ê²°ê³¼
        if 'chronos' in worker_results:
            chronos_result = worker_results['chronos']
            results_summary.update({
                'chronos_prediction': chronos_result.get('prediction', 'Unknown'),
                'chronos_probability': chronos_result.get('probability', 0),
                'chronos_trend': chronos_result.get('trend', 'Stable')
            })
            
            with open(employee_dir / "chronos_result.json", 'w', encoding='utf-8') as f:
                json.dump(chronos_result, f, ensure_ascii=False, indent=2)
            
            # Attention ì‹œê°í™” ì €ì¥
            self._save_chronos_visualizations(employee_id, chronos_result, viz_dir)
        
        # Sentio ê²°ê³¼
        if 'sentio' in worker_results:
            sentio_result = worker_results['sentio']
            results_summary.update({
                'sentio_risk_score': sentio_result.get('psychological_risk_score', 0),
                'sentio_risk_level': sentio_result.get('risk_level', 'MEDIUM'),
                'sentio_job_demands': sentio_result.get('jd_r_indicators', {}).get('job_demands_score', 0),
                'sentio_resources_deficiency': sentio_result.get('jd_r_indicators', {}).get('job_resources_deficiency_score', 0)
            })
            
            with open(employee_dir / "sentio_result.json", 'w', encoding='utf-8') as f:
                json.dump(sentio_result, f, ensure_ascii=False, indent=2)
        
        # 3. í†µí•© ê²°ê³¼ ìš”ì•½ CSV ì €ì¥
        summary_df = pd.DataFrame([results_summary])
        summary_df.to_csv(employee_dir / "analysis_summary.csv", index=False, encoding='utf-8-sig')
        
        # 4. ì¢…í•© ë ˆí¬íŠ¸ ìƒì„± (Sentio í™œìš©)
        if len(worker_results) >= 2:  # ìµœì†Œ 2ê°œ ì›Œì»¤ ê²°ê³¼ê°€ ìˆì„ ë•Œ
            comprehensive_report = self._generate_comprehensive_report(employee_id, worker_results)
            with open(employee_dir / "comprehensive_report.json", 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ì§ì› {employee_id} ê²°ê³¼ê°€ {employee_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ê³„ì¸µë³„ ìš”ì•½ ì—…ë°ì´íŠ¸
        self._update_hierarchical_summaries(dept, role, pos, employee_id, results_summary)
        
        return str(employee_dir)
    
    def _generate_comprehensive_report(self, employee_id: str, worker_results: Dict) -> Dict:
        """ê°œë³„ ì§ì›ì˜ ì¢…í•© ë ˆí¬íŠ¸ ìƒì„± (Sentio í™œìš©)"""
        
        # ì¢…í•© ìœ„í—˜ë„ ê³„ì‚° (ê° ì›Œì»¤ì˜ ì ìˆ˜ë¥¼ ê°€ì¤‘í‰ê· )
        risk_scores = []
        
        # Structura: í‡´ì§ í™•ë¥ 
        if 'structura' in worker_results and worker_results['structura'].get('attrition_probability'):
            risk_scores.append(('structura', worker_results['structura']['attrition_probability'], 0.3))
        
        # Cognita: ì „ì²´ ìœ„í—˜ë„
        if 'cognita' in worker_results and worker_results['cognita'].get('overall_risk_score'):
            risk_scores.append(('cognita', worker_results['cognita']['overall_risk_score'], 0.25))
        
        # Chronos: ì˜ˆì¸¡ í™•ë¥ 
        if 'chronos' in worker_results and worker_results['chronos'].get('probability'):
            risk_scores.append(('chronos', worker_results['chronos']['probability'], 0.2))
        
        # Sentio: ì‹¬ë¦¬ì  ìœ„í—˜ ì ìˆ˜
        if 'sentio' in worker_results and worker_results['sentio'].get('psychological_risk_score'):
            risk_scores.append(('sentio', worker_results['sentio']['psychological_risk_score'], 0.25))
        
        # ê°€ì¤‘í‰ê·  ê³„ì‚°
        if risk_scores:
            weighted_sum = sum(score * weight for _, score, weight in risk_scores)
            total_weight = sum(weight for _, _, weight in risk_scores)
            comprehensive_risk_score = weighted_sum / total_weight
        else:
            comprehensive_risk_score = 0.5
        
        # ì¢…í•© ìœ„í—˜ ìˆ˜ì¤€ ê²°ì •
        if comprehensive_risk_score >= 0.7:
            overall_risk_level = "HIGH"
            risk_color = "ğŸ”´"
        elif comprehensive_risk_score >= 0.4:
            overall_risk_level = "MEDIUM" 
            risk_color = "ğŸŸ¡"
        else:
            overall_risk_level = "LOW"
            risk_color = "ğŸŸ¢"
        
        # ì¢…í•© ë ˆí¬íŠ¸ êµ¬ì„±
        comprehensive_report = {
            'employee_id': employee_id,
            'analysis_timestamp': datetime.now().isoformat(),
            'comprehensive_assessment': {
                'overall_risk_score': round(comprehensive_risk_score, 3),
                'overall_risk_level': overall_risk_level,
                'risk_indicator': risk_color,
                'confidence_level': 'HIGH' if len(risk_scores) >= 3 else 'MEDIUM'
            },
            'worker_contributions': {
                worker: {'score': score, 'weight': weight} 
                for worker, score, weight in risk_scores
            },
            'rule_based_interpretation': self._generate_rule_based_interpretation(
                employee_id, comprehensive_risk_score, overall_risk_level, worker_results
            )
        }
        
        return comprehensive_report
    
    def _generate_rule_based_interpretation(self, employee_id: str, risk_score: float, 
                                          risk_level: str, worker_results: Dict) -> str:
        """ê·œì¹™ ê¸°ë°˜ ì¢…í•© í•´ì„ ìƒì„±"""
        
        interpretation = f"""
=== ì§ì› {employee_id} ì¢…í•© ë¶„ì„ ê²°ê³¼ ===

ì „ì²´ ìœ„í—˜ë„: {risk_level} ({risk_score:.3f}/1.0)

ğŸ” ì›Œì»¤ë³„ ìƒì„¸ ë¶„ì„:
"""
        
        # ê° ì›Œì»¤ ê²°ê³¼ ìš”ì•½
        if 'structura' in worker_results:
            structura = worker_results['structura']
            prob = structura.get('attrition_probability', 0)
            pred = structura.get('prediction', 'Unknown')
            interpretation += f"ğŸ“ˆ êµ¬ì¡°ì  ë¶„ì„ (Structura): í‡´ì§ í™•ë¥  {prob:.1%}, ì˜ˆì¸¡ '{pred}'\n"
        
        if 'cognita' in worker_results:
            cognita = worker_results['cognita']
            score = cognita.get('overall_risk_score', 0)
            category = cognita.get('risk_category', 'Unknown')
            interpretation += f"ğŸŒ ê´€ê³„ì  ë¶„ì„ (Cognita): ìœ„í—˜ë„ {score:.3f}, ì¹´í…Œê³ ë¦¬ '{category}'\n"
        
        if 'chronos' in worker_results:
            chronos = worker_results['chronos']
            prob = chronos.get('probability', 0)
            trend = chronos.get('trend', 'Stable')
            interpretation += f"â° ì‹œê³„ì—´ ë¶„ì„ (Chronos): í™•ë¥  {prob:.1%}, íŠ¸ë Œë“œ '{trend}'\n"
        
        if 'sentio' in worker_results:
            sentio = worker_results['sentio']
            psych_score = sentio.get('psychological_risk_score', 0)
            level = sentio.get('risk_level', 'MEDIUM')
            interpretation += f"ğŸ§  ì‹¬ë¦¬ì  ë¶„ì„ (Sentio): ìœ„í—˜ë„ {psych_score:.3f}, ìˆ˜ì¤€ '{level}'\n"
        
        interpretation += f"\nğŸ’¡ ê¶Œì¥ ì¡°ì¹˜:\n"
        
        # ìœ„í—˜ ìˆ˜ì¤€ë³„ ê¶Œì¥ì‚¬í•­
        if risk_level == 'HIGH':
            interpretation += """ğŸš¨ ì¦‰ì‹œ ê°œì… í•„ìš”:
- ìƒê¸‰ìì™€ì˜ ê¸´ê¸‰ ë©´ë‹´ ì‹¤ì‹œ
- ì—…ë¬´ ì¡°ì • ë° ì§€ì› ë°©ì•ˆ ê²€í† 
- ì •ê¸°ì  ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•"""
        elif risk_level == 'MEDIUM':
            interpretation += """âš ï¸ ì˜ˆë°©ì  ê´€ë¦¬ í•„ìš”:
- ì •ê¸°ì  ìƒë‹´ ë° í”¼ë“œë°± ì œê³µ
- ì—…ë¬´ í™˜ê²½ ê°œì„  ê²€í† 
- ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ í”„ë¡œê·¸ë¨ ì°¸ì—¬ ê¶Œì¥"""
        else:
            interpretation += """âœ… í˜„ì¬ ìƒíƒœ ìœ ì§€:
- ì •ê¸°ì  ëª¨ë‹ˆí„°ë§ ì§€ì†
- ê¸ì •ì  ìš”ì†Œ ê°•í™”
- ì„±ì¥ ê¸°íšŒ ì œê³µ ê²€í† """
        
        return interpretation.strip()
    
    def _update_hierarchical_summaries(self, department: str, job_role: str, position: str, 
                                     employee_id: str, summary_data: Dict):
        """ê³„ì¸µë³„ ìš”ì•½ íŒŒì¼ë“¤ ì—…ë°ì´íŠ¸"""
        
        # 1. ì§ê¸‰ë³„ ìš”ì•½ ì—…ë°ì´íŠ¸
        self._update_position_summary(department, job_role, position, summary_data)
        
        # 2. ì§ë¬´ë³„ ìš”ì•½ ì—…ë°ì´íŠ¸  
        self._update_job_role_summary(department, job_role, summary_data)
        
        # 3. ë¶€ì„œë³„ ìš”ì•½ ì—…ë°ì´íŠ¸
        self._update_department_summary(department, summary_data)
        
        # 4. ì „ì²´ ìš”ì•½ ì—…ë°ì´íŠ¸
        self._update_global_summary(summary_data)
    
    def _update_position_summary(self, department: str, job_role: str, position: str, summary_data: Dict):
        """ì§ê¸‰ë³„ ìš”ì•½ CSV ì—…ë°ì´íŠ¸"""
        dept_clean = self._sanitize_folder_name(department)
        role_clean = self._sanitize_folder_name(job_role)
        pos_clean = self._sanitize_folder_name(position)
        
        position_dir = (
            self.base_output_dir / "departments" / dept_clean / 
            "job_roles" / role_clean / "positions" / pos_clean
        )
        position_dir.mkdir(parents=True, exist_ok=True)
        
        summary_path = position_dir / "position_summary.csv"
        self._append_to_csv(summary_path, summary_data)
        
        logger.debug(f"ì§ê¸‰ '{position}' ìš”ì•½ ì—…ë°ì´íŠ¸: {summary_path}")
    
    def _update_job_role_summary(self, department: str, job_role: str, summary_data: Dict):
        """ì§ë¬´ë³„ ìš”ì•½ CSV ì—…ë°ì´íŠ¸"""
        dept_clean = self._sanitize_folder_name(department)
        role_clean = self._sanitize_folder_name(job_role)
        
        job_role_dir = (
            self.base_output_dir / "departments" / dept_clean / "job_roles" / role_clean
        )
        job_role_dir.mkdir(parents=True, exist_ok=True)
        
        summary_path = job_role_dir / "job_role_summary.csv"
        self._append_to_csv(summary_path, summary_data)
        
        logger.debug(f"ì§ë¬´ '{job_role}' ìš”ì•½ ì—…ë°ì´íŠ¸: {summary_path}")
    
    def _update_department_summary(self, department: str, summary_data: Dict):
        """ë¶€ì„œë³„ ìš”ì•½ CSV ì—…ë°ì´íŠ¸"""
        dept_clean = self._sanitize_folder_name(department)
        
        dept_dir = self.base_output_dir / "departments" / dept_clean
        dept_dir.mkdir(parents=True, exist_ok=True)
        
        summary_path = dept_dir / "department_summary.csv"
        self._append_to_csv(summary_path, summary_data)
        
        logger.debug(f"ë¶€ì„œ '{department}' ìš”ì•½ ì—…ë°ì´íŠ¸: {summary_path}")
    
    def _update_global_summary(self, summary_data: Dict):
        """ì „ì²´ ìš”ì•½ CSV ì—…ë°ì´íŠ¸"""
        global_dir = self.base_output_dir / "global_reports"
        global_dir.mkdir(parents=True, exist_ok=True)
        
        summary_path = global_dir / "global_summary.csv"
        self._append_to_csv(summary_path, summary_data)
        
        logger.debug(f"ì „ì²´ ìš”ì•½ ì—…ë°ì´íŠ¸: {summary_path}")
    
    def _append_to_csv(self, csv_path: Path, data: Dict):
        """CSV íŒŒì¼ì— ë°ì´í„° ì¶”ê°€"""
        df_new = pd.DataFrame([data])
        
        if csv_path.exists():
            df_existing = pd.read_csv(csv_path, encoding='utf-8-sig')
            df_combined = pd.concat([df_existing, df_new], ignore_index=True)
        else:
            df_combined = df_new
        
        df_combined.to_csv(csv_path, index=False, encoding='utf-8-sig')
        logger.debug(f"CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ: {csv_path} ({len(df_combined)}í–‰)")
    
    def _save_structura_visualizations(self, employee_id: str, structura_result: Dict, viz_dir: Path):
        """Structura XAI ì‹œê°í™” ì €ì¥"""
        try:
            # Feature Importance
            if 'feature_importance_plot' in structura_result:
                self._save_base64_image(
                    structura_result['feature_importance_plot'], 
                    viz_dir / "structura_feature_importance.png"
                )
            
            # SHAP Analysis
            if 'shap_plot' in structura_result:
                self._save_base64_image(
                    structura_result['shap_plot'], 
                    viz_dir / "structura_shap_analysis.png"
                )
            
            # LIME Explanation
            if 'lime_plot' in structura_result:
                self._save_base64_image(
                    structura_result['lime_plot'], 
                    viz_dir / "structura_lime_explanation.png"
                )
                
            logger.debug(f"Structura ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {viz_dir}")
            
        except Exception as e:
            logger.error(f"Structura ì‹œê°í™” ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_chronos_visualizations(self, employee_id: str, chronos_result: Dict, viz_dir: Path):
        """Chronos Attention ì‹œê°í™” ì €ì¥"""
        try:
            # Temporal Attention
            if 'temporal_attention_plot' in chronos_result:
                self._save_base64_image(
                    chronos_result['temporal_attention_plot'], 
                    viz_dir / "chronos_temporal_attention.png"
                )
            
            # Feature Attention
            if 'feature_attention_plot' in chronos_result:
                self._save_base64_image(
                    chronos_result['feature_attention_plot'], 
                    viz_dir / "chronos_feature_attention.png"
                )
                
            logger.debug(f"Chronos ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {viz_dir}")
            
        except Exception as e:
            logger.error(f"Chronos ì‹œê°í™” ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_base64_image(self, base64_string: str, output_path: Path):
        """Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # "data:image/png;base64," ì ‘ë‘ì‚¬ ì œê±°
            if "," in base64_string:
                base64_string = base64_string.split(",")[1]
            
            img_data = base64.b64decode(base64_string)
            with open(output_path, 'wb') as f:
                f.write(img_data)
                
            logger.debug(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_path}")
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨ ({output_path}): {e}")
    
    def get_employee_results(self, employee_id: str, department: str = None, 
                           job_role: str = None, position: str = None) -> Dict:
        """íŠ¹ì • ì§ì›ì˜ ëª¨ë“  ê²°ê³¼ ì¡°íšŒ (ê³„ì¸µì  ê²½ë¡œ)"""
        
        if all([department, job_role, position]):
            # ì •í™•í•œ ê²½ë¡œë¡œ ì¡°íšŒ
            employee_dir = self._get_hierarchical_path(department, job_role, position, employee_id)
        else:
            # ì „ì²´ ê²€ìƒ‰ (ëŠë¦¼)
            employee_dir = self._find_employee_directory(employee_id)
        
        if not employee_dir or not employee_dir.exists():
            return {"error": f"ì§ì› {employee_id}ì˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        results = {"employee_id": employee_id, "path": str(employee_dir), "files": {}}
        
        # ê° ì›Œì»¤ ê²°ê³¼ íŒŒì¼ ì½ê¸°
        for worker in ['structura', 'cognita', 'chronos', 'sentio']:
            result_file = employee_dir / f"{worker}_result.json"
            if result_file.exists():
                with open(result_file, 'r', encoding='utf-8') as f:
                    results['files'][f'{worker}_result'] = json.load(f)
        
        # ì¢…í•© ë ˆí¬íŠ¸
        comprehensive_file = employee_dir / "comprehensive_report.json"
        if comprehensive_file.exists():
            with open(comprehensive_file, 'r', encoding='utf-8') as f:
                results['files']['comprehensive_report'] = json.load(f)
        
        # ì‹œê°í™” íŒŒì¼ ëª©ë¡
        viz_dir = employee_dir / "visualizations"
        if viz_dir.exists():
            results['files']['visualizations'] = [f.name for f in viz_dir.iterdir() if f.is_file()]
        
        return results
    
    def _find_employee_directory(self, employee_id: str) -> Optional[Path]:
        """ì§ì› ë””ë ‰í† ë¦¬ ì „ì²´ ê²€ìƒ‰"""
        for dept_dir in (self.base_output_dir / "departments").iterdir():
            if dept_dir.is_dir():
                for role_dir in (dept_dir / "job_roles").iterdir():
                    if role_dir.is_dir():
                        for pos_dir in (role_dir / "positions").iterdir():
                            if pos_dir.is_dir():
                                emp_dir = pos_dir / "employees" / f"employee_{employee_id}"
                                if emp_dir.exists():
                                    return emp_dir
        return None
    
    def get_hierarchy_summary(self) -> Dict:
        """ì „ì²´ ê³„ì¸µ êµ¬ì¡° ìš”ì•½ ì¡°íšŒ"""
        summary = {
            "total_departments": 0,
            "total_job_roles": 0,
            "total_positions": 0,
            "total_employees": 0,
            "hierarchy": {}
        }
        
        departments_dir = self.base_output_dir / "departments"
        if not departments_dir.exists():
            return summary
        
        for dept_dir in departments_dir.iterdir():
            if dept_dir.is_dir():
                dept_name = dept_dir.name
                summary["total_departments"] += 1
                summary["hierarchy"][dept_name] = {"job_roles": {}}
                
                job_roles_dir = dept_dir / "job_roles"
                if job_roles_dir.exists():
                    for role_dir in job_roles_dir.iterdir():
                        if role_dir.is_dir():
                            role_name = role_dir.name
                            summary["total_job_roles"] += 1
                            summary["hierarchy"][dept_name]["job_roles"][role_name] = {"positions": {}}
                            
                            positions_dir = role_dir / "positions"
                            if positions_dir.exists():
                                for pos_dir in positions_dir.iterdir():
                                    if pos_dir.is_dir():
                                        pos_name = pos_dir.name
                                        summary["total_positions"] += 1
                                        
                                        employees_dir = pos_dir / "employees"
                                        employee_count = 0
                                        if employees_dir.exists():
                                            employee_count = len([d for d in employees_dir.iterdir() if d.is_dir()])
                                        
                                        summary["hierarchy"][dept_name]["job_roles"][role_name]["positions"][pos_name] = {
                                            "employee_count": employee_count
                                        }
                                        summary["total_employees"] += employee_count
        
        return summary

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
hierarchical_result_manager = HierarchicalResultManager()
