"""
Supervisor Flask ë°±ì—”ë“œ
ìŠˆí¼ë°”ì´ì € ì—ì´ì „íŠ¸ì˜ REST API ì„œë²„
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import asyncio
import logging
import traceback
from datetime import datetime
from typing import Dict, Any, Optional
import os
import json

from langchain_openai import ChatOpenAI

from .langgraph_workflow import SupervisorWorkflow
from .worker_integrator import DEFAULT_WORKER_CONFIGS
from .agent_state import AgentState

# Flask ì•± ìƒì„±
app = Flask(__name__)
CORS(app)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì „ì—­ ë³€ìˆ˜
supervisor_workflow: Optional[SupervisorWorkflow] = None
active_sessions: Dict[str, Dict[str, Any]] = {}


def initialize_supervisor():
    """ìŠˆí¼ë°”ì´ì € ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”"""
    global supervisor_workflow
    
    try:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            logger.warning("OPENAI_API_KEY not found in environment variables")
        
        # LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(
            model="gpt-4-turbo-preview",
            temperature=0.1,
            api_key=openai_api_key
        )
        
        # ì›Œì»¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
        worker_configs = DEFAULT_WORKER_CONFIGS.copy()
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì›Œì»¤ URL ì˜¤ë²„ë¼ì´ë“œ
        for worker_name in worker_configs.keys():
            env_key = f"{worker_name.upper()}_URL"
            env_url = os.getenv(env_key)
            if env_url:
                worker_configs[worker_name]["base_url"] = env_url
                logger.info(f"Using {env_key}: {env_url}")
        
        # ìŠˆí¼ë°”ì´ì € ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
        supervisor_workflow = SupervisorWorkflow(
            worker_configs=worker_configs,
            llm=llm,
            max_retry_count=int(os.getenv("MAX_RETRY_COUNT", "3")),
            timeout_minutes=int(os.getenv("TIMEOUT_MINUTES", "30"))
        )
        
        logger.info("Supervisor workflow initialized successfully")
        
    except Exception as e:
        logger.error(f"Failed to initialize supervisor workflow: {e}")
        logger.error(traceback.format_exc())
        raise


@app.route('/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        status = {
            'status': 'healthy',
            'service': 'Supervisor',
            'timestamp': datetime.now().isoformat(),
            'version': '1.0.0'
        }
        
        if supervisor_workflow:
            status['workflow_initialized'] = True
            status['available_workers'] = supervisor_workflow.get_available_workers()
        else:
            status['workflow_initialized'] = False
            status['error'] = 'Workflow not initialized'
        
        return jsonify(status)
        
    except Exception as e:
        logger.error(f"Health check error: {e}")
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/analyze_employee', methods=['POST'])
def analyze_employee():
    """ì§ì› ë¶„ì„ ìš”ì²­"""
    try:
        if not supervisor_workflow:
            return jsonify({
                'success': False,
                'error': 'Supervisor workflow not initialized'
            }), 500
        
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'No JSON data provided'
            }), 400
        
        employee_id = data.get('employee_id')
        if not employee_id:
            return jsonify({
                'success': False,
                'error': 'employee_id is required'
            }), 400
        
        session_id = data.get('session_id')
        
        logger.info(f"Starting analysis for employee {employee_id}")
        
        # ë¹„ë™ê¸° ë¶„ì„ ì‹¤í–‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            result = loop.run_until_complete(
                supervisor_workflow.analyze_employee(employee_id, session_id)
            )
            
            # í™œì„± ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥
            if result.get('session_id'):
                active_sessions[result['session_id']] = {
                    'employee_id': employee_id,
                    'result': result,
                    'created_at': datetime.now().isoformat(),
                    'status': 'completed' if result['success'] else 'failed'
                }
            
            logger.info(f"Analysis completed for employee {employee_id}")
            return jsonify(result)
            
        finally:
            loop.close()
        
    except Exception as e:
        logger.error(f"Analysis error for employee {data.get('employee_id', 'unknown')}: {e}")
        logger.error(traceback.format_exc())
        
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/get_workflow_status/<session_id>', methods=['GET'])
def get_workflow_status(session_id: str):
    """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì¡°íšŒ"""
    try:
        if not supervisor_workflow:
            return jsonify({
                'success': False,
                'error': 'Supervisor workflow not initialized'
            }), 500
        
        # ë¹„ë™ê¸° ìƒíƒœ ì¡°íšŒ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            status = loop.run_until_complete(
                supervisor_workflow.get_workflow_status(session_id)
            )
            
            return jsonify({
                'success': True,
                'session_id': session_id,
                'status': status
            })
            
        finally:
            loop.close()
        
    except Exception as e:
        logger.error(f"Status query error for session {session_id}: {e}")
        
        return jsonify({
            'success': False,
            'error': str(e),
            'session_id': session_id
        }), 500


@app.route('/list_active_sessions', methods=['GET'])
def list_active_sessions():
    """í™œì„± ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
    try:
        sessions = []
        for session_id, session_data in active_sessions.items():
            sessions.append({
                'session_id': session_id,
                'employee_id': session_data['employee_id'],
                'status': session_data['status'],
                'created_at': session_data['created_at']
            })
        
        return jsonify({
            'success': True,
            'active_sessions': sessions,
            'total_sessions': len(sessions)
        })
        
    except Exception as e:
        logger.error(f"List sessions error: {e}")
        
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/get_session_result/<session_id>', methods=['GET'])
def get_session_result(session_id: str):
    """ì„¸ì…˜ ê²°ê³¼ ì¡°íšŒ"""
    try:
        if session_id not in active_sessions:
            return jsonify({
                'success': False,
                'error': 'Session not found'
            }), 404
        
        session_data = active_sessions[session_id]
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'employee_id': session_data['employee_id'],
            'status': session_data['status'],
            'created_at': session_data['created_at'],
            'result': session_data['result']
        })
        
    except Exception as e:
        logger.error(f"Get session result error for {session_id}: {e}")
        
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/worker_health_check', methods=['GET'])
def worker_health_check():
    """ì›Œì»¤ ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸"""
    try:
        if not supervisor_workflow:
            return jsonify({
                'success': False,
                'error': 'Supervisor workflow not initialized'
            }), 500
        
        # ë¹„ë™ê¸° í—¬ìŠ¤ì²´í¬
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            health_status = loop.run_until_complete(
                supervisor_workflow.worker_integrator.health_check_all()
            )
            
            # ê²°ê³¼ ë³€í™˜
            worker_status = {}
            for worker_type, is_healthy in health_status.items():
                worker_status[worker_type.value] = {
                    'healthy': is_healthy,
                    'status': 'online' if is_healthy else 'offline'
                }
            
            total_workers = len(worker_status)
            healthy_workers = sum(1 for status in worker_status.values() if status['healthy'])
            
            return jsonify({
                'success': True,
                'worker_status': worker_status,
                'summary': {
                    'total_workers': total_workers,
                    'healthy_workers': healthy_workers,
                    'unhealthy_workers': total_workers - healthy_workers,
                    'health_rate': healthy_workers / total_workers if total_workers > 0 else 0
                },
                'timestamp': datetime.now().isoformat()
            })
            
        finally:
            loop.close()
        
    except Exception as e:
        logger.error(f"Worker health check error: {e}")
        
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/system_info', methods=['GET'])
def system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
    try:
        info = {
            'service': 'Supervisor',
            'version': '1.0.0',
            'timestamp': datetime.now().isoformat(),
            'workflow_initialized': supervisor_workflow is not None,
            'active_sessions_count': len(active_sessions),
            'environment': {
                'max_retry_count': os.getenv('MAX_RETRY_COUNT', '3'),
                'timeout_minutes': os.getenv('TIMEOUT_MINUTES', '30'),
                'openai_api_key_configured': bool(os.getenv('OPENAI_API_KEY'))
            }
        }
        
        if supervisor_workflow:
            info['available_workers'] = supervisor_workflow.get_available_workers()
            info['worker_configs'] = supervisor_workflow.worker_integrator.get_worker_status()
        
        return jsonify(info)
        
    except Exception as e:
        logger.error(f"System info error: {e}")
        
        return jsonify({
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/clear_sessions', methods=['POST'])
def clear_sessions():
    """ì„¸ì…˜ ì •ë¦¬"""
    try:
        data = request.get_json() or {}
        older_than_hours = data.get('older_than_hours', 24)
        
        current_time = datetime.now()
        cleared_count = 0
        
        sessions_to_remove = []
        for session_id, session_data in active_sessions.items():
            created_at = datetime.fromisoformat(session_data['created_at'])
            age_hours = (current_time - created_at).total_seconds() / 3600
            
            if age_hours > older_than_hours:
                sessions_to_remove.append(session_id)
        
        for session_id in sessions_to_remove:
            del active_sessions[session_id]
            cleared_count += 1
        
        return jsonify({
            'success': True,
            'cleared_sessions': cleared_count,
            'remaining_sessions': len(active_sessions),
            'older_than_hours': older_than_hours
        })
        
    except Exception as e:
        logger.error(f"Clear sessions error: {e}")
        
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/batch_analyze', methods=['POST'])
def batch_analyze():
    """ë°°ì¹˜ ë¶„ì„ (ì—¬ëŸ¬ ì§ì› ë™ì‹œ ë¶„ì„)"""
    try:
        if not supervisor_workflow:
            return jsonify({
                'success': False,
                'error': 'Supervisor workflow not initialized'
            }), 500
        
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'No JSON data provided'
            }), 400
        
        employee_ids = data.get('employee_ids', [])
        if not employee_ids or not isinstance(employee_ids, list):
            return jsonify({
                'success': False,
                'error': 'employee_ids list is required'
            }), 400
        
        max_batch_size = int(os.getenv('MAX_BATCH_SIZE', '10'))
        if len(employee_ids) > max_batch_size:
            return jsonify({
                'success': False,
                'error': f'Batch size exceeds maximum ({max_batch_size})'
            }), 400
        
        logger.info(f"Starting batch analysis for {len(employee_ids)} employees")
        
        # ë¹„ë™ê¸° ë°°ì¹˜ ë¶„ì„
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
            tasks = []
            for employee_id in employee_ids:
                task = supervisor_workflow.analyze_employee(employee_id)
                tasks.append(task)
            
            results = loop.run_until_complete(asyncio.gather(*tasks, return_exceptions=True))
            
            # ê²°ê³¼ ì •ë¦¬
            batch_results = []
            successful_count = 0
            
            for i, result in enumerate(results):
                employee_id = employee_ids[i]
                
                if isinstance(result, Exception):
                    batch_results.append({
                        'employee_id': employee_id,
                        'success': False,
                        'error': str(result)
                    })
                else:
                    batch_results.append(result)
                    if result.get('success'):
                        successful_count += 1
                    
                    # ì„¸ì…˜ ì €ì¥
                    if result.get('session_id'):
                        active_sessions[result['session_id']] = {
                            'employee_id': employee_id,
                            'result': result,
                            'created_at': datetime.now().isoformat(),
                            'status': 'completed' if result['success'] else 'failed'
                        }
            
            logger.info(f"Batch analysis completed: {successful_count}/{len(employee_ids)} successful")
            
            return jsonify({
                'success': True,
                'batch_results': batch_results,
                'summary': {
                    'total_employees': len(employee_ids),
                    'successful_analyses': successful_count,
                    'failed_analyses': len(employee_ids) - successful_count,
                    'success_rate': successful_count / len(employee_ids)
                }
            })
            
        finally:
            loop.close()
        
    except Exception as e:
        logger.error(f"Batch analysis error: {e}")
        logger.error(traceback.format_exc())
        
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ì—ëŸ¬ í•¸ë“¤ëŸ¬
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'Endpoint not found',
        'timestamp': datetime.now().isoformat()
    }), 404


@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {error}")
    return jsonify({
        'success': False,
        'error': 'Internal server error',
        'timestamp': datetime.now().isoformat()
    }), 500


# ì•± ì´ˆê¸°í™”
def create_app():
    """Flask ì•± ìƒì„± ë° ì´ˆê¸°í™”"""
    try:
        initialize_supervisor()
        logger.info("Supervisor Flask backend initialized successfully")
        return app
    except Exception as e:
        logger.error(f"Failed to create app: {e}")
        raise


if __name__ == '__main__':
    try:
        # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        port = int(os.getenv('SUPERVISOR_PORT', '5006'))
        debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
        
        # ì•± ì´ˆê¸°í™”
        app = create_app()
        
        print(f"ğŸš€ Supervisor Flask ì„œë²„ ì‹œì‘")
        print(f"ğŸ“¡ ì„œë²„ ì£¼ì†Œ: http://localhost:{port}")
        print(f"ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ: {debug}")
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:")
        print("  GET  /health - ì„œë²„ ìƒíƒœ í™•ì¸")
        print("  POST /analyze_employee - ì§ì› ë¶„ì„")
        print("  GET  /get_workflow_status/<session_id> - ì›Œí¬í”Œë¡œìš° ìƒíƒœ")
        print("  GET  /list_active_sessions - í™œì„± ì„¸ì…˜ ëª©ë¡")
        print("  GET  /worker_health_check - ì›Œì»¤ ìƒíƒœ í™•ì¸")
        print("  POST /batch_analyze - ë°°ì¹˜ ë¶„ì„")
        print("  GET  /system_info - ì‹œìŠ¤í…œ ì •ë³´")
        
        # ì„œë²„ ì‹¤í–‰
        app.run(host='0.0.0.0', port=port, debug=debug)
        
    except Exception as e:
        logger.error(f"Failed to start server: {e}")
        logger.error(traceback.format_exc())
        exit(1)
