"""
ê°€ì¤‘ì¹˜ ìµœì í™” ëª¨ë“ˆ
Weight_setting.ipynb ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„
"""

import pandas as pd
import numpy as np
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score
from sklearn.metrics import confusion_matrix
from scipy.optimize import minimize
from itertools import product
from typing import Dict, Tuple, List, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# Bayesian Optimization ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    from skopt import gp_minimize
    from skopt.space import Real
    from skopt.utils import use_named_args
    SKOPT_AVAILABLE = True
except ImportError:
    SKOPT_AVAILABLE = False


class WeightOptimizer:
    """
    ê°€ì¤‘ì¹˜ ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤
    """
    
    def __init__(self):
        self.optimal_weights = {}
        self.optimal_threshold = 0.5
        self.optimization_results = {}
        
    def calculate_weighted_score(self, data: pd.DataFrame, weights: Dict[str, float]) -> np.ndarray:
        """
        ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
        
        Parameters:
        data: DataFrame, ì˜ˆì¸¡ ë°ì´í„°
        weights: dict, ê° ì»¬ëŸ¼ë³„ ê°€ì¤‘ì¹˜
        
        Returns:
        weighted_score: array, 0~1 ì‚¬ì´ì˜ ê°€ì¤‘ ì ìˆ˜
        """
        weighted_score = np.zeros(len(data))
        
        for col, weight in weights.items():
            if col in data.columns:
                weighted_score += data[col] * weight
        
        return weighted_score
    
    def evaluate_weighted_score(self, y_true: np.ndarray, weighted_score: np.ndarray, 
                              threshold: float = 0.5) -> Dict[str, float]:
        """
        ê°€ì¤‘ ì ìˆ˜ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜
        
        Parameters:
        y_true: ì‹¤ì œ ë¼ë²¨
        weighted_score: ê°€ì¤‘ ì ìˆ˜
        threshold: ë¶„ë¥˜ ì„ê³„ê°’
        
        Returns:
        metrics: dict, ì„±ëŠ¥ ì§€í‘œë“¤
        """
        y_pred = (weighted_score >= threshold).astype(int)
        
        # ëª¨ë“  ì˜ˆì¸¡ì´ ê°™ì€ í´ë˜ìŠ¤ì¸ ê²½ìš° ì²˜ë¦¬
        if len(np.unique(y_pred)) == 1:
            if y_pred[0] == 1:  # ëª¨ë‘ 1ë¡œ ì˜ˆì¸¡
                precision = np.mean(y_true)
                recall = 1.0
            else:  # ëª¨ë‘ 0ìœ¼ë¡œ ì˜ˆì¸¡
                precision = 0.0
                recall = 0.0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        else:
            f1 = f1_score(y_true, y_pred)
            precision = precision_score(y_true, y_pred)
            recall = recall_score(y_true, y_pred)
        
        accuracy = accuracy_score(y_true, y_pred)
        
        # ROC AUCëŠ” í™•ë¥  ì ìˆ˜ë¡œ ê³„ì‚°
        try:
            auc = roc_auc_score(y_true, weighted_score)
        except:
            auc = 0.0
        
        return {
            'f1_score': f1,
            'precision': precision,
            'recall': recall,
            'accuracy': accuracy,
            'auc': auc,
            'threshold': threshold
        }
    
    def find_best_threshold_for_weighted_score(self, y_true: np.ndarray, 
                                             weighted_score: np.ndarray, 
                                             n_thresholds: int = 100) -> Tuple[float, Dict]:
        """
        ê°€ì¤‘ ì ìˆ˜ì— ëŒ€í•œ ìµœì  ì„ê³„ê°’ ì°¾ê¸°
        """
        min_score = np.min(weighted_score)
        max_score = np.max(weighted_score)
        thresholds = np.linspace(min_score, max_score, n_thresholds)
        
        best_f1 = 0
        best_threshold = 0.5
        best_metrics = None
        
        for threshold in thresholds:
            metrics = self.evaluate_weighted_score(y_true, weighted_score, threshold)
            if metrics['f1_score'] > best_f1:
                best_f1 = metrics['f1_score']
                best_threshold = threshold
                best_metrics = metrics
        
        return best_threshold, best_metrics
    
    def grid_search_weights_normalized(self, data: pd.DataFrame, y_true: np.ndarray, 
                                     prediction_cols: List[str], 
                                     n_points_per_dim: int = 5) -> Tuple[Dict, float, float]:
        """
        Grid Searchë¥¼ í†µí•œ ê°€ì¤‘ì¹˜ ìµœì í™” (ê°€ì¤‘ì¹˜ í•© = 1 ì œì•½ì¡°ê±´)
        
        Parameters:
        data: DataFrame
        y_true: ì‹¤ì œ ë¼ë²¨
        prediction_cols: ì˜ˆì¸¡ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        n_points_per_dim: ê° ì°¨ì›ë‹¹ í…ŒìŠ¤íŠ¸í•  ì  ê°œìˆ˜
        
        Returns:
        best_weights: dict, ìµœì  ê°€ì¤‘ì¹˜ (í•©=1)
        best_f1: float, ìµœê³  F1 ì ìˆ˜
        best_threshold: float, ìµœì  ì„ê³„ê°’
        """
        n_cols = len(prediction_cols)
        
        print(f"ğŸ” Grid Search ì‹œì‘ (ê°€ì¤‘ì¹˜ í•©=1 ì œì•½ì¡°ê±´)...")
        print(f"   ì˜ˆì¸¡ ì»¬ëŸ¼ ìˆ˜: {n_cols}")
        print(f"   ê° ì°¨ì›ë‹¹ ì  ìˆ˜: {n_points_per_dim}")
        
        best_f1 = 0
        best_weights = None
        best_threshold = 0.5
        
        # n-1ê°œ ê°€ì¤‘ì¹˜ë§Œ ë³€í™”ì‹œí‚¤ê³ , ë§ˆì§€ë§‰ ê°€ì¤‘ì¹˜ëŠ” 1-sum(others)ë¡œ ê³„ì‚°
        tested_combinations = 0
        total_combinations = n_points_per_dim ** (n_cols - 1)
        
        print(f"   ì´ ì¡°í•© ìˆ˜: {total_combinations:,}")
        
        # ì²« n-1ê°œ ê°€ì¤‘ì¹˜ì˜ ê°€ëŠ¥í•œ ê°’ë“¤ ìƒì„±
        weight_values = np.linspace(0.1, 0.9, n_points_per_dim)
        
        # ëª¨ë“  ì¡°í•© ìƒì„± (n-1ì°¨ì›)
        for weight_combo in product(weight_values, repeat=n_cols-1):
            tested_combinations += 1
            
            # ì²« n-1ê°œ ê°€ì¤‘ì¹˜
            weights_partial = list(weight_combo)
            
            # ë§ˆì§€ë§‰ ê°€ì¤‘ì¹˜ = 1 - sum(ì²« n-1ê°œ)
            sum_partial = sum(weights_partial)
            
            # ë§ˆì§€ë§‰ ê°€ì¤‘ì¹˜ê°€ 0~1 ë²”ìœ„ì— ìˆëŠ”ì§€ í™•ì¸
            if sum_partial <= 1.0:
                last_weight = 1.0 - sum_partial
                weights_full = weights_partial + [last_weight]
                
                # ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
                weights = dict(zip(prediction_cols, weights_full))
                
                # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
                weighted_score = self.calculate_weighted_score(data, weights)
                
                # ìµœì  ì„ê³„ê°’ ë° ì„±ëŠ¥ í‰ê°€
                threshold, metrics = self.find_best_threshold_for_weighted_score(y_true, weighted_score)
                
                # ìµœê³  ì„±ëŠ¥ ì—…ë°ì´íŠ¸
                if metrics['f1_score'] > best_f1:
                    best_f1 = metrics['f1_score']
                    best_weights = weights.copy()
                    best_threshold = threshold
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if tested_combinations % 500 == 0:
                print(f"   ì§„í–‰: {tested_combinations:,} / {total_combinations:,}")
        
        print(f"âœ… Grid Search ì™„ë£Œ!")
        print(f"   í…ŒìŠ¤íŠ¸ëœ ì¡°í•©: {tested_combinations:,}")
        
        return best_weights, best_f1, best_threshold
    
    def bayesian_optimize_weights_normalized(self, data: pd.DataFrame, y_true: np.ndarray,
                                           prediction_cols: List[str], 
                                           n_calls: int = 100) -> Tuple[Dict, float, Any]:
        """
        Bayesian Optimizationì„ í†µí•œ ê°€ì¤‘ì¹˜ ìµœì í™” (ê°€ì¤‘ì¹˜ í•©=1 ì œì•½ì¡°ê±´)
        """
        if not SKOPT_AVAILABLE:
            raise ImportError("scikit-optimizeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install scikit-optimize")
        
        n_cols = len(prediction_cols)
        
        # n-1ê°œ ê°€ì¤‘ì¹˜ë§Œ ìµœì í™”í•˜ê³ , ë§ˆì§€ë§‰ì€ 1-sum(others)ë¡œ ê³„ì‚°
        dimensions = [Real(0.1, 0.9, name=f'weight_{i}') for i in range(n_cols-1)]
        
        @use_named_args(dimensions)
        def objective(**params):
            """ëª©ì  í•¨ìˆ˜: F1-scoreì˜ ìŒìˆ˜ë¥¼ ë°˜í™˜"""
            
            # ì²« n-1ê°œ ê°€ì¤‘ì¹˜
            weights_partial = list(params.values())
            sum_partial = sum(weights_partial)
            
            # ê°€ì¤‘ì¹˜ í•©ì´ 1ì„ ì´ˆê³¼í•˜ë©´ penalty
            if sum_partial > 1.0:
                return 1.0  # ìµœì•…ì˜ ì ìˆ˜
            
            # ë§ˆì§€ë§‰ ê°€ì¤‘ì¹˜
            last_weight = 1.0 - sum_partial
            weights_full = weights_partial + [last_weight]
            
            # ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            weights = dict(zip(prediction_cols, weights_full))
            
            # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
            weighted_score = self.calculate_weighted_score(data, weights)
            
            # ìµœì  ì„ê³„ê°’ ë° ì„±ëŠ¥ í‰ê°€
            _, metrics = self.find_best_threshold_for_weighted_score(y_true, weighted_score)
            
            # F1-scoreì˜ ìŒìˆ˜ ë°˜í™˜
            return -metrics['f1_score']
        
        print("ğŸ§  Bayesian Optimization ì‹œì‘ (ê°€ì¤‘ì¹˜ í•©=1 ì œì•½ì¡°ê±´)...")
        print(f"   ë°˜ë³µ íšŸìˆ˜: {n_calls}")
        print(f"   ìµœì í™” ì°¨ì›: {len(dimensions)} (ë§ˆì§€ë§‰ ê°€ì¤‘ì¹˜ëŠ” ìë™ ê³„ì‚°)")
        
        # Bayesian Optimization ì‹¤í–‰
        result = gp_minimize(
            func=objective,
            dimensions=dimensions,
            n_calls=n_calls,
            random_state=42,
            acq_func='EI',
            n_initial_points=10
        )
        
        # ìµœì  ê°€ì¤‘ì¹˜ ì¶”ì¶œ
        weights_partial = result.x
        sum_partial = sum(weights_partial)
        last_weight = 1.0 - sum_partial
        weights_full = weights_partial + [last_weight]
        
        best_weights = dict(zip(prediction_cols, weights_full))
        best_f1 = -result.fun
        
        print("âœ… Bayesian Optimization ì™„ë£Œ!")
        
        return best_weights, best_f1, result
    
    def scipy_optimize_weights_normalized(self, data: pd.DataFrame, y_true: np.ndarray,
                                        prediction_cols: List[str]) -> Tuple[Dict, float]:
        """
        Scipy optimizeë¥¼ ì‚¬ìš©í•œ ê°€ì¤‘ì¹˜ ìµœì í™” (ê°€ì¤‘ì¹˜ í•©=1 ì œì•½ì¡°ê±´)
        """
        n_weights = len(prediction_cols)
        
        def objective_function(weights_array, data, y_true, prediction_cols):
            """
            ìµœì í™” ëª©ì  í•¨ìˆ˜ (F1-scoreë¥¼ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ ìŒìˆ˜ ë°˜í™˜)
            """
            # ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            weights = dict(zip(prediction_cols, weights_array))
            
            # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
            weighted_score = self.calculate_weighted_score(data, weights)
            
            # ìµœì  ì„ê³„ê°’ ë° ì„±ëŠ¥ í‰ê°€
            _, metrics = self.find_best_threshold_for_weighted_score(y_true, weighted_score)
            
            # F1-scoreì˜ ìŒìˆ˜ ë°˜í™˜ (ìµœì†Œí™” ë¬¸ì œë¡œ ë³€í™˜)
            return -metrics['f1_score']
        
        # ì œì•½ ì¡°ê±´: ê°€ì¤‘ì¹˜ í•©ì´ ì •í™•íˆ 1.0
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})
        
        # ê²½ê³„ ì¡°ê±´: ê° ê°€ì¤‘ì¹˜ëŠ” 0.0 ~ 1.0
        bounds = [(0.0, 1.0) for _ in range(n_weights)]
        
        # ì´ˆê¸°ê°’: ê· ë“± ê°€ì¤‘ì¹˜ (í•©=1)
        x0 = np.array([1.0/n_weights] * n_weights)
        
        print("ğŸš€ Scipy Optimize ìµœì í™” ì‹œì‘ (ê°€ì¤‘ì¹˜ í•©=1 ì œì•½ì¡°ê±´)...")
        
        # ìµœì í™” ì‹¤í–‰
        result = minimize(
            objective_function,
            x0,
            args=(data, y_true, prediction_cols),
            method='SLSQP',
            bounds=bounds,
            constraints=constraints,
            options={'disp': False, 'maxiter': 1000, 'ftol': 1e-9}
        )
        
        if result.success:
            # ê°€ì¤‘ì¹˜ ì •ê·œí™” (í˜¹ì‹œ ëª¨ë¥¼ ìˆ˜ì¹˜ ì˜¤ì°¨ ë³´ì •)
            weights_raw = result.x
            weights_normalized = weights_raw / np.sum(weights_raw)
            
            optimal_weights = dict(zip(prediction_cols, weights_normalized))
            optimal_f1 = -result.fun
            
            print("âœ… ìµœì í™” ì„±ê³µ!")
            
            return optimal_weights, optimal_f1
        else:
            print("âŒ ìµœì í™” ì‹¤íŒ¨!")
            print(result.message)
            return None, 0
    
    def optimize_weights(self, data: pd.DataFrame, method: str = 'bayesian',
                        **kwargs) -> Dict[str, Any]:
        """
        ê°€ì¤‘ì¹˜ ìµœì í™” ë©”ì¸ í•¨ìˆ˜
        
        Parameters:
        data: DataFrame (ì˜ˆì¸¡ ì»¬ëŸ¼ë“¤ê³¼ attrition_binary í¬í•¨)
        method: ìµœì í™” ë°©ë²• ('grid', 'bayesian', 'scipy')
        **kwargs: ê° ë°©ë²•ë³„ ì¶”ê°€ íŒŒë¼ë¯¸í„°
        
        Returns:
        results: ìµœì í™” ê²°ê³¼
        """
        
        # ì˜ˆì¸¡ ì»¬ëŸ¼ë“¤ ì°¾ê¸°
        prediction_cols = [col for col in data.columns if col.endswith('_prediction')]
        y_true = data['attrition_binary']
        
        print(f"ğŸ¯ ê°€ì¤‘ì¹˜ ìµœì í™” ì‹œì‘ - ë°©ë²•: {method}")
        print(f"   ì˜ˆì¸¡ ì»¬ëŸ¼: {prediction_cols}")
        print(f"   ë°ì´í„° í¬ê¸°: {len(data)}")
        
        results = {
            'method': method,
            'prediction_columns': prediction_cols,
            'data_size': len(data)
        }
        
        if method == 'grid':
            n_points = kwargs.get('n_points_per_dim', 5)
            best_weights, best_f1, best_threshold = self.grid_search_weights_normalized(
                data, y_true, prediction_cols, n_points
            )
            results.update({
                'best_weights': best_weights,
                'best_f1': best_f1,
                'best_threshold': best_threshold
            })
            
        elif method == 'bayesian':
            if not SKOPT_AVAILABLE:
                print("âŒ scikit-optimizeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                print("ëŒ€ì‹  scipy ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                method = 'scipy'
            else:
                n_calls = kwargs.get('n_calls', 100)
                best_weights, best_f1, bayes_result = self.bayesian_optimize_weights_normalized(
                    data, y_true, prediction_cols, n_calls
                )
                
                # ìµœì  ì„ê³„ê°’ ê³„ì‚°
                weighted_score = self.calculate_weighted_score(data, best_weights)
                best_threshold, _ = self.find_best_threshold_for_weighted_score(y_true, weighted_score)
                
                results.update({
                    'best_weights': best_weights,
                    'best_f1': best_f1,
                    'best_threshold': best_threshold,
                    'bayes_result': bayes_result
                })
        
        if method == 'scipy':
            best_weights, best_f1 = self.scipy_optimize_weights_normalized(
                data, y_true, prediction_cols
            )
            
            if best_weights:
                # ìµœì  ì„ê³„ê°’ ê³„ì‚°
                weighted_score = self.calculate_weighted_score(data, best_weights)
                best_threshold, _ = self.find_best_threshold_for_weighted_score(y_true, weighted_score)
                
                results.update({
                    'best_weights': best_weights,
                    'best_f1': best_f1,
                    'best_threshold': best_threshold
                })
            else:
                results.update({
                    'best_weights': None,
                    'best_f1': 0,
                    'best_threshold': 0.5,
                    'error': 'Optimization failed'
                })
        
        # ê²°ê³¼ ì €ì¥
        if results.get('best_weights'):
            self.optimal_weights = results['best_weights']
            self.optimal_threshold = results['best_threshold']
            self.optimization_results = results
        
        return results
    
    def apply_optimal_weights(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ë°ì´í„°ì— ì ìš©
        
        Parameters:
        data: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
        Returns:
        data_with_weighted: ê°€ì¤‘ ì ìˆ˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
        """
        
        if not self.optimal_weights:
            raise ValueError("ìµœì  ê°€ì¤‘ì¹˜ê°€ ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. optimize_weights()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        data_with_weighted = data.copy()
        
        # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
        data_with_weighted['final_weighted_score'] = self.calculate_weighted_score(
            data_with_weighted, self.optimal_weights
        )
        
        # ìµœì¢… ì˜ˆì¸¡ ìƒì„±
        data_with_weighted['final_prediction'] = (
            data_with_weighted['final_weighted_score'] >= self.optimal_threshold
        ).astype(int)
        
        return data_with_weighted
    
    def classify_risk_level(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ìœ„í—˜ë„ êµ¬ê°„ ë¶„ë¥˜ ì¶”ê°€
        
        Parameters:
        data: ê°€ì¤‘ ì ìˆ˜ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        
        Returns:
        data_with_risk: ìœ„í—˜ë„ ë¶„ë¥˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
        """
        
        def get_risk_level(score):
            if score < 0.3:
                return 'ì•ˆì „êµ°'
            elif score < 0.7:
                return 'ì£¼ì˜êµ°'
            else:
                return 'ê³ ìœ„í—˜êµ°'
        
        def get_risk_level_numeric(score):
            if score < 0.3:
                return 1
            elif score < 0.7:
                return 2
            else:
                return 3
        
        data_with_risk = data.copy()
        
        if 'final_weighted_score' in data_with_risk.columns:
            data_with_risk['risk_level'] = data_with_risk['final_weighted_score'].apply(get_risk_level)
            data_with_risk['risk_level_numeric'] = data_with_risk['final_weighted_score'].apply(get_risk_level_numeric)
        
        return data_with_risk
    
    def get_performance_summary(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ìµœì¢… ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜
        
        Parameters:
        data: ìµœì¢… ì˜ˆì¸¡ì´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        
        Returns:
        summary: ì„±ëŠ¥ ìš”ì•½ ë”•ì…”ë„ˆë¦¬
        """
        
        if 'final_prediction' not in data.columns or 'attrition_binary' not in data.columns:
            raise ValueError("final_prediction ë˜ëŠ” attrition_binary ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        y_true = data['attrition_binary']
        y_pred = data['final_prediction']
        weighted_score = data.get('final_weighted_score', np.zeros(len(data)))
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        metrics = self.evaluate_weighted_score(y_true, weighted_score, self.optimal_threshold)
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_true, y_pred)
        
        # ìœ„í—˜ë„ êµ¬ê°„ë³„ í†µê³„
        risk_stats = {}
        if 'risk_level' in data.columns:
            risk_counts = data['risk_level'].value_counts()
            risk_attrition = data.groupby('risk_level')['attrition_binary'].agg(['count', 'sum', 'mean'])
            
            risk_stats = {
                'counts': risk_counts.to_dict(),
                'attrition_rates': risk_attrition['mean'].to_dict()
            }
        
        summary = {
            'optimal_weights': self.optimal_weights,
            'optimal_threshold': self.optimal_threshold,
            'performance_metrics': metrics,
            'confusion_matrix': cm.tolist(),
            'risk_statistics': risk_stats,
            'optimization_method': self.optimization_results.get('method', 'unknown')
        }
        
        return summary


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
    try:
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” threshold_calculatorì˜ ê²°ê³¼ë¥¼ ì‚¬ìš©)
        np.random.seed(42)
        n_samples = 1000
        
        data = pd.DataFrame({
            'employee_id': range(1, n_samples + 1),
            'Structura_score_prediction': np.random.randint(0, 2, n_samples),
            'Cognita_score_prediction': np.random.randint(0, 2, n_samples),
            'Chronos_score_prediction': np.random.randint(0, 2, n_samples),
            'Sentio_score_prediction': np.random.randint(0, 2, n_samples),
            'Agora_score_prediction': np.random.randint(0, 2, n_samples),
            'attrition_binary': np.random.randint(0, 2, n_samples)
        })
        
        # ê°€ì¤‘ì¹˜ ìµœì í™”ê¸° ì´ˆê¸°í™”
        optimizer = WeightOptimizer()
        
        # Grid Searchë¡œ ìµœì í™”
        print("=== Grid Search ìµœì í™” ===")
        results = optimizer.optimize_weights(data, method='grid', n_points_per_dim=3)
        print(f"ìµœì  ê°€ì¤‘ì¹˜: {results['best_weights']}")
        print(f"ìµœê³  F1-Score: {results['best_f1']:.4f}")
        
        # ìµœì  ê°€ì¤‘ì¹˜ ì ìš©
        data_with_weighted = optimizer.apply_optimal_weights(data)
        data_with_risk = optimizer.classify_risk_level(data_with_weighted)
        
        # ì„±ëŠ¥ ìš”ì•½
        summary = optimizer.get_performance_summary(data_with_risk)
        print(f"\n=== ìµœì¢… ì„±ëŠ¥ ìš”ì•½ ===")
        print(f"ìµœì  ì„ê³„ê°’: {summary['optimal_threshold']:.4f}")
        print(f"F1-Score: {summary['performance_metrics']['f1_score']:.4f}")
        print(f"ì •í™•ë„: {summary['performance_metrics']['accuracy']:.4f}")
        
        print(f"\nìœ„í—˜ë„ êµ¬ê°„ë³„ ë¶„í¬:")
        for level, count in summary['risk_statistics']['counts'].items():
            print(f"  {level}: {count}ëª…")
            
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
