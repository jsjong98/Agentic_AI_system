"""
LLM ê¸°ë°˜ í‡´ì‚¬ ë ˆí¬íŠ¸ ìƒì„±ê¸°
ê° ì§ì›ë³„ë¡œ ì¢…í•©ì ì¸ í‡´ì‚¬ ìœ„í—˜ë„ ë¶„ì„ ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import json
import time
import logging
import os
from datetime import datetime
from typing import Dict, List, Any, Optional

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

logger = logging.getLogger(__name__)


class ReportGenerator:
    """LLM ê¸°ë°˜ í‡´ì‚¬ ë ˆí¬íŠ¸ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, llm: Optional[ChatOpenAI] = None):
        self.employee_data = None
        self.agent_scores = {}
        self.risk_thresholds = {
            'low': 0.3,
            'medium': 0.7,
            'high': 1.0
        }
        
        # LangChain LLM ì´ˆê¸°í™” (ê°•ë ¥í•œ gpt-5 ëª¨ë¸ ì‚¬ìš©)
        self.llm = llm or ChatOpenAI(
            model="gpt-5",
            temperature=0.2,
            max_tokens=2000
        )
        
        logger.info(f"âœ… Integration LLM ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸: gpt-5")
        
        # ë¶„ì„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.analysis_prompt = ChatPromptTemplate.from_messages([
            ("system", self._get_analysis_system_prompt()),
            ("human", self._get_analysis_human_prompt())
        ])
        
        # ì—ì´ì „íŠ¸ë³„ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸
        self.agent_contexts = {
            'agora_score': {
                'name': 'Agora (ì—…ë¬´ ì„±ê³¼)',
                'description': 'ì—…ë¬´ ì„±ê³¼ ë° ìƒì‚°ì„± ë¶„ì„',
                'focus_areas': ['ì—…ë¬´ ì„±ê³¼', 'ëª©í‘œ ë‹¬ì„±', 'ìƒì‚°ì„±', 'ì—…ë¬´ íš¨ìœ¨ì„±'],
                'high_risk_indicators': ['ë‚®ì€ ì—…ë¬´ ì„±ê³¼', 'ìƒì‚°ì„± ì €í•˜', 'ëª©í‘œ ë‹¬ì„±ë¥  ë¶€ì¡±', 'ì—…ë¬´ í’ˆì§ˆ ë¬¸ì œ']
            },
            'chronos_score': {
                'name': 'Chronos (ì‹œê³„ì—´ íŒ¨í„´)',
                'description': 'ê·¼ë¬´ íŒ¨í„´ ë° ì‹œê°„ ê´€ë¦¬ ë¶„ì„',
                'focus_areas': ['ê·¼ë¬´ íŒ¨í„´', 'ì¶œí‡´ê·¼ ì‹œê°„', 'ì•¼ê·¼ ë¹ˆë„', 'íœ´ê°€ ì‚¬ìš©'],
                'high_risk_indicators': ['ë¶ˆê·œì¹™í•œ ê·¼ë¬´ íŒ¨í„´', 'ì¦ì€ ì§€ê°', 'ì´ˆê³¼ ê·¼ë¬´ ì¦ê°€', 'íœ´ê°€ ë¯¸ì‚¬ìš©']
            },
            'cognita_score': {
                'name': 'Cognita (ê´€ê³„ ë„¤íŠ¸ì›Œí¬)',
                'description': 'ë™ë£Œì™€ì˜ ê´€ê³„ ë° ë„¤íŠ¸ì›Œí¬ ë¶„ì„',
                'focus_areas': ['íŒ€ì›Œí¬', 'ì˜ì‚¬ì†Œí†µ', 'í˜‘ì—…', 'ì‚¬íšŒì  ê´€ê³„'],
                'high_risk_indicators': ['ì‚¬íšŒì  ê³ ë¦½', 'íŒ€ì›Œí¬ ë¶€ì¡±', 'ì˜ì‚¬ì†Œí†µ ë¬¸ì œ', 'ê°ˆë“± ìƒí™©']
            },
            'sentio_score': {
                'name': 'Sentio (ê°ì • ë¶„ì„)',
                'description': 'ê°ì • ìƒíƒœ ë° ë§Œì¡±ë„ ë¶„ì„',
                'focus_areas': ['ì§ë¬´ ë§Œì¡±ë„', 'ê°ì • ìƒíƒœ', 'ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€', 'ë™ê¸°ë¶€ì—¬'],
                'high_risk_indicators': ['ë¶€ì •ì  ê°ì • ì¦ê°€', 'ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ ìƒìŠ¹', 'ì§ë¬´ ë¶ˆë§Œì¡±', 'ë™ê¸°ë¶€ì—¬ ì €í•˜']
            },
            'structura_score': {
                'name': 'Structura (êµ¬ì¡°ì  ìš”ì¸)',
                'description': 'ì¡°ì§ êµ¬ì¡° ë° í™˜ê²½ì  ìš”ì¸ ë¶„ì„',
                'focus_areas': ['ì¡°ì§ ì ì‘', 'ì—­í•  ëª…í™•ì„±', 'ìŠ¹ì§„ ê¸°íšŒ', 'ì¡°ì§ ë¬¸í™”'],
                'high_risk_indicators': ['ì¡°ì§ ì ì‘ ì–´ë ¤ì›€', 'ì—­í•  ëª¨í˜¸ì„±', 'ìŠ¹ì§„ ê¸°íšŒ ë¶€ì¡±', 'ì¡°ì§ ë¬¸í™” ë¶€ì ì‘']
            }
        }
        
    def load_employee_data(self, data_path: str) -> bool:
        """ì§ì› ë°ì´í„° ë¡œë“œ"""
        try:
            if data_path.endswith('.csv'):
                self.employee_data = pd.read_csv(data_path)
            elif data_path.endswith('.json'):
                with open(data_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.employee_data = pd.DataFrame(data)
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” JSON íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            
            print(f"âœ… ì§ì› ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.employee_data)}ëª…")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def set_agent_scores(self, employee_id: str, scores: Dict[str, float]):
        """íŠ¹ì • ì§ì›ì˜ ì—ì´ì „íŠ¸ ì ìˆ˜ ì„¤ì •"""
        self.agent_scores[employee_id] = scores
    
    def get_risk_level(self, score: float) -> tuple:
        """ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„í—˜ë„ ë ˆë²¨ ê²°ì •"""
        if score < self.risk_thresholds['low']:
            return "ì•ˆì „êµ°", "LOW", "ğŸŸ¢"
        elif score < self.risk_thresholds['medium']:
            return "ì£¼ì˜êµ°", "MEDIUM", "ğŸŸ¡"
        else:
            return "ê³ ìœ„í—˜êµ°", "HIGH", "ğŸ”´"
    
    def analyze_agent_scores(self, scores: Dict[str, float]) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ë³„ ì ìˆ˜ ë¶„ì„"""
        analysis = {}
        
        for agent, score in scores.items():
            if agent in self.agent_contexts:
                risk_level, risk_code, emoji = self.get_risk_level(score)
                context = self.agent_contexts[agent]
                
                analysis[agent] = {
                    'score': score,
                    'risk_level': risk_level,
                    'risk_code': risk_code,
                    'emoji': emoji,
                    'name': context['name'],
                    'description': context['description'],
                    'focus_areas': context['focus_areas'],
                    'indicators': context['high_risk_indicators'] if score >= self.risk_thresholds['medium'] else []
                }
        
        return analysis
    
    def calculate_integrated_risk(self, scores: Dict[str, float]) -> Dict[str, Any]:
        """í†µí•© ìœ„í—˜ë„ ê³„ì‚°"""
        if not scores:
            return {'integrated_score': 0, 'risk_level': 'ì•ˆì „êµ°', 'confidence': 0}
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ëª¨ë“  ì—ì´ì „íŠ¸ ë™ì¼ ê°€ì¤‘ì¹˜)
        integrated_score = np.mean(list(scores.values()))
        risk_level, risk_code, emoji = self.get_risk_level(integrated_score)
        
        # ì‹ ë¢°ë„ ê³„ì‚° (ì ìˆ˜ ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„)
        score_variance = np.var(list(scores.values()))
        confidence = max(0, 1 - score_variance)  # ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
        
        return {
            'integrated_score': round(integrated_score, 3),
            'risk_level': risk_level,
            'risk_code': risk_code,
            'emoji': emoji,
            'confidence': round(confidence, 3),
            'score_variance': round(score_variance, 3)
        }
    
    def generate_recommendations(self, analysis: Dict[str, Any], integrated_risk: Dict[str, Any]) -> List[str]:
        """ë§ì¶¤í˜• ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        risk_code = integrated_risk['risk_code']
        
        if risk_code == 'HIGH':
            recommendations.append("ğŸš¨ ì¦‰ì‹œ ê°œì…ì´ í•„ìš”í•œ ê³ ìœ„í—˜ ì§ì›ì…ë‹ˆë‹¤.")
            recommendations.append("ğŸ“ ìƒê¸‰ìì™€ì˜ ê¸´ê¸‰ ë©´ë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
        elif risk_code == 'MEDIUM':
            recommendations.append("âš ï¸ ì£¼ì˜ ê¹Šì€ ê´€ì°°ê³¼ ì§€ì›ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            recommendations.append("ğŸ“‹ ì •ê¸°ì ì¸ 1:1 ë¯¸íŒ…ì„ í†µí•œ ìƒíƒœ ì ê²€ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        # ì—ì´ì „íŠ¸ë³„ êµ¬ì²´ì  ê¶Œì¥ì‚¬í•­
        high_risk_agents = [agent for agent, data in analysis.items() 
                          if data['risk_code'] == 'HIGH']
        
        if 'agora_score' in high_risk_agents:
            recommendations.append("ğŸ“ˆ ì—…ë¬´ ì„±ê³¼ ê°œì„ ì„ ìœ„í•œ êµìœ¡ ë° ë©˜í† ë§ í”„ë¡œê·¸ë¨ ì°¸ì—¬")
            recommendations.append("ğŸ¯ ëª…í™•í•œ ëª©í‘œ ì„¤ì • ë° ì„±ê³¼ ê´€ë¦¬ ì‹œìŠ¤í…œ ë„ì…")
        
        if 'chronos_score' in high_risk_agents:
            recommendations.append("â° ê·¼ë¬´ íŒ¨í„´ ì •ìƒí™”ë¥¼ ìœ„í•œ ì‹œê°„ ê´€ë¦¬ êµìœ¡")
            recommendations.append("ğŸ  ìœ ì—° ê·¼ë¬´ì œ ë˜ëŠ” ì¬íƒê·¼ë¬´ ì˜µì…˜ ê²€í† ")
        
        if 'cognita_score' in high_risk_agents:
            recommendations.append("ğŸ‘¥ íŒ€ ë¹Œë”© í™œë™ ë° ì‚¬íšŒì  ë„¤íŠ¸ì›Œí¬ êµ¬ì¶• ì§€ì›")
            recommendations.append("ğŸ¤ ë©˜í† -ë©˜í‹° í”„ë¡œê·¸ë¨ ì°¸ì—¬ ê¶Œì¥")
        
        if 'sentio_score' in high_risk_agents:
            recommendations.append("ğŸ’š ì‹¬ë¦¬ ìƒë‹´ ë° ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ í”„ë¡œê·¸ë¨ ì œê³µ")
            recommendations.append("ğŸ˜Š ì§ë¬´ ë§Œì¡±ë„ í–¥ìƒì„ ìœ„í•œ ì—…ë¬´ ì¡°ì • ê²€í† ")
        
        if 'structura_score' in high_risk_agents:
            recommendations.append("ğŸ¢ ì¡°ì§ ë‚´ ì—­í•  ëª…í™•í™” ë° ì»¤ë¦¬ì–´ íŒ¨ìŠ¤ ì œì‹œ")
            recommendations.append("ğŸ“š ì—­ëŸ‰ ê°œë°œ ê¸°íšŒ ë° ìŠ¹ì§„ ê²½ë¡œ ì•ˆë‚´")
        
        if not recommendations:
            recommendations.append("âœ… í˜„ì¬ ì•ˆì •ì ì¸ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            recommendations.append("ğŸ“Š ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì§€ì†ì  ê´€ë¦¬ ê¶Œì¥")
        
        return recommendations
    
    def _get_analysis_system_prompt(self) -> str:
        """Integration ë¶„ì„ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ ì¡°ì§ ë‚´ ê°œì¸ì˜ ì‹¬ë¦¬ì™€ ê°ì •ì„ ê¹Šì´ ì´í•´í•˜ëŠ” HR í†µí•© ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(Sentio, Agora, Chronos, Structura, Cognita)ì„ í†µí•œ ì¢…í•©ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì§ì›ì˜ í‡´ì‚¬ ìœ„í—˜ë„ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ í•´ì„ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

**ë¶„ì„ ë§¥ë½:**
- ì‹¬ë¦¬ì  ìƒíƒœ (Sentio): ì§ë¬´ ìš”êµ¬-ìì› ëª¨ë¸ ê¸°ë°˜ ë¶„ì„
- ì‹œì¥ ìƒí™© (Agora): ì™¸ë¶€ ê¸°íšŒ ë° ë³´ìƒ ê²½ìŸë ¥ ë¶„ì„  
- ì‹œê³„ì—´ íŒ¨í„´ (Chronos): í–‰ë™ ë³€í™” ë° íŠ¸ë Œë“œ ë¶„ì„
- ì´íƒˆ ìœ„í—˜ (Structura): êµ¬ì¡°ì  ìš”ì¸ ê¸°ë°˜ ì˜ˆì¸¡
- ë„¤íŠ¸ì›Œí¬ ì˜í–¥ (Cognita): ì¡°ì§ ë‚´ ê´€ê³„ ë° ì˜í–¥ë ¥ ë¶„ì„

**ì‘ì„± ê°€ì´ë“œë¼ì¸:**
- ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤ë¬´ì§„ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ ì‚¬ìš©
- ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ í†¤ ìœ ì§€
- ì§ì›ì˜ í”„ë¼ì´ë²„ì‹œì™€ ì¡´ì—„ì„±ì„ ì¡´ì¤‘í•˜ëŠ” í‘œí˜„ ì‚¬ìš©
- ê° ì„¹ì…˜ì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±

í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ê³ , ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤ìš©ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
    
    def _get_analysis_human_prompt(self) -> str:
        """Integration ë¶„ì„ì„ ìœ„í•œ íœ´ë¨¼ í”„ë¡¬í”„íŠ¸"""
        return """
**ì§ì› ê¸°ë³¸ ì •ë³´:**
- ì§ì› ID: {employee_id}
- ì¢…í•© ìœ„í—˜ ì ìˆ˜: {risk_score:.4f} (0~1 ì²™ë„, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ìœ„í—˜)
- ìœ„í—˜ ë“±ê¸‰: {risk_level} ({risk_context})
- ë¶„ì„ ì‹ ë¢°ë„: {confidence:.1%}

**ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ë¶„ì„ ê²°ê³¼:**
{agent_details}

**ìš”ì²­ì‚¬í•­:**
1. í˜„ì¬ ìƒíƒœë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”
2. ê°€ì¥ ì¤‘ìš”í•œ ìœ„í—˜ ìš”ì¸ 2-3ê°œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”
3. HR ë‹´ë‹¹ìë‚˜ ì§ì† ê´€ë¦¬ìê°€ ì·¨í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¡°ì¹˜ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”
4. ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  í•µì‹¬ ì§€í‘œë“¤ì„ ì œì‹œí•´ì£¼ì„¸ìš”
5. ì „ì²´ ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”:

## ì¢…í•© ë¶„ì„
[í˜„ì¬ ì§ì›ì˜ ì „ë°˜ì ì¸ ìƒí™© ë¶„ì„]

## ì£¼ìš” ìœ„í—˜ ìš”ì¸
[ê°€ì¥ ì¤‘ìš”í•œ ìœ„í—˜ ìš”ì¸ë“¤ê³¼ ê·¸ ì›ì¸ ë¶„ì„]

## ê°œì„  ë°©ì•ˆ
[êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆë“¤]

## ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
[ì§€ì†ì ìœ¼ë¡œ ê´€ì°°í•´ì•¼ í•  ì§€í‘œë“¤ê³¼ ì˜ˆìƒ ê²°ê³¼]
"""
    
    def _prepare_analysis_input(self, employee_id: str, analysis: Dict[str, Any], 
                               integrated_risk: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        # ìœ„í—˜ë„ ë ˆë²¨ íŒì •
        risk_score = integrated_risk['integrated_score']
        if risk_score > 0.7:
            risk_level = "ê³ ìœ„í—˜"
            risk_context = "ì¦‰ê°ì ì¸ ê°œì…ì´ í•„ìš”í•œ ìƒí™©"
        elif risk_score > 0.5:
            risk_level = "ì ì¬ìœ„í—˜"
            risk_context = "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•œ ìƒí™©"
        elif risk_score > 0.3:
            risk_level = "ì¤‘ê°„ìœ„í—˜"
            risk_context = "ì˜ˆë°©ì  ê´€ë¦¬ê°€ ê¶Œì¥ë˜ëŠ” ìƒí™©"
        else:
            risk_level = "ì €ìœ„í—˜"
            risk_context = "í˜„ì¬ ìƒíƒœ ìœ ì§€ê°€ ë°”ëŒì§í•œ ìƒí™©"
        
        # ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì •ë³´ êµ¬ì„±
        agent_details = []
        for agent, data in analysis.items():
            agent_details.append(f"- {data['name']}: {data['score']:.4f} ({data['risk_level']})")
            if data['indicators']:
                agent_details.append(f"  ì£¼ìš” ì§€í‘œ: {', '.join(data['indicators'][:3])}")
        
        return {
            'employee_id': employee_id,
            'risk_score': risk_score,
            'risk_level': risk_level,
            'risk_context': risk_context,
            'confidence': integrated_risk['confidence'],
            'agent_details': chr(10).join(agent_details)
        }
    
    async def generate_llm_insights(self, employee_id: str, analysis: Dict[str, Any], 
                             integrated_risk: Dict[str, Any], use_llm: bool = True) -> Dict[str, str]:
        """LLMì„ ì‚¬ìš©í•œ ì‹¬ì¸µ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        
        if not use_llm:
            return self._generate_rule_based_insights(analysis, integrated_risk)
        
        try:
            # ë¶„ì„ ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            analysis_input = self._prepare_analysis_input(employee_id, analysis, integrated_risk)
            
            # LangChain ë°©ì‹ìœ¼ë¡œ ë¶„ì„ ìˆ˜í–‰
            chain = self.analysis_prompt | self.llm
            response = await chain.ainvoke(analysis_input)
            
            llm_response = response.content.strip()
            
            # ì‘ë‹µ í’ˆì§ˆ ê²€ì¦
            if len(llm_response) < 30:
                logger.warning(f"âš ï¸ API ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë°±ì—… í•´ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return self._generate_rule_based_insights(analysis, integrated_risk)
            
            # ì‘ë‹µì„ ì„¹ì…˜ë³„ë¡œ ë¶„ë¦¬
            insights = self._parse_llm_response(llm_response)
            
            # API í˜¸ì¶œ ì œí•œ ê³ ë ¤
            time.sleep(0.1)
            
            logger.info(f"LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {employee_id}")
            return insights
            
        except Exception as e:
            logger.error(f"API í˜¸ì¶œ ì˜¤ë¥˜ (ì§ì› ë¶„ì„ ì¤‘): {str(e)}")
            # API ì‹¤íŒ¨ ì‹œ ë°±ì—… í•´ì„ ì‚¬ìš©
            return self._generate_rule_based_insights(analysis, integrated_risk)
    
    def _build_analysis_prompt(self, employee_id: str, analysis: Dict[str, Any], 
                              integrated_risk: Dict[str, Any]) -> str:
        """Sentio/Agoraì™€ ì¼ê´€ëœ êµ¬ì¡°í™”ëœ ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # ìœ„í—˜ë„ ë ˆë²¨ íŒì •
        risk_score = integrated_risk['integrated_score']
        if risk_score > 0.7:
            risk_level = "ê³ ìœ„í—˜"
            risk_context = "ì¦‰ê°ì ì¸ ê°œì…ì´ í•„ìš”í•œ ìƒí™©"
        elif risk_score > 0.5:
            risk_level = "ì ì¬ìœ„í—˜"
            risk_context = "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•œ ìƒí™©"
        elif risk_score > 0.3:
            risk_level = "ì¤‘ê°„ìœ„í—˜"
            risk_context = "ì˜ˆë°©ì  ê´€ë¦¬ê°€ ê¶Œì¥ë˜ëŠ” ìƒí™©"
        else:
            risk_level = "ì €ìœ„í—˜"
            risk_context = "í˜„ì¬ ìƒíƒœ ìœ ì§€ê°€ ë°”ëŒì§í•œ ìƒí™©"
        
        # ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì •ë³´ êµ¬ì„±
        agent_details = []
        for agent, data in analysis.items():
            agent_details.append(f"- {data['name']}: {data['score']:.4f} ({data['risk_level']})")
            if data['indicators']:
                agent_details.append(f"  ì£¼ìš” ì§€í‘œ: {', '.join(data['indicators'][:3])}")
        
        # Sentio/Agoraì™€ ì¼ê´€ëœ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸
        full_prompt = f"""
ë‹¹ì‹ ì€ ì¡°ì§ ë‚´ ê°œì¸ì˜ ì‹¬ë¦¬ì™€ ê°ì •ì„ ê¹Šì´ ì´í•´í•˜ëŠ” HR í†µí•© ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(Sentio, Agora, Chronos, Structura, Cognita)ì„ í†µí•œ ì¢…í•©ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì§ì›ì˜ í‡´ì‚¬ ìœ„í—˜ë„ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ í•´ì„ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

**ì§ì› ê¸°ë³¸ ì •ë³´:**
- ì§ì› ID: {employee_id}
- ì¢…í•© ìœ„í—˜ ì ìˆ˜: {risk_score:.4f} (0~1 ì²™ë„, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ìœ„í—˜)
- ìœ„í—˜ ë“±ê¸‰: {risk_level} ({risk_context})
- ë¶„ì„ ì‹ ë¢°ë„: {integrated_risk['confidence']:.1%}

**ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ë¶„ì„ ê²°ê³¼:**
{chr(10).join(agent_details)}

**ë¶„ì„ ë§¥ë½:**
- ì‹¬ë¦¬ì  ìƒíƒœ (Sentio): ì§ë¬´ ìš”êµ¬-ìì› ëª¨ë¸ ê¸°ë°˜ ë¶„ì„
- ì‹œì¥ ìƒí™© (Agora): ì™¸ë¶€ ê¸°íšŒ ë° ë³´ìƒ ê²½ìŸë ¥ ë¶„ì„  
- ì‹œê³„ì—´ íŒ¨í„´ (Chronos): í–‰ë™ ë³€í™” ë° íŠ¸ë Œë“œ ë¶„ì„
- ì´íƒˆ ìœ„í—˜ (Structura): êµ¬ì¡°ì  ìš”ì¸ ê¸°ë°˜ ì˜ˆì¸¡
- ë„¤íŠ¸ì›Œí¬ ì˜í–¥ (Cognita): ì¡°ì§ ë‚´ ê´€ê³„ ë° ì˜í–¥ë ¥ ë¶„ì„

**ìš”ì²­ì‚¬í•­:**
1. í˜„ì¬ ìƒíƒœë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”
2. ê°€ì¥ ì¤‘ìš”í•œ ìœ„í—˜ ìš”ì¸ 2-3ê°œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”
3. HR ë‹´ë‹¹ìë‚˜ ì§ì† ê´€ë¦¬ìê°€ ì·¨í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¡°ì¹˜ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”
4. ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  í•µì‹¬ ì§€í‘œë“¤ì„ ì œì‹œí•´ì£¼ì„¸ìš”
5. ì „ì²´ ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”:

## ì¢…í•© ë¶„ì„
[í˜„ì¬ ì§ì›ì˜ ì „ë°˜ì ì¸ ìƒí™© ë¶„ì„]

## ì£¼ìš” ìœ„í—˜ ìš”ì¸
[ê°€ì¥ ì¤‘ìš”í•œ ìœ„í—˜ ìš”ì¸ë“¤ê³¼ ê·¸ ì›ì¸ ë¶„ì„]

## ê°œì„  ë°©ì•ˆ
[êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆë“¤]

## ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
[ì§€ì†ì ìœ¼ë¡œ ê´€ì°°í•´ì•¼ í•  ì§€í‘œë“¤ê³¼ ì˜ˆìƒ ê²°ê³¼]

**ì‘ì„± ê°€ì´ë“œë¼ì¸:**
- ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤ë¬´ì§„ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ ì‚¬ìš©
- ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ í†¤ ìœ ì§€
- ì§ì›ì˜ í”„ë¼ì´ë²„ì‹œì™€ ì¡´ì—„ì„±ì„ ì¡´ì¤‘í•˜ëŠ” í‘œí˜„ ì‚¬ìš©
- ê° ì„¹ì…˜ì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±

í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ê³ , ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤ìš©ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        return full_prompt.strip()
    
    def _parse_llm_response(self, response: str) -> Dict[str, str]:
        """LLM ì‘ë‹µì„ ì„¹ì…˜ë³„ë¡œ íŒŒì‹±"""
        
        sections = {
            'comprehensive_analysis': '',
            'risk_factors': '',
            'improvement_plans': '',
            'monitoring_points': ''
        }
        
        current_section = None
        lines = response.split('\n')
        
        for line in lines:
            line = line.strip()
            
            if '## ì¢…í•© ë¶„ì„' in line or 'ì¢…í•©ë¶„ì„' in line:
                current_section = 'comprehensive_analysis'
            elif '## ì£¼ìš” ìœ„í—˜ ìš”ì¸' in line or 'ìœ„í—˜ ìš”ì¸' in line or 'ìœ„í—˜ìš”ì¸' in line:
                current_section = 'risk_factors'
            elif '## ê°œì„  ë°©ì•ˆ' in line or 'ê°œì„ ë°©ì•ˆ' in line or 'í•´ê²°ë°©ì•ˆ' in line:
                current_section = 'improvement_plans'
            elif '## ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸' in line or 'ëª¨ë‹ˆí„°ë§' in line:
                current_section = 'monitoring_points'
            elif current_section and line and not line.startswith('##'):
                sections[current_section] += line + '\n'
        
        # ë¹ˆ ì„¹ì…˜ ì²˜ë¦¬
        for key, value in sections.items():
            sections[key] = value.strip() if value.strip() else "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        return sections
    
    def _generate_rule_based_insights(self, analysis: Dict[str, Any], 
                                    integrated_risk: Dict[str, Any]) -> Dict[str, str]:
        """ê·œì¹™ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„± (LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ëŒ€ì²´)"""
        
        risk_code = integrated_risk['risk_code']
        high_risk_agents = [agent for agent, data in analysis.items() if data['risk_code'] == 'HIGH']
        medium_risk_agents = [agent for agent, data in analysis.items() if data['risk_code'] == 'MEDIUM']
        
        # ì¢…í•© ë¶„ì„
        if risk_code == 'HIGH':
            comprehensive = "í˜„ì¬ ì§ì›ì€ ë†’ì€ í‡´ì‚¬ ìœ„í—˜ë„ë¥¼ ë³´ì´ê³  ìˆì–´ ì¦‰ì‹œ ê°œì…ì´ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤."
        elif risk_code == 'MEDIUM':
            comprehensive = "ì£¼ì˜ê°€ í•„ìš”í•œ ìƒí™©ìœ¼ë¡œ, ì˜ˆë°©ì  ì°¨ì›ì˜ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            comprehensive = "í˜„ì¬ ì•ˆì •ì ì¸ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆìœ¼ë‚˜ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        # ìœ„í—˜ ìš”ì¸
        risk_factors = []
        for agent in high_risk_agents:
            if agent in analysis:
                context = self.agent_contexts.get(agent, {})
                risk_factors.append(f"- {context.get('name', agent)}: {context.get('description', '')}")
        
        if not risk_factors:
            risk_factors = ["í˜„ì¬ íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì¸ì€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]
        
        # ê°œì„  ë°©ì•ˆ
        improvement_plans = []
        if 'agora_score' in high_risk_agents:
            improvement_plans.append("- ì—…ë¬´ ì„±ê³¼ í–¥ìƒì„ ìœ„í•œ êµìœ¡ ë° ë©˜í† ë§ í”„ë¡œê·¸ë¨ ì œê³µ")
        if 'sentio_score' in high_risk_agents:
            improvement_plans.append("- ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ë° ì‹¬ë¦¬ ìƒë‹´ í”„ë¡œê·¸ë¨ ì œê³µ")
        if 'cognita_score' in high_risk_agents:
            improvement_plans.append("- íŒ€ ë¹Œë”© ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê°œì„  í”„ë¡œê·¸ë¨ ì°¸ì—¬")
        
        if not improvement_plans:
            improvement_plans = ["í˜„ì¬ ìƒíƒœ ìœ ì§€ë¥¼ ìœ„í•œ ì •ê¸°ì  ë©´ë‹´ ë° í”¼ë“œë°±"]
        
        # ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
        monitoring = [
            "- ì›” 1íšŒ ì •ê¸° ë©´ë‹´ì„ í†µí•œ ìƒíƒœ ì ê²€",
            "- ì—ì´ì „íŠ¸ë³„ ì ìˆ˜ ë³€í™” ì¶”ì´ ëª¨ë‹ˆí„°ë§",
            "- ì§ë¬´ ë§Œì¡±ë„ ë° ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ ì •ê¸° ì¡°ì‚¬"
        ]
        
        return {
            'comprehensive_analysis': comprehensive,
            'risk_factors': '\n'.join(risk_factors),
            'improvement_plans': '\n'.join(improvement_plans),
            'monitoring_points': '\n'.join(monitoring)
        }
    
    def generate_employee_report(self, employee_id: str, use_llm: bool = True) -> Dict[str, Any]:
        """ê°œë³„ ì§ì› ë ˆí¬íŠ¸ ìƒì„±"""
        if employee_id not in self.agent_scores:
            return {'error': f'ì§ì› ID {employee_id}ì˜ ì ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        # ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
        employee_info = {}
        if self.employee_data is not None:
            employee_row = self.employee_data[self.employee_data['employee_id'] == employee_id]
            if not employee_row.empty:
                employee_info = employee_row.iloc[0].to_dict()
        
        # ì ìˆ˜ ë¶„ì„
        scores = self.agent_scores[employee_id]
        agent_analysis = self.analyze_agent_scores(scores)
        integrated_risk = self.calculate_integrated_risk(scores)
        recommendations = self.generate_recommendations(agent_analysis, integrated_risk)
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        llm_insights = self.generate_llm_insights(employee_id, agent_analysis, integrated_risk, use_llm)
        
        # ë ˆí¬íŠ¸ ìƒì„±
        report = {
            'employee_id': employee_id,
            'employee_info': employee_info,
            'analysis_date': datetime.now().isoformat(),
            'agent_scores': scores,
            'agent_analysis': agent_analysis,
            'integrated_risk': integrated_risk,
            'recommendations': recommendations,
            'llm_insights': llm_insights,
            'summary': {
                'total_agents': len(scores),
                'high_risk_agents': len([a for a in agent_analysis.values() if a['risk_code'] == 'HIGH']),
                'medium_risk_agents': len([a for a in agent_analysis.values() if a['risk_code'] == 'MEDIUM']),
                'low_risk_agents': len([a for a in agent_analysis.values() if a['risk_code'] == 'LOW']),
                'llm_enabled': use_llm and self.client is not None
            }
        }
        
        return report
    
    def generate_text_report(self, employee_id: str, use_llm: bool = True) -> str:
        """í…ìŠ¤íŠ¸ í˜•íƒœì˜ ë ˆí¬íŠ¸ ìƒì„±"""
        report_data = self.generate_employee_report(employee_id, use_llm)
        
        if 'error' in report_data:
            return f"âŒ ë ˆí¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {report_data['error']}"
        
        # í…ìŠ¤íŠ¸ ë ˆí¬íŠ¸ êµ¬ì„±
        text_report = []
        
        # í—¤ë”
        text_report.append("=" * 80)
        text_report.append("ğŸ¢ ì§ì› í‡´ì‚¬ ìœ„í—˜ë„ ë¶„ì„ ë ˆí¬íŠ¸")
        text_report.append("=" * 80)
        text_report.append(f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {report_data['analysis_date'][:19]}")
        text_report.append(f"ğŸ‘¤ ì§ì› ID: {employee_id}")
        
        # ê¸°ë³¸ ì •ë³´
        if report_data['employee_info']:
            text_report.append("\nğŸ“‹ ì§ì› ê¸°ë³¸ ì •ë³´")
            text_report.append("-" * 40)
            for key, value in report_data['employee_info'].items():
                if key != 'employee_id':
                    text_report.append(f"   {key}: {value}")
        
        # í†µí•© ìœ„í—˜ë„
        integrated = report_data['integrated_risk']
        text_report.append(f"\nğŸ¯ í†µí•© ìœ„í—˜ë„ ë¶„ì„")
        text_report.append("-" * 40)
        text_report.append(f"   {integrated['emoji']} ìœ„í—˜ë„: {integrated['risk_level']}")
        text_report.append(f"   ğŸ“Š í†µí•© ì ìˆ˜: {integrated['integrated_score']}")
        text_report.append(f"   ğŸ² ì‹ ë¢°ë„: {integrated['confidence']:.1%}")
        
        # ì—ì´ì „íŠ¸ë³„ ë¶„ì„
        text_report.append(f"\nğŸ” ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ë¶„ì„")
        text_report.append("-" * 40)
        
        for agent, analysis in report_data['agent_analysis'].items():
            text_report.append(f"\n   {analysis['emoji']} {analysis['name']}")
            text_report.append(f"      ì ìˆ˜: {analysis['score']:.3f} ({analysis['risk_level']})")
            text_report.append(f"      ì„¤ëª…: {analysis['description']}")
            
            if analysis['indicators']:
                text_report.append("      âš ï¸ ìœ„í—˜ ì§€í‘œ:")
                for indicator in analysis['indicators']:
                    text_report.append(f"         â€¢ {indicator}")
        
        # LLM ì¸ì‚¬ì´íŠ¸ (ìˆëŠ” ê²½ìš°)
        if 'llm_insights' in report_data and report_data['summary'].get('llm_enabled', False):
            insights = report_data['llm_insights']
            text_report.append(f"\nğŸ¤– AI ì‹¬ì¸µ ë¶„ì„")
            text_report.append("=" * 40)
            
            text_report.append(f"\nğŸ“‹ ì¢…í•© ë¶„ì„:")
            text_report.append(f"   {insights.get('comprehensive_analysis', 'N/A')}")
            
            text_report.append(f"\nâš ï¸ ì£¼ìš” ìœ„í—˜ ìš”ì¸:")
            for line in insights.get('risk_factors', '').split('\n'):
                if line.strip():
                    text_report.append(f"   {line}")
            
            text_report.append(f"\nğŸ’¡ ê°œì„  ë°©ì•ˆ:")
            for line in insights.get('improvement_plans', '').split('\n'):
                if line.strip():
                    text_report.append(f"   {line}")
            
            text_report.append(f"\nğŸ“Š ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸:")
            for line in insights.get('monitoring_points', '').split('\n'):
                if line.strip():
                    text_report.append(f"   {line}")
        
        # ê¶Œì¥ì‚¬í•­
        text_report.append(f"\nğŸ’¡ ê¸°ë³¸ ê¶Œì¥ì‚¬í•­")
        text_report.append("-" * 40)
        for i, recommendation in enumerate(report_data['recommendations'], 1):
            text_report.append(f"   {i}. {recommendation}")
        
        # ìš”ì•½ í†µê³„
        summary = report_data['summary']
        text_report.append(f"\nğŸ“Š ë¶„ì„ ìš”ì•½")
        text_report.append("-" * 40)
        text_report.append(f"   ì „ì²´ ì—ì´ì „íŠ¸ ìˆ˜: {summary['total_agents']}")
        text_report.append(f"   ğŸ”´ ê³ ìœ„í—˜ ì—ì´ì „íŠ¸: {summary['high_risk_agents']}")
        text_report.append(f"   ğŸŸ¡ ì£¼ì˜ ì—ì´ì „íŠ¸: {summary['medium_risk_agents']}")
        text_report.append(f"   ğŸŸ¢ ì•ˆì „ ì—ì´ì „íŠ¸: {summary['low_risk_agents']}")
        text_report.append(f"   ğŸ¤– AI ë¶„ì„ ì‚¬ìš©: {'ì˜ˆ' if summary.get('llm_enabled', False) else 'ì•„ë‹ˆì˜¤'}")
        
        text_report.append("\n" + "=" * 80)
        
        return "\n".join(text_report)
    
    def save_report(self, employee_id: str, output_dir: str = "reports", 
                   format_type: str = "both") -> Dict[str, str]:
        """ë ˆí¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        saved_files = {}
        
        try:
            if format_type in ["json", "both"]:
                # JSON í˜•íƒœ ì €ì¥
                report_data = self.generate_employee_report(employee_id)
                json_file = os.path.join(output_dir, f"report_{employee_id}_{timestamp}.json")
                
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(report_data, f, ensure_ascii=False, indent=2, default=str)
                
                saved_files['json'] = json_file
            
            if format_type in ["text", "both"]:
                # í…ìŠ¤íŠ¸ í˜•íƒœ ì €ì¥
                text_report = self.generate_text_report(employee_id)
                text_file = os.path.join(output_dir, f"report_{employee_id}_{timestamp}.txt")
                
                with open(text_file, 'w', encoding='utf-8') as f:
                    f.write(text_report)
                
                saved_files['text'] = text_file
            
            return saved_files
            
        except Exception as e:
            return {'error': f'íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}'}
    
    def generate_comprehensive_report(self, employee_id, comprehensive_report, agent_data, 
                                     employee_info, analysis_summary, visualization_files):
        """ì €ì¥ëœ íŒŒì¼ ë°ì´í„°ë¡œë¶€í„° ì¢…í•© ë³´ê³ ì„œ ìƒì„± (XAI, ì›ì¸ ë¶„ì„, LLM ì¸ì‚¬ì´íŠ¸ í¬í•¨)"""
        try:
            import os
            import openai
            
            # 1. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            overall_assessment = comprehensive_report.get('comprehensive_assessment', {})
            risk_score = overall_assessment.get('overall_risk_score', 0)
            risk_level = overall_assessment.get('overall_risk_level', 'UNKNOWN')
            risk_indicator = overall_assessment.get('risk_indicator', 'â“')
            confidence = overall_assessment.get('confidence_level', 'LOW')
            
            # ìœ„í—˜ë„ ë ˆë²¨ í•œê¸€ ë³€í™˜
            risk_level_kr = {
                'HIGH': 'ğŸ”´ ê³ ìœ„í—˜êµ°',
                'MEDIUM': 'ğŸŸ¡ ì£¼ì˜êµ°',
                'LOW': 'ğŸŸ¢ ì•ˆì „êµ°',
                'UNKNOWN': 'â“ ë¯¸ë¶„ë¥˜'
            }.get(risk_level, 'â“ ë¯¸ë¶„ë¥˜')
            
            # ì§ì› ê¸°ë³¸ ì •ë³´
            emp_data = employee_info.get('employee_data', {})
            department = emp_data.get('Department', 'ë¯¸ë¶„ë¥˜')
            job_role = emp_data.get('JobRole', 'ë¯¸ë¶„ë¥˜')
            age = emp_data.get('Age', 'N/A')
            years_at_company = emp_data.get('YearsAtCompany', 'N/A')
            job_satisfaction = emp_data.get('JobSatisfaction', 'N/A')
            work_life_balance = emp_data.get('WorkLifeBalance', 'N/A')
            
            # 2. ì—ì´ì „íŠ¸ë³„ ì ìˆ˜ ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
            agent_scores = self._extract_agent_scores(comprehensive_report, agent_data)
            
            # 3. XAI ë¶„ì„
            xai_analysis = self._analyze_xai(agent_data, employee_id)
            
            # 4. ê·¼ë³¸ ì›ì¸ ë¶„ì„
            root_cause = self._analyze_root_cause(agent_data, employee_info, department, job_role)
            
            # 5. GPT-5-Nano LLM ì¸ì‚¬ì´íŠ¸ ìƒì„±
            llm_insights = self._generate_gpt5_nano_insights(
                employee_id, department, job_role, age, years_at_company,
                job_satisfaction, work_life_balance, agent_scores, 
                risk_level, risk_score, xai_analysis, root_cause
            )
            
            # 6. ë³´ê³ ì„œ ìƒì„±
            rule_based_interpretation = comprehensive_report.get('rule_based_interpretation', '')
            
            report = self._format_comprehensive_report(
                employee_id=employee_id,
                department=department,
                job_role=job_role,
                age=age,
                years_at_company=years_at_company,
                job_satisfaction=job_satisfaction,
                work_life_balance=work_life_balance,
                risk_indicator=risk_indicator,
                risk_level_kr=risk_level_kr,
                risk_score=risk_score,
                confidence=confidence,
                agent_scores=agent_scores,
                rule_based_interpretation=rule_based_interpretation,
                xai_analysis=xai_analysis,
                root_cause=root_cause,
                llm_insights=llm_insights,
                visualization_files=visualization_files,
                comprehensive_report=comprehensive_report
            )
            
            return report
            
        except Exception as e:
            import traceback
            logger.error(f"ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            logger.error(traceback.format_exc())
            return f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _extract_agent_scores(self, comprehensive_report, agent_data):
        """ì—ì´ì „íŠ¸ë³„ ì ìˆ˜ ì¶”ì¶œ"""
        worker_contributions = comprehensive_report.get('worker_contributions', {})
        scores = {}
        
        # Structura
        if 'structura' in worker_contributions:
            scores['structura'] = worker_contributions['structura'].get('score', 0)
        elif 'structura' in agent_data and 'prediction' in agent_data['structura']:
            scores['structura'] = agent_data['structura']['prediction'].get('attrition_probability', 0)
        else:
            scores['structura'] = 0
        
        # Chronos
        if 'chronos' in worker_contributions:
            scores['chronos'] = worker_contributions['chronos'].get('score', 0)
        elif 'chronos' in agent_data and 'prediction' in agent_data['chronos']:
            scores['chronos'] = agent_data['chronos']['prediction'].get('risk_score', 0)
        else:
            scores['chronos'] = 0
        
        # Cognita
        if 'cognita' in worker_contributions:
            scores['cognita'] = worker_contributions['cognita'].get('score', 0)
        elif 'cognita' in agent_data and 'risk_analysis' in agent_data['cognita']:
            scores['cognita'] = agent_data['cognita']['risk_analysis'].get('overall_risk_score', 0)
        else:
            scores['cognita'] = 0
        
        # Sentio
        if 'sentio' in worker_contributions:
            scores['sentio'] = worker_contributions['sentio'].get('score', 0)
        elif 'sentio' in agent_data:
            sentio_data = agent_data['sentio']
            scores['sentio'] = sentio_data.get('psychological_risk_score',
                                             sentio_data.get('risk_score', 0))
        else:
            scores['sentio'] = 0
        
        # Agora
        if 'agora' in worker_contributions:
            scores['agora'] = worker_contributions['agora'].get('score', 0)
        elif 'agora' in agent_data:
            agora_data = agent_data['agora']
            if 'market_analysis' in agora_data:
                scores['agora'] = agora_data['market_analysis'].get('risk_score', 0)
            else:
                scores['agora'] = agora_data.get('agora_score', 0)
        else:
            scores['agora'] = 0
        
        return scores
    
    def _analyze_xai(self, agent_data, employee_id):
        """XAI ë¶„ì„ (Structura, Chronos)"""
        xai_summary = ""
        
        # Structura XAI
        if 'structura' in agent_data and 'explanation' in agent_data['structura']:
            explanation = agent_data['structura']['explanation']
            xai_summary += "ğŸ“Š **Structura XAI ë¶„ì„:**\n"
            
            if 'feature_importance' in explanation:
                xai_summary += "  ì£¼ìš” ì˜í–¥ ë³€ìˆ˜:\n"
                for feat in explanation['feature_importance'][:5]:
                    xai_summary += f"    - {feat.get('feature', 'N/A')}: {feat.get('importance', 0):.3f}\n"
            
            if 'individual_explanation' in explanation:
                ind_exp = explanation['individual_explanation']
                if 'top_risk_factors' in ind_exp:
                    xai_summary += "  ì£¼ìš” ìœ„í—˜ ìš”ì¸:\n"
                    for factor in ind_exp['top_risk_factors'][:3]:
                        xai_summary += f"    - {factor.get('factor', 'N/A')}\n"
            
            xai_summary += "\n"
        
        return xai_summary.strip() if xai_summary else "XAI ë°ì´í„°ê°€ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    def _analyze_root_cause(self, agent_data, employee_info, department, job_role):
        """ê·¼ë³¸ ì›ì¸ ë¶„ì„ (Sentio, Agora, Cognita)"""
        root_cause = ""
        
        # Sentio
        if 'sentio' in agent_data:
            sentio_data = agent_data['sentio']
            root_cause += "ğŸ§  **Sentio ì‹¬ë¦¬Â·ê°ì • ë¶„ì„:**\n"
            if 'sentiment_analysis' in sentio_data:
                sentiment = sentio_data['sentiment_analysis']
                root_cause += f"  ê°ì • ìƒíƒœ: {sentiment.get('sentiment_label', 'N/A')}\n"
            if 'jd_r_analysis' in sentio_data:
                jdr = sentio_data['jd_r_analysis']
                root_cause += f"  ì§ë¬´ ìš”êµ¬/ìì› ê· í˜•: {jdr.get('balance_status', 'N/A')}\n"
            root_cause += "\n"
        
        # Agora
        if 'agora' in agent_data:
            agora_data = agent_data['agora']
            root_cause += "ğŸŒ **Agora ì‹œì¥ ë¶„ì„:**\n"
            if 'market_analysis' in agora_data:
                market = agora_data['market_analysis']
                root_cause += f"  ì‹œì¥ ì••ë ¥: {market.get('market_pressure_index', 0):.3f}\n"
                root_cause += f"  ë³´ìƒ ê²©ì°¨: {market.get('compensation_gap', 0):.3f}\n"
            root_cause += "\n"
        
        return root_cause.strip() if root_cause else "ì›ì¸ ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
    
    def _generate_gpt5_nano_insights(self, employee_id, department, job_role, age, years_at_company,
                                    job_satisfaction, work_life_balance, agent_scores, 
                                    risk_level, risk_score, xai_analysis, root_cause):
        """GPT-5-Nanoë¥¼ ì‚¬ìš©í•œ LLM ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            import os
            import openai
            
            if not os.getenv('OPENAI_API_KEY'):
                return ""
            
            client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            
            prompt = f"""ì§ì› {employee_id}ì˜ í‡´ì‚¬ ìœ„í—˜ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.

**ê¸°ë³¸ ì •ë³´:**
- ë¶€ì„œ: {department}, ì§ë¬´: {job_role}
- ë‚˜ì´: {age}ì„¸, ì¬ì§: {years_at_company}ë…„
- ë§Œì¡±ë„: {job_satisfaction}/4, ì›Œë¼ë°¸: {work_life_balance}/4

**AI ì—ì´ì „íŠ¸ ë¶„ì„:**
- Structura: {agent_scores.get('structura', 0):.1%}
- Chronos: {agent_scores.get('chronos', 0):.1%}
- Cognita: {agent_scores.get('cognita', 0):.1%}
- Sentio: {agent_scores.get('sentio', 0):.1%}
- Agora: {agent_scores.get('agora', 0):.1%}

**XAI ë¶„ì„:** {xai_analysis}
**ì›ì¸ ë¶„ì„:** {root_cause}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ìœ„í—˜ ìš”ì¸ 3ê°€ì§€ì™€ êµ¬ì²´ì  ì„¤ëª…
2. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ 3ê°€ì§€
3. ì¥ê¸°ì  ê´€ë¦¬ ì „ëµ 2ê°€ì§€"""

            response = client.responses.create(
                model="gpt-5-nano-2025-08-07",
                input=prompt,
                reasoning={"effort": "medium"},
                text={"verbosity": "medium"}
            )
            
            return "\n\nğŸ¤– LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (GPT-5-Nano)\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n" + response.output_text
            
        except Exception as e:
            logger.error(f"LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""
    
    def _format_comprehensive_report(self, **kwargs):
        """ì¢…í•© ë³´ê³ ì„œ í¬ë§·íŒ…"""
        return f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
         ğŸ“Š ì§ì› í‡´ì‚¬ ìœ„í—˜ë„ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ ê¸°ë³¸ ì •ë³´
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ ì§ì› ID        : {kwargs['employee_id']}
â€¢ ì†Œì† ë¶€ì„œ      : {kwargs['department']}
â€¢ ì§ë¬´           : {kwargs['job_role']}
â€¢ ë‚˜ì´           : {kwargs['age']}ì„¸
â€¢ ì¬ì§ ê¸°ê°„      : {kwargs['years_at_company']}ë…„
â€¢ ì§ë¬´ ë§Œì¡±ë„    : {kwargs['job_satisfaction']}/4
â€¢ ì›Œë¼ë°¸         : {kwargs['work_life_balance']}/4

ğŸ¯ ì¢…í•© ìœ„í—˜ë„ í‰ê°€
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{kwargs['risk_indicator']} ìœ„í—˜ë„ ë“±ê¸‰  : {kwargs['risk_level_kr']}
ğŸ“Š ì¢…í•© ìœ„í—˜ ì ìˆ˜ : {kwargs['risk_score']:.3f} / 1.0 ({kwargs['risk_score']*100:.1f}%)
ğŸ² ì‹ ë¢°ë„ ìˆ˜ì¤€    : {kwargs['confidence']}

ğŸ“ˆ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ë¶„ì„ ê²°ê³¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¢ Structura: {kwargs['agent_scores']['structura']:.3f} ({kwargs['agent_scores']['structura']*100:.1f}%)
â° Chronos: {kwargs['agent_scores']['chronos']:.3f} ({kwargs['agent_scores']['chronos']*100:.1f}%)
ğŸ”— Cognita: {kwargs['agent_scores']['cognita']:.3f} ({kwargs['agent_scores']['cognita']*100:.1f}%)
ğŸ§  Sentio: {kwargs['agent_scores']['sentio']:.3f} ({kwargs['agent_scores']['sentio']*100:.1f}%)
ğŸŒ Agora: {kwargs['agent_scores']['agora']:.3f} ({kwargs['agent_scores']['agora']*100:.1f}%)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ AI ë¶„ì„ ì¸ì‚¬ì´íŠ¸
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{kwargs['rule_based_interpretation']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” XAI ì„¤ëª… ê°€ëŠ¥í•œ AI ë¶„ì„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{kwargs['xai_analysis']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ ê·¼ë³¸ ì›ì¸ ë¶„ì„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{kwargs['root_cause']}
{kwargs['llm_insights']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š ì‹œê°í™” ìë£Œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{"â€¢ ì´ " + str(len(kwargs['visualization_files'])) + "ê°œì˜ ì‹œê°í™” ì°¨íŠ¸" if kwargs['visualization_files'] else "â€¢ ì‹œê°í™” ìë£Œ ì—†ìŒ"}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“… ë³´ê³ ì„œ ìƒì„±: {kwargs['comprehensive_report'].get('analysis_timestamp', 'N/A')}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
    
    def generate_llm_based_report(self, employee_id, department, risk_level, risk_score, 
                                 agent_scores, agent_data, employee_info):
        """LLM ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„±)"""
        # ReportGeneratorì˜ ê¸°ì¡´ ë©”ì„œë“œ í™œìš©
        return self.generate_text_report(employee_id, use_llm=True)
    
    def generate_batch_reports(self, employee_ids: List[str], output_dir: str = "reports") -> Dict[str, Any]:
        """ì—¬ëŸ¬ ì§ì›ì˜ ë ˆí¬íŠ¸ë¥¼ ì¼ê´„ ìƒì„±"""
        results = {
            'success': [],
            'failed': [],
            'total': len(employee_ids),
            'output_directory': output_dir
        }
        
        for employee_id in employee_ids:
            try:
                saved_files = self.save_report(employee_id, output_dir, "both")
                
                if 'error' in saved_files:
                    results['failed'].append({
                        'employee_id': employee_id,
                        'error': saved_files['error']
                    })
                else:
                    results['success'].append({
                        'employee_id': employee_id,
                        'files': saved_files
                    })
                    
            except Exception as e:
                results['failed'].append({
                    'employee_id': employee_id,
                    'error': str(e)
                })
        
        return results


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë ˆí¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” (API í‚¤ ì—†ì´ í…ŒìŠ¤íŠ¸)
    generator = ReportGenerator()
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    sample_scores = {
        'agora_score': 0.75,
        'chronos_score': 0.45,
        'cognita_score': 0.82,
        'sentio_score': 0.65,
        'structura_score': 0.38
    }
    
    generator.set_agent_scores('EMP001', sample_scores)
    
    # í…ìŠ¤íŠ¸ ë ˆí¬íŠ¸ ìƒì„± (LLM ì—†ì´)
    text_report = generator.generate_text_report('EMP001', use_llm=False)
    print(text_report)
    
    # íŒŒì¼ë¡œ ì €ì¥
    saved_files = generator.save_report('EMP001')
    print(f"\nì €ì¥ëœ íŒŒì¼: {saved_files}")
        
    # LLM ì‚¬ìš© ì˜ˆì‹œ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
    print("\n" + "="*50)
    print("LLM ì‚¬ìš© ì˜ˆì‹œ:")
    print("generator = ReportGenerator(api_key='your-api-key')")
    print("llm_report = generator.generate_text_report('EMP001', use_llm=True)")
    print("="*50)
