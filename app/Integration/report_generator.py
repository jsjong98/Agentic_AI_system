"""
LLM ê¸°ë°˜ í‡´ì‚¬ ë ˆí¬íŠ¸ ìƒì„±ê¸°
ê° ì§ì›ë³„ë¡œ ì¢…í•©ì ì¸ í‡´ì‚¬ ìœ„í—˜ë„ ë¶„ì„ ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import json
import openai
import time
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
import os
from dotenv import load_dotenv

logger = logging.getLogger(__name__)


class ReportGenerator:
    """LLM ê¸°ë°˜ í‡´ì‚¬ ë ˆí¬íŠ¸ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str = None):
        self.employee_data = None
        self.agent_scores = {}
        self.risk_thresholds = {
            'low': 0.3,
            'medium': 0.7,
            'high': 1.0
        }
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (Sentio/Agoraì™€ ë™ì¼í•œ ë°©ì‹)
        self.client = None
        self.model = "gpt-5-nano-2025-08-07"  # GPT-5-nano ëª¨ë¸ ì‚¬ìš©
        
        if api_key:
            try:
                self.client = openai.OpenAI(api_key=api_key)
                logger.info(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸: {self.model}")
            except Exception as e:
                logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.client = None
        else:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ (Sentio/Agoraì™€ ë™ì¼)
            load_dotenv()
            env_api_key = os.getenv("OPENAI_API_KEY")
            if not env_api_key:
                logger.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
                self.client = None
            else:
                try:
                    self.client = openai.OpenAI(api_key=env_api_key)
                    logger.info(f"âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ ì™„ë£Œ - ëª¨ë¸: {self.model}")
                except Exception as e:
                    logger.error(f"í™˜ê²½ë³€ìˆ˜ API í‚¤ë¡œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    self.client = None
        
        # ì—ì´ì „íŠ¸ë³„ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸
        self.agent_contexts = {
            'agora_score': {
                'name': 'Agora (ì—…ë¬´ ì„±ê³¼)',
                'description': 'ì—…ë¬´ ì„±ê³¼ ë° ìƒì‚°ì„± ë¶„ì„',
                'focus_areas': ['ì—…ë¬´ ì„±ê³¼', 'ëª©í‘œ ë‹¬ì„±', 'ìƒì‚°ì„±', 'ì—…ë¬´ íš¨ìœ¨ì„±'],
                'high_risk_indicators': ['ë‚®ì€ ì—…ë¬´ ì„±ê³¼', 'ìƒì‚°ì„± ì €í•˜', 'ëª©í‘œ ë‹¬ì„±ë¥  ë¶€ì¡±', 'ì—…ë¬´ í’ˆì§ˆ ë¬¸ì œ']
            },
            'chronos_score': {
                'name': 'Chronos (ì‹œê³„ì—´ íŒ¨í„´)',
                'description': 'ê·¼ë¬´ íŒ¨í„´ ë° ì‹œê°„ ê´€ë¦¬ ë¶„ì„',
                'focus_areas': ['ê·¼ë¬´ íŒ¨í„´', 'ì¶œí‡´ê·¼ ì‹œê°„', 'ì•¼ê·¼ ë¹ˆë„', 'íœ´ê°€ ì‚¬ìš©'],
                'high_risk_indicators': ['ë¶ˆê·œì¹™í•œ ê·¼ë¬´ íŒ¨í„´', 'ì¦ì€ ì§€ê°', 'ì´ˆê³¼ ê·¼ë¬´ ì¦ê°€', 'íœ´ê°€ ë¯¸ì‚¬ìš©']
            },
            'cognita_score': {
                'name': 'Cognita (ê´€ê³„ ë„¤íŠ¸ì›Œí¬)',
                'description': 'ë™ë£Œì™€ì˜ ê´€ê³„ ë° ë„¤íŠ¸ì›Œí¬ ë¶„ì„',
                'focus_areas': ['íŒ€ì›Œí¬', 'ì˜ì‚¬ì†Œí†µ', 'í˜‘ì—…', 'ì‚¬íšŒì  ê´€ê³„'],
                'high_risk_indicators': ['ì‚¬íšŒì  ê³ ë¦½', 'íŒ€ì›Œí¬ ë¶€ì¡±', 'ì˜ì‚¬ì†Œí†µ ë¬¸ì œ', 'ê°ˆë“± ìƒí™©']
            },
            'sentio_score': {
                'name': 'Sentio (ê°ì • ë¶„ì„)',
                'description': 'ê°ì • ìƒíƒœ ë° ë§Œì¡±ë„ ë¶„ì„',
                'focus_areas': ['ì§ë¬´ ë§Œì¡±ë„', 'ê°ì • ìƒíƒœ', 'ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€', 'ë™ê¸°ë¶€ì—¬'],
                'high_risk_indicators': ['ë¶€ì •ì  ê°ì • ì¦ê°€', 'ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ ìƒìŠ¹', 'ì§ë¬´ ë¶ˆë§Œì¡±', 'ë™ê¸°ë¶€ì—¬ ì €í•˜']
            },
            'structura_score': {
                'name': 'Structura (êµ¬ì¡°ì  ìš”ì¸)',
                'description': 'ì¡°ì§ êµ¬ì¡° ë° í™˜ê²½ì  ìš”ì¸ ë¶„ì„',
                'focus_areas': ['ì¡°ì§ ì ì‘', 'ì—­í•  ëª…í™•ì„±', 'ìŠ¹ì§„ ê¸°íšŒ', 'ì¡°ì§ ë¬¸í™”'],
                'high_risk_indicators': ['ì¡°ì§ ì ì‘ ì–´ë ¤ì›€', 'ì—­í•  ëª¨í˜¸ì„±', 'ìŠ¹ì§„ ê¸°íšŒ ë¶€ì¡±', 'ì¡°ì§ ë¬¸í™” ë¶€ì ì‘']
            }
        }
        
    def load_employee_data(self, data_path: str) -> bool:
        """ì§ì› ë°ì´í„° ë¡œë“œ"""
        try:
            if data_path.endswith('.csv'):
                self.employee_data = pd.read_csv(data_path)
            elif data_path.endswith('.json'):
                with open(data_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.employee_data = pd.DataFrame(data)
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” JSON íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            
            print(f"âœ… ì§ì› ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.employee_data)}ëª…")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def set_agent_scores(self, employee_id: str, scores: Dict[str, float]):
        """íŠ¹ì • ì§ì›ì˜ ì—ì´ì „íŠ¸ ì ìˆ˜ ì„¤ì •"""
        self.agent_scores[employee_id] = scores
    
    def get_risk_level(self, score: float) -> tuple:
        """ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„í—˜ë„ ë ˆë²¨ ê²°ì •"""
        if score < self.risk_thresholds['low']:
            return "ì•ˆì „êµ°", "LOW", "ğŸŸ¢"
        elif score < self.risk_thresholds['medium']:
            return "ì£¼ì˜êµ°", "MEDIUM", "ğŸŸ¡"
        else:
            return "ê³ ìœ„í—˜êµ°", "HIGH", "ğŸ”´"
    
    def analyze_agent_scores(self, scores: Dict[str, float]) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ë³„ ì ìˆ˜ ë¶„ì„"""
        analysis = {}
        
        for agent, score in scores.items():
            if agent in self.agent_contexts:
                risk_level, risk_code, emoji = self.get_risk_level(score)
                context = self.agent_contexts[agent]
                
                analysis[agent] = {
                    'score': score,
                    'risk_level': risk_level,
                    'risk_code': risk_code,
                    'emoji': emoji,
                    'name': context['name'],
                    'description': context['description'],
                    'focus_areas': context['focus_areas'],
                    'indicators': context['high_risk_indicators'] if score >= self.risk_thresholds['medium'] else []
                }
        
        return analysis
    
    def calculate_integrated_risk(self, scores: Dict[str, float]) -> Dict[str, Any]:
        """í†µí•© ìœ„í—˜ë„ ê³„ì‚°"""
        if not scores:
            return {'integrated_score': 0, 'risk_level': 'ì•ˆì „êµ°', 'confidence': 0}
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ëª¨ë“  ì—ì´ì „íŠ¸ ë™ì¼ ê°€ì¤‘ì¹˜)
        integrated_score = np.mean(list(scores.values()))
        risk_level, risk_code, emoji = self.get_risk_level(integrated_score)
        
        # ì‹ ë¢°ë„ ê³„ì‚° (ì ìˆ˜ ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„)
        score_variance = np.var(list(scores.values()))
        confidence = max(0, 1 - score_variance)  # ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
        
        return {
            'integrated_score': round(integrated_score, 3),
            'risk_level': risk_level,
            'risk_code': risk_code,
            'emoji': emoji,
            'confidence': round(confidence, 3),
            'score_variance': round(score_variance, 3)
        }
    
    def generate_recommendations(self, analysis: Dict[str, Any], integrated_risk: Dict[str, Any]) -> List[str]:
        """ë§ì¶¤í˜• ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        risk_code = integrated_risk['risk_code']
        
        if risk_code == 'HIGH':
            recommendations.append("ğŸš¨ ì¦‰ì‹œ ê°œì…ì´ í•„ìš”í•œ ê³ ìœ„í—˜ ì§ì›ì…ë‹ˆë‹¤.")
            recommendations.append("ğŸ“ ìƒê¸‰ìì™€ì˜ ê¸´ê¸‰ ë©´ë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
        elif risk_code == 'MEDIUM':
            recommendations.append("âš ï¸ ì£¼ì˜ ê¹Šì€ ê´€ì°°ê³¼ ì§€ì›ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            recommendations.append("ğŸ“‹ ì •ê¸°ì ì¸ 1:1 ë¯¸íŒ…ì„ í†µí•œ ìƒíƒœ ì ê²€ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        # ì—ì´ì „íŠ¸ë³„ êµ¬ì²´ì  ê¶Œì¥ì‚¬í•­
        high_risk_agents = [agent for agent, data in analysis.items() 
                          if data['risk_code'] == 'HIGH']
        
        if 'agora_score' in high_risk_agents:
            recommendations.append("ğŸ“ˆ ì—…ë¬´ ì„±ê³¼ ê°œì„ ì„ ìœ„í•œ êµìœ¡ ë° ë©˜í† ë§ í”„ë¡œê·¸ë¨ ì°¸ì—¬")
            recommendations.append("ğŸ¯ ëª…í™•í•œ ëª©í‘œ ì„¤ì • ë° ì„±ê³¼ ê´€ë¦¬ ì‹œìŠ¤í…œ ë„ì…")
        
        if 'chronos_score' in high_risk_agents:
            recommendations.append("â° ê·¼ë¬´ íŒ¨í„´ ì •ìƒí™”ë¥¼ ìœ„í•œ ì‹œê°„ ê´€ë¦¬ êµìœ¡")
            recommendations.append("ğŸ  ìœ ì—° ê·¼ë¬´ì œ ë˜ëŠ” ì¬íƒê·¼ë¬´ ì˜µì…˜ ê²€í† ")
        
        if 'cognita_score' in high_risk_agents:
            recommendations.append("ğŸ‘¥ íŒ€ ë¹Œë”© í™œë™ ë° ì‚¬íšŒì  ë„¤íŠ¸ì›Œí¬ êµ¬ì¶• ì§€ì›")
            recommendations.append("ğŸ¤ ë©˜í† -ë©˜í‹° í”„ë¡œê·¸ë¨ ì°¸ì—¬ ê¶Œì¥")
        
        if 'sentio_score' in high_risk_agents:
            recommendations.append("ğŸ’š ì‹¬ë¦¬ ìƒë‹´ ë° ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ í”„ë¡œê·¸ë¨ ì œê³µ")
            recommendations.append("ğŸ˜Š ì§ë¬´ ë§Œì¡±ë„ í–¥ìƒì„ ìœ„í•œ ì—…ë¬´ ì¡°ì • ê²€í† ")
        
        if 'structura_score' in high_risk_agents:
            recommendations.append("ğŸ¢ ì¡°ì§ ë‚´ ì—­í•  ëª…í™•í™” ë° ì»¤ë¦¬ì–´ íŒ¨ìŠ¤ ì œì‹œ")
            recommendations.append("ğŸ“š ì—­ëŸ‰ ê°œë°œ ê¸°íšŒ ë° ìŠ¹ì§„ ê²½ë¡œ ì•ˆë‚´")
        
        if not recommendations:
            recommendations.append("âœ… í˜„ì¬ ì•ˆì •ì ì¸ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            recommendations.append("ğŸ“Š ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì§€ì†ì  ê´€ë¦¬ ê¶Œì¥")
        
        return recommendations
    
    def generate_llm_insights(self, employee_id: str, analysis: Dict[str, Any], 
                             integrated_risk: Dict[str, Any], use_llm: bool = True) -> Dict[str, str]:
        """LLMì„ ì‚¬ìš©í•œ ì‹¬ì¸µ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        
        if not use_llm or not self.client:
            return self._generate_rule_based_insights(analysis, integrated_risk)
        
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_analysis_prompt(employee_id, analysis, integrated_risk)
            
            # Sentio/Agoraì™€ ë™ì¼í•œ OpenAI API í˜¸ì¶œ ë°©ì‹ ì‚¬ìš©
            response = self.client.responses.create(
                model=self.model,
                input=prompt,
                reasoning={"effort": "medium"},
                text={"verbosity": "medium"}
            )
            
            llm_response = response.output_text.strip()
            
            # ì‘ë‹µ í’ˆì§ˆ ê²€ì¦
            if len(llm_response) < 30:
                logger.warning(f"âš ï¸ API ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë°±ì—… í•´ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return self._generate_rule_based_insights(analysis, integrated_risk)
            
            # ì‘ë‹µì„ ì„¹ì…˜ë³„ë¡œ ë¶„ë¦¬
            insights = self._parse_llm_response(llm_response)
            
            # API í˜¸ì¶œ ì œí•œ ê³ ë ¤
            time.sleep(0.1)
            
            logger.info(f"LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {employee_id}")
            return insights
            
        except Exception as e:
            logger.error(f"API í˜¸ì¶œ ì˜¤ë¥˜ (ì§ì› ë¶„ì„ ì¤‘): {str(e)}")
            # API ì‹¤íŒ¨ ì‹œ ë°±ì—… í•´ì„ ì‚¬ìš©
            return self._generate_rule_based_insights(analysis, integrated_risk)
    
    def _build_analysis_prompt(self, employee_id: str, analysis: Dict[str, Any], 
                              integrated_risk: Dict[str, Any]) -> str:
        """Sentio/Agora ìŠ¤íƒ€ì¼ì˜ ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # ìœ„í—˜ë„ ë ˆë²¨ íŒì •
        risk_score = integrated_risk['integrated_score']
        if risk_score > 0.7:
            risk_level = "ê³ ìœ„í—˜"
            risk_context = "ì¦‰ê°ì ì¸ ê°œì…ì´ í•„ìš”í•œ ìƒí™©"
        elif risk_score > 0.5:
            risk_level = "ì ì¬ìœ„í—˜"
            risk_context = "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•œ ìƒí™©"
        elif risk_score > 0.3:
            risk_level = "ì¤‘ê°„ìœ„í—˜"
            risk_context = "ì˜ˆë°©ì  ê´€ë¦¬ê°€ ê¶Œì¥ë˜ëŠ” ìƒí™©"
        else:
            risk_level = "ì €ìœ„í—˜"
            risk_context = "í˜„ì¬ ìƒíƒœ ìœ ì§€ê°€ ë°”ëŒì§í•œ ìƒí™©"
        
        # ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì •ë³´ êµ¬ì„±
        agent_details = []
        for agent, data in analysis.items():
            agent_details.append(f"- {data['name']}: {data['score']:.4f} ({data['risk_level']})")
            if data['indicators']:
                agent_details.append(f"  ì£¼ìš” ì§€í‘œ: {', '.join(data['indicators'][:3])}")
        
        prompt = f"""
ë‹¹ì‹ ì€ ì¡°ì§ ë‚´ ê°œì¸ì˜ ì‹¬ë¦¬ì™€ ê°ì •ì„ ê¹Šì´ ì´í•´í•˜ëŠ” HR ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ í†µí•œ ì¢…í•©ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì§ì›ì˜ í‡´ì‚¬ ìœ„í—˜ë„ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ í•´ì„ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

**ë¶„ì„ ê²°ê³¼:**
- ì§ì› ID: {employee_id}
- ì¢…í•© ìœ„í—˜ ì ìˆ˜: {risk_score:.4f} (0~1 ì²™ë„)
- ìœ„í—˜ ë“±ê¸‰: {risk_level} ({risk_context})
- ë¶„ì„ ì‹ ë¢°ë„: {integrated_risk['confidence']:.1%}

**ì—ì´ì „íŠ¸ë³„ ì„¸ë¶€ ë¶„ì„:**
{chr(10).join(agent_details)}

**ìš”ì²­ì‚¬í•­:**
1. í˜„ì¬ ìƒíƒœë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”
2. ì£¼ìš” ìœ„í—˜ ìš”ì¸ì´ë‚˜ ê¸ì •ì  ìš”ì¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”  
3. ì‹¤ë¬´ì§„ì´ë‚˜ ê´€ë¦¬ìê°€ ì·¨í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¡°ì¹˜ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”
4. ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  í•µì‹¬ ì§€í‘œë“¤ì„ ì œì‹œí•´ì£¼ì„¸ìš”
5. ì „ì²´ ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”:

## ì¢…í•© ë¶„ì„
[í˜„ì¬ ì§ì›ì˜ ì „ë°˜ì ì¸ ìƒí™© ë¶„ì„]

## ì£¼ìš” ìœ„í—˜ ìš”ì¸
[ê°€ì¥ ì¤‘ìš”í•œ ìœ„í—˜ ìš”ì¸ë“¤ê³¼ ê·¸ ì›ì¸ ë¶„ì„]

## ê°œì„  ë°©ì•ˆ
[êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆë“¤]

## ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
[ì§€ì†ì ìœ¼ë¡œ ê´€ì°°í•´ì•¼ í•  ì§€í‘œë“¤ê³¼ ì˜ˆìƒ ê²°ê³¼]

í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ê³ , ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤ìš©ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        return prompt.strip()
    
    def _parse_llm_response(self, response: str) -> Dict[str, str]:
        """LLM ì‘ë‹µì„ ì„¹ì…˜ë³„ë¡œ íŒŒì‹±"""
        
        sections = {
            'comprehensive_analysis': '',
            'risk_factors': '',
            'improvement_plans': '',
            'monitoring_points': ''
        }
        
        current_section = None
        lines = response.split('\n')
        
        for line in lines:
            line = line.strip()
            
            if '## ì¢…í•© ë¶„ì„' in line or 'ì¢…í•©ë¶„ì„' in line:
                current_section = 'comprehensive_analysis'
            elif '## ì£¼ìš” ìœ„í—˜ ìš”ì¸' in line or 'ìœ„í—˜ ìš”ì¸' in line or 'ìœ„í—˜ìš”ì¸' in line:
                current_section = 'risk_factors'
            elif '## ê°œì„  ë°©ì•ˆ' in line or 'ê°œì„ ë°©ì•ˆ' in line or 'í•´ê²°ë°©ì•ˆ' in line:
                current_section = 'improvement_plans'
            elif '## ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸' in line or 'ëª¨ë‹ˆí„°ë§' in line:
                current_section = 'monitoring_points'
            elif current_section and line and not line.startswith('##'):
                sections[current_section] += line + '\n'
        
        # ë¹ˆ ì„¹ì…˜ ì²˜ë¦¬
        for key, value in sections.items():
            sections[key] = value.strip() if value.strip() else "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        return sections
    
    def _generate_rule_based_insights(self, analysis: Dict[str, Any], 
                                    integrated_risk: Dict[str, Any]) -> Dict[str, str]:
        """ê·œì¹™ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„± (LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ëŒ€ì²´)"""
        
        risk_code = integrated_risk['risk_code']
        high_risk_agents = [agent for agent, data in analysis.items() if data['risk_code'] == 'HIGH']
        medium_risk_agents = [agent for agent, data in analysis.items() if data['risk_code'] == 'MEDIUM']
        
        # ì¢…í•© ë¶„ì„
        if risk_code == 'HIGH':
            comprehensive = "í˜„ì¬ ì§ì›ì€ ë†’ì€ í‡´ì‚¬ ìœ„í—˜ë„ë¥¼ ë³´ì´ê³  ìˆì–´ ì¦‰ì‹œ ê°œì…ì´ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤."
        elif risk_code == 'MEDIUM':
            comprehensive = "ì£¼ì˜ê°€ í•„ìš”í•œ ìƒí™©ìœ¼ë¡œ, ì˜ˆë°©ì  ì°¨ì›ì˜ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            comprehensive = "í˜„ì¬ ì•ˆì •ì ì¸ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆìœ¼ë‚˜ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        # ìœ„í—˜ ìš”ì¸
        risk_factors = []
        for agent in high_risk_agents:
            if agent in analysis:
                context = self.agent_contexts.get(agent, {})
                risk_factors.append(f"- {context.get('name', agent)}: {context.get('description', '')}")
        
        if not risk_factors:
            risk_factors = ["í˜„ì¬ íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì¸ì€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]
        
        # ê°œì„  ë°©ì•ˆ
        improvement_plans = []
        if 'agora_score' in high_risk_agents:
            improvement_plans.append("- ì—…ë¬´ ì„±ê³¼ í–¥ìƒì„ ìœ„í•œ êµìœ¡ ë° ë©˜í† ë§ í”„ë¡œê·¸ë¨ ì œê³µ")
        if 'sentio_score' in high_risk_agents:
            improvement_plans.append("- ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ë° ì‹¬ë¦¬ ìƒë‹´ í”„ë¡œê·¸ë¨ ì œê³µ")
        if 'cognita_score' in high_risk_agents:
            improvement_plans.append("- íŒ€ ë¹Œë”© ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê°œì„  í”„ë¡œê·¸ë¨ ì°¸ì—¬")
        
        if not improvement_plans:
            improvement_plans = ["í˜„ì¬ ìƒíƒœ ìœ ì§€ë¥¼ ìœ„í•œ ì •ê¸°ì  ë©´ë‹´ ë° í”¼ë“œë°±"]
        
        # ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
        monitoring = [
            "- ì›” 1íšŒ ì •ê¸° ë©´ë‹´ì„ í†µí•œ ìƒíƒœ ì ê²€",
            "- ì—ì´ì „íŠ¸ë³„ ì ìˆ˜ ë³€í™” ì¶”ì´ ëª¨ë‹ˆí„°ë§",
            "- ì§ë¬´ ë§Œì¡±ë„ ë° ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ ì •ê¸° ì¡°ì‚¬"
        ]
        
        return {
            'comprehensive_analysis': comprehensive,
            'risk_factors': '\n'.join(risk_factors),
            'improvement_plans': '\n'.join(improvement_plans),
            'monitoring_points': '\n'.join(monitoring)
        }
    
    def generate_employee_report(self, employee_id: str, use_llm: bool = True) -> Dict[str, Any]:
        """ê°œë³„ ì§ì› ë ˆí¬íŠ¸ ìƒì„±"""
        if employee_id not in self.agent_scores:
            return {'error': f'ì§ì› ID {employee_id}ì˜ ì ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        # ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
        employee_info = {}
        if self.employee_data is not None:
            employee_row = self.employee_data[self.employee_data['employee_id'] == employee_id]
            if not employee_row.empty:
                employee_info = employee_row.iloc[0].to_dict()
        
        # ì ìˆ˜ ë¶„ì„
        scores = self.agent_scores[employee_id]
        agent_analysis = self.analyze_agent_scores(scores)
        integrated_risk = self.calculate_integrated_risk(scores)
        recommendations = self.generate_recommendations(agent_analysis, integrated_risk)
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        llm_insights = self.generate_llm_insights(employee_id, agent_analysis, integrated_risk, use_llm)
        
        # ë ˆí¬íŠ¸ ìƒì„±
        report = {
            'employee_id': employee_id,
            'employee_info': employee_info,
            'analysis_date': datetime.now().isoformat(),
            'agent_scores': scores,
            'agent_analysis': agent_analysis,
            'integrated_risk': integrated_risk,
            'recommendations': recommendations,
            'llm_insights': llm_insights,
            'summary': {
                'total_agents': len(scores),
                'high_risk_agents': len([a for a in agent_analysis.values() if a['risk_code'] == 'HIGH']),
                'medium_risk_agents': len([a for a in agent_analysis.values() if a['risk_code'] == 'MEDIUM']),
                'low_risk_agents': len([a for a in agent_analysis.values() if a['risk_code'] == 'LOW']),
                'llm_enabled': use_llm and self.client is not None
            }
        }
        
        return report
    
    def generate_text_report(self, employee_id: str, use_llm: bool = True) -> str:
        """í…ìŠ¤íŠ¸ í˜•íƒœì˜ ë ˆí¬íŠ¸ ìƒì„±"""
        report_data = self.generate_employee_report(employee_id, use_llm)
        
        if 'error' in report_data:
            return f"âŒ ë ˆí¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {report_data['error']}"
        
        # í…ìŠ¤íŠ¸ ë ˆí¬íŠ¸ êµ¬ì„±
        text_report = []
        
        # í—¤ë”
        text_report.append("=" * 80)
        text_report.append("ğŸ¢ ì§ì› í‡´ì‚¬ ìœ„í—˜ë„ ë¶„ì„ ë ˆí¬íŠ¸")
        text_report.append("=" * 80)
        text_report.append(f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {report_data['analysis_date'][:19]}")
        text_report.append(f"ğŸ‘¤ ì§ì› ID: {employee_id}")
        
        # ê¸°ë³¸ ì •ë³´
        if report_data['employee_info']:
            text_report.append("\nğŸ“‹ ì§ì› ê¸°ë³¸ ì •ë³´")
            text_report.append("-" * 40)
            for key, value in report_data['employee_info'].items():
                if key != 'employee_id':
                    text_report.append(f"   {key}: {value}")
        
        # í†µí•© ìœ„í—˜ë„
        integrated = report_data['integrated_risk']
        text_report.append(f"\nğŸ¯ í†µí•© ìœ„í—˜ë„ ë¶„ì„")
        text_report.append("-" * 40)
        text_report.append(f"   {integrated['emoji']} ìœ„í—˜ë„: {integrated['risk_level']}")
        text_report.append(f"   ğŸ“Š í†µí•© ì ìˆ˜: {integrated['integrated_score']}")
        text_report.append(f"   ğŸ² ì‹ ë¢°ë„: {integrated['confidence']:.1%}")
        
        # ì—ì´ì „íŠ¸ë³„ ë¶„ì„
        text_report.append(f"\nğŸ” ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ë¶„ì„")
        text_report.append("-" * 40)
        
        for agent, analysis in report_data['agent_analysis'].items():
            text_report.append(f"\n   {analysis['emoji']} {analysis['name']}")
            text_report.append(f"      ì ìˆ˜: {analysis['score']:.3f} ({analysis['risk_level']})")
            text_report.append(f"      ì„¤ëª…: {analysis['description']}")
            
            if analysis['indicators']:
                text_report.append("      âš ï¸ ìœ„í—˜ ì§€í‘œ:")
                for indicator in analysis['indicators']:
                    text_report.append(f"         â€¢ {indicator}")
        
        # LLM ì¸ì‚¬ì´íŠ¸ (ìˆëŠ” ê²½ìš°)
        if 'llm_insights' in report_data and report_data['summary'].get('llm_enabled', False):
            insights = report_data['llm_insights']
            text_report.append(f"\nğŸ¤– AI ì‹¬ì¸µ ë¶„ì„")
            text_report.append("=" * 40)
            
            text_report.append(f"\nğŸ“‹ ì¢…í•© ë¶„ì„:")
            text_report.append(f"   {insights.get('comprehensive_analysis', 'N/A')}")
            
            text_report.append(f"\nâš ï¸ ì£¼ìš” ìœ„í—˜ ìš”ì¸:")
            for line in insights.get('risk_factors', '').split('\n'):
                if line.strip():
                    text_report.append(f"   {line}")
            
            text_report.append(f"\nğŸ’¡ ê°œì„  ë°©ì•ˆ:")
            for line in insights.get('improvement_plans', '').split('\n'):
                if line.strip():
                    text_report.append(f"   {line}")
            
            text_report.append(f"\nğŸ“Š ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸:")
            for line in insights.get('monitoring_points', '').split('\n'):
                if line.strip():
                    text_report.append(f"   {line}")
        
        # ê¶Œì¥ì‚¬í•­
        text_report.append(f"\nğŸ’¡ ê¸°ë³¸ ê¶Œì¥ì‚¬í•­")
        text_report.append("-" * 40)
        for i, recommendation in enumerate(report_data['recommendations'], 1):
            text_report.append(f"   {i}. {recommendation}")
        
        # ìš”ì•½ í†µê³„
        summary = report_data['summary']
        text_report.append(f"\nğŸ“Š ë¶„ì„ ìš”ì•½")
        text_report.append("-" * 40)
        text_report.append(f"   ì „ì²´ ì—ì´ì „íŠ¸ ìˆ˜: {summary['total_agents']}")
        text_report.append(f"   ğŸ”´ ê³ ìœ„í—˜ ì—ì´ì „íŠ¸: {summary['high_risk_agents']}")
        text_report.append(f"   ğŸŸ¡ ì£¼ì˜ ì—ì´ì „íŠ¸: {summary['medium_risk_agents']}")
        text_report.append(f"   ğŸŸ¢ ì•ˆì „ ì—ì´ì „íŠ¸: {summary['low_risk_agents']}")
        text_report.append(f"   ğŸ¤– AI ë¶„ì„ ì‚¬ìš©: {'ì˜ˆ' if summary.get('llm_enabled', False) else 'ì•„ë‹ˆì˜¤'}")
        
        text_report.append("\n" + "=" * 80)
        
        return "\n".join(text_report)
    
    def save_report(self, employee_id: str, output_dir: str = "reports", 
                   format_type: str = "both") -> Dict[str, str]:
        """ë ˆí¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        saved_files = {}
        
        try:
            if format_type in ["json", "both"]:
                # JSON í˜•íƒœ ì €ì¥
                report_data = self.generate_employee_report(employee_id)
                json_file = os.path.join(output_dir, f"report_{employee_id}_{timestamp}.json")
                
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(report_data, f, ensure_ascii=False, indent=2, default=str)
                
                saved_files['json'] = json_file
            
            if format_type in ["text", "both"]:
                # í…ìŠ¤íŠ¸ í˜•íƒœ ì €ì¥
                text_report = self.generate_text_report(employee_id)
                text_file = os.path.join(output_dir, f"report_{employee_id}_{timestamp}.txt")
                
                with open(text_file, 'w', encoding='utf-8') as f:
                    f.write(text_report)
                
                saved_files['text'] = text_file
            
            return saved_files
            
        except Exception as e:
            return {'error': f'íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}'}
    
    def generate_batch_reports(self, employee_ids: List[str], output_dir: str = "reports") -> Dict[str, Any]:
        """ì—¬ëŸ¬ ì§ì›ì˜ ë ˆí¬íŠ¸ë¥¼ ì¼ê´„ ìƒì„±"""
        results = {
            'success': [],
            'failed': [],
            'total': len(employee_ids),
            'output_directory': output_dir
        }
        
        for employee_id in employee_ids:
            try:
                saved_files = self.save_report(employee_id, output_dir, "both")
                
                if 'error' in saved_files:
                    results['failed'].append({
                        'employee_id': employee_id,
                        'error': saved_files['error']
                    })
                else:
                    results['success'].append({
                        'employee_id': employee_id,
                        'files': saved_files
                    })
                    
            except Exception as e:
                results['failed'].append({
                    'employee_id': employee_id,
                    'error': str(e)
                })
        
        return results


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë ˆí¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” (API í‚¤ ì—†ì´ í…ŒìŠ¤íŠ¸)
    generator = ReportGenerator()
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    sample_scores = {
        'agora_score': 0.75,
        'chronos_score': 0.45,
        'cognita_score': 0.82,
        'sentio_score': 0.65,
        'structura_score': 0.38
    }
    
    generator.set_agent_scores('EMP001', sample_scores)
    
    # í…ìŠ¤íŠ¸ ë ˆí¬íŠ¸ ìƒì„± (LLM ì—†ì´)
    text_report = generator.generate_text_report('EMP001', use_llm=False)
    print(text_report)
    
    # íŒŒì¼ë¡œ ì €ì¥
    saved_files = generator.save_report('EMP001')
    print(f"\nì €ì¥ëœ íŒŒì¼: {saved_files}")
        
    # LLM ì‚¬ìš© ì˜ˆì‹œ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
    print("\n" + "="*50)
    print("LLM ì‚¬ìš© ì˜ˆì‹œ:")
    print("generator = ReportGenerator(api_key='your-api-key')")
    print("llm_report = generator.generate_text_report('EMP001', use_llm=True)")
    print("="*50)
