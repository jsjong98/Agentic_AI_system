"""
Integration Flask ë°±ì—”ë“œ
ì„ê³„ê°’ ì„¤ì •, ê°€ì¤‘ì¹˜ ìµœì í™” ë° LLM ê¸°ë°˜ ë ˆí¬íŠ¸ ìƒì„± API ì„œë²„
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename
import pandas as pd
import numpy as np
import os
import json
from datetime import datetime
import traceback
from typing import Dict, List, Any
from dotenv import load_dotenv

from threshold_calculator import ThresholdCalculator, load_and_process_data
from weight_optimizer import WeightOptimizer
from report_generator import ReportGenerator

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (Sentio/Agoraì™€ ë™ì¼)
load_dotenv()

app = Flask(__name__)
CORS(app)

# ì „ì—­ ë³€ìˆ˜
threshold_calculator = ThresholdCalculator()
weight_optimizer = WeightOptimizer()
report_generator = ReportGenerator()  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ API í‚¤ ë¡œë“œ ì‹œë„
current_data = None
current_results = {}

# ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'data')
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), 'outputs')

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(OUTPUT_DIR, exist_ok=True)


@app.route('/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'healthy',
        'service': 'Integration',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0',
        'llm_enabled': report_generator.client is not None
    })


@app.route('/set_api_key', methods=['POST'])
def set_api_key():
    """OpenAI API í‚¤ ì„¤ì •"""
    try:
        data = request.get_json()
        api_key = data.get('api_key')
        
        if not api_key:
            return jsonify({
                'success': False,
                'error': 'API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        # ìƒˆë¡œìš´ ReportGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        global report_generator
        report_generator = ReportGenerator(api_key=api_key)
        
        return jsonify({
            'success': True,
            'message': 'API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'llm_enabled': report_generator.client is not None
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/load_data', methods=['POST'])
def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    global current_data
    
    try:
        data = request.get_json()
        file_path = data.get('file_path', 'Total_score.csv')
        
        # ì ˆëŒ€ ê²½ë¡œ ìƒì„±
        if not os.path.isabs(file_path):
            file_path = os.path.join(DATA_DIR, file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                'success': False,
                'error': f'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}'
            }), 404
        
        # ë°ì´í„° ë¡œë“œ
        current_data, score_columns = load_and_process_data(file_path)
        
        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        stats = {
            'total_rows': len(current_data),
            'total_columns': len(current_data.columns),
            'score_columns': score_columns,
            'attrition_distribution': current_data['attrition'].value_counts().to_dict() if 'attrition' in current_data.columns else {},
            'missing_values': current_data.isnull().sum().to_dict()
        }
        
        return jsonify({
            'success': True,
            'message': 'ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'file_path': file_path,
            'statistics': stats
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/calculate_thresholds', methods=['POST'])
def calculate_thresholds():
    """ì„ê³„ê°’ ê³„ì‚°"""
    global current_data, current_results
    
    try:
        if current_data is None:
            return jsonify({
                'success': False,
                'error': 'ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. /load_dataë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.'
            }), 400
        
        data = request.get_json()
        score_columns = data.get('score_columns', None)
        
        # Score ì»¬ëŸ¼ ìë™ ê°ì§€
        if score_columns is None:
            score_columns = [col for col in current_data.columns if col.endswith('_score')]
        
        if not score_columns:
            return jsonify({
                'success': False,
                'error': 'Score ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }), 400
        
        # ì„ê³„ê°’ ê³„ì‚°
        results = threshold_calculator.calculate_thresholds_for_scores(current_data, score_columns)
        
        # ìš”ì•½ í…Œì´ë¸” ìƒì„±
        summary_df = threshold_calculator.get_summary_table()
        thresholds_dict = threshold_calculator.get_thresholds_dict()
        
        # ì˜ˆì¸¡ ì»¬ëŸ¼ ì¶”ê°€
        data_with_predictions = threshold_calculator.apply_thresholds_to_data(current_data, score_columns)
        
        # ê²°ê³¼ ì €ì¥
        current_results['threshold_results'] = results
        current_results['threshold_summary'] = summary_df.to_dict('records')
        current_results['thresholds_dict'] = thresholds_dict
        current_results['data_with_predictions'] = data_with_predictions
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ìš”ì•½ ê²°ê³¼ ì €ì¥
        summary_file = os.path.join(OUTPUT_DIR, f'threshold_summary_{timestamp}.csv')
        summary_df.to_csv(summary_file, index=False, encoding='utf-8')
        
        # ì˜ˆì¸¡ ë°ì´í„° ì €ì¥
        predictions_file = os.path.join(OUTPUT_DIR, f'data_with_predictions_{timestamp}.csv')
        data_with_predictions.to_csv(predictions_file, index=False, encoding='utf-8')
        
        return jsonify({
            'success': True,
            'message': 'ì„ê³„ê°’ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'results': {
                'summary': current_results['threshold_summary'],
                'thresholds': thresholds_dict,
                'best_score': summary_df.loc[summary_df['F1_Score'].idxmax()].to_dict(),
                'total_predictions': len(data_with_predictions)
            },
            'files': {
                'summary': summary_file,
                'predictions': predictions_file
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ì„ê³„ê°’ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/optimize_weights', methods=['POST'])
def optimize_weights():
    """ê°€ì¤‘ì¹˜ ìµœì í™”"""
    global current_data, current_results
    
    try:
        if current_data is None:
            return jsonify({
                'success': False,
                'error': 'ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. /load_dataë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.'
            }), 400
        
        # ì˜ˆì¸¡ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        data_to_use = current_results.get('data_with_predictions', current_data)
        prediction_cols = [col for col in data_to_use.columns if col.endswith('_prediction')]
        
        if not prediction_cols:
            return jsonify({
                'success': False,
                'error': 'ì˜ˆì¸¡ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. /calculate_thresholdsë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.'
            }), 400
        
        data = request.get_json()
        method = data.get('method', 'bayesian')  # 'grid', 'bayesian', 'scipy'
        
        # ë°©ë²•ë³„ íŒŒë¼ë¯¸í„°
        method_params = {}
        if method == 'grid':
            method_params['n_points_per_dim'] = data.get('n_points_per_dim', 5)
        elif method == 'bayesian':
            method_params['n_calls'] = data.get('n_calls', 100)
        
        # ê°€ì¤‘ì¹˜ ìµœì í™” ì‹¤í–‰
        optimization_results = weight_optimizer.optimize_weights(
            data_to_use, method=method, **method_params
        )
        
        if not optimization_results.get('best_weights'):
            return jsonify({
                'success': False,
                'error': 'ê°€ì¤‘ì¹˜ ìµœì í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                'details': optimization_results.get('error', 'Unknown error')
            }), 500
        
        # ìµœì  ê°€ì¤‘ì¹˜ ì ìš©
        data_with_weighted = weight_optimizer.apply_optimal_weights(data_to_use)
        data_with_risk = weight_optimizer.classify_risk_level(data_with_weighted)
        
        # ì„±ëŠ¥ ìš”ì•½
        performance_summary = weight_optimizer.get_performance_summary(data_with_risk)
        
        # ê²°ê³¼ ì €ì¥
        current_results['weight_optimization'] = optimization_results
        current_results['final_data'] = data_with_risk
        current_results['performance_summary'] = performance_summary
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ìµœì¢… ë°ì´í„° ì €ì¥
        final_data_file = os.path.join(OUTPUT_DIR, f'final_weighted_predictions_{timestamp}.csv')
        data_with_risk.to_csv(final_data_file, index=False, encoding='utf-8')
        
        # ê°€ì¤‘ì¹˜ ì •ë³´ ì €ì¥
        weights_info = pd.DataFrame([
            {'Variable': col, 'Weight': weight} 
            for col, weight in optimization_results['best_weights'].items()
        ])
        weights_info['Method'] = method
        weights_info['F1_Score'] = optimization_results['best_f1']
        weights_info['Threshold'] = optimization_results['best_threshold']
        
        weights_file = os.path.join(OUTPUT_DIR, f'optimal_weights_{timestamp}.csv')
        weights_info.to_csv(weights_file, index=False, encoding='utf-8')
        
        # ìœ„í—˜ë„ ê¸°ì¤€ ì •ë³´ ì €ì¥
        risk_criteria = pd.DataFrame([
            {'Risk_Level': 'ì•ˆì „êµ°', 'Score_Range': '0.0 ~ 0.3', 'Numeric_Code': 1},
            {'Risk_Level': 'ì£¼ì˜êµ°', 'Score_Range': '0.3 ~ 0.7', 'Numeric_Code': 2},
            {'Risk_Level': 'ê³ ìœ„í—˜êµ°', 'Score_Range': '0.7 ~ 1.0', 'Numeric_Code': 3}
        ])
        
        risk_criteria_file = os.path.join(OUTPUT_DIR, f'risk_criteria_{timestamp}.csv')
        risk_criteria.to_csv(risk_criteria_file, index=False, encoding='utf-8')
        
        return jsonify({
            'success': True,
            'message': 'ê°€ì¤‘ì¹˜ ìµœì í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'results': {
                'method': method,
                'optimal_weights': optimization_results['best_weights'],
                'optimal_threshold': optimization_results['best_threshold'],
                'best_f1_score': optimization_results['best_f1'],
                'performance_metrics': performance_summary['performance_metrics'],
                'risk_statistics': performance_summary['risk_statistics'],
                'total_records': len(data_with_risk)
            },
            'files': {
                'final_data': final_data_file,
                'weights_info': weights_file,
                'risk_criteria': risk_criteria_file
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ê°€ì¤‘ì¹˜ ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/predict_employee', methods=['POST'])
def predict_employee():
    """ê°œë³„ ì§ì› ì˜ˆì¸¡"""
    try:
        data = request.get_json()
        employee_scores = data.get('scores', {})
        
        if not employee_scores:
            return jsonify({
                'success': False,
                'error': 'ì§ì› ì ìˆ˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        results = {}
        
        # ì„ê³„ê°’ ê¸°ë°˜ ì˜ˆì¸¡
        if threshold_calculator.optimal_thresholds:
            threshold_predictions = threshold_calculator.predict_attrition(employee_scores)
            results['threshold_predictions'] = threshold_predictions
        
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì˜ˆì¸¡
        if weight_optimizer.optimal_weights:
            # ì˜ˆì¸¡ ì»¬ëŸ¼ ìƒì„± (ì„ê³„ê°’ ê¸°ë°˜)
            prediction_data = {}
            for score_name, score_value in employee_scores.items():
                if score_name in threshold_calculator.optimal_thresholds:
                    threshold = threshold_calculator.optimal_thresholds[score_name]
                    prediction_col = f"{score_name}_prediction"
                    prediction_data[prediction_col] = 1 if score_value >= threshold else 0
            
            if prediction_data:
                # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
                weighted_score = sum(
                    prediction_data[col] * weight 
                    for col, weight in weight_optimizer.optimal_weights.items()
                    if col in prediction_data
                )
                
                # ìµœì¢… ì˜ˆì¸¡
                final_prediction = 1 if weighted_score >= weight_optimizer.optimal_threshold else 0
                
                # ìœ„í—˜ë„ ë¶„ë¥˜
                if weighted_score < 0.3:
                    risk_level = 'ì•ˆì „êµ°'
                    risk_numeric = 1
                elif weighted_score < 0.7:
                    risk_level = 'ì£¼ì˜êµ°'
                    risk_numeric = 2
                else:
                    risk_level = 'ê³ ìœ„í—˜êµ°'
                    risk_numeric = 3
                
                results['weighted_prediction'] = {
                    'weighted_score': weighted_score,
                    'final_prediction': final_prediction,
                    'prediction_label': 'ìœ„í—˜' if final_prediction == 1 else 'ì•ˆì „',
                    'risk_level': risk_level,
                    'risk_numeric': risk_numeric,
                    'threshold_used': weight_optimizer.optimal_threshold
                }
        
        if not results:
            return jsonify({
                'success': False,
                'error': 'ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì„ê³„ê°’ ê³„ì‚° ë° ê°€ì¤‘ì¹˜ ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.'
            }), 400
        
        return jsonify({
            'success': True,
            'employee_scores': employee_scores,
            'predictions': results
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/get_results', methods=['GET'])
def get_results():
    """í˜„ì¬ ê²°ê³¼ ì¡°íšŒ"""
    try:
        if not current_results:
            return jsonify({
                'success': False,
                'error': 'ê³„ì‚°ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'
            }), 404
        
        # ë¯¼ê°í•œ ë°ì´í„° ì œì™¸í•˜ê³  ìš”ì•½ ì •ë³´ë§Œ ë°˜í™˜
        summary = {
            'has_threshold_results': 'threshold_results' in current_results,
            'has_weight_optimization': 'weight_optimization' in current_results,
            'has_final_data': 'final_data' in current_results
        }
        
        if 'threshold_summary' in current_results:
            summary['threshold_summary'] = current_results['threshold_summary']
            summary['thresholds_dict'] = current_results['thresholds_dict']
        
        if 'performance_summary' in current_results:
            summary['performance_summary'] = current_results['performance_summary']
        
        return jsonify({
            'success': True,
            'results': summary
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/compare_methods', methods=['POST'])
def compare_methods():
    """ì—¬ëŸ¬ ìµœì í™” ë°©ë²• ë¹„êµ"""
    global current_data, current_results
    
    try:
        if current_data is None:
            return jsonify({
                'success': False,
                'error': 'ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            }), 400
        
        data_to_use = current_results.get('data_with_predictions', current_data)
        prediction_cols = [col for col in data_to_use.columns if col.endswith('_prediction')]
        
        if not prediction_cols:
            return jsonify({
                'success': False,
                'error': 'ì˜ˆì¸¡ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. /calculate_thresholdsë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.'
            }), 400
        
        data = request.get_json()
        methods = data.get('methods', ['grid', 'scipy'])  # bayesianì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ
        
        comparison_results = []
        
        for method in methods:
            try:
                print(f"=== {method} ë°©ë²• í…ŒìŠ¤íŠ¸ ì¤‘ ===")
                
                # ìƒˆë¡œìš´ optimizer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                temp_optimizer = WeightOptimizer()
                
                # ë°©ë²•ë³„ íŒŒë¼ë¯¸í„° ì„¤ì •
                method_params = {}
                if method == 'grid':
                    method_params['n_points_per_dim'] = 3  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¤„ì„
                elif method == 'bayesian':
                    method_params['n_calls'] = 50  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¤„ì„
                
                # ìµœì í™” ì‹¤í–‰
                result = temp_optimizer.optimize_weights(
                    data_to_use, method=method, **method_params
                )
                
                if result.get('best_weights'):
                    # ì„±ëŠ¥ í‰ê°€
                    data_temp = temp_optimizer.apply_optimal_weights(data_to_use)
                    performance = temp_optimizer.get_performance_summary(data_temp)
                    
                    comparison_results.append({
                        'method': method,
                        'best_weights': result['best_weights'],
                        'best_f1_score': result['best_f1'],
                        'best_threshold': result['best_threshold'],
                        'performance_metrics': performance['performance_metrics'],
                        'success': True
                    })
                else:
                    comparison_results.append({
                        'method': method,
                        'success': False,
                        'error': result.get('error', 'Unknown error')
                    })
                    
            except Exception as method_error:
                comparison_results.append({
                    'method': method,
                    'success': False,
                    'error': str(method_error)
                })
        
        # ìµœê³  ì„±ëŠ¥ ë°©ë²• ì°¾ê¸°
        successful_results = [r for r in comparison_results if r.get('success')]
        best_method = None
        
        if successful_results:
            best_method = max(successful_results, key=lambda x: x['best_f1_score'])
        
        return jsonify({
            'success': True,
            'message': 'ë°©ë²• ë¹„êµê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'comparison_results': comparison_results,
            'best_method': best_method,
            'total_methods_tested': len(methods),
            'successful_methods': len(successful_results)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ë°©ë²• ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/export_results', methods=['POST'])
def export_results():
    """ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"""
    try:
        if not current_results:
            return jsonify({
                'success': False,
                'error': 'ë‚´ë³´ë‚¼ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'
            }), 404
        
        data = request.get_json()
        export_format = data.get('format', 'csv')  # 'csv', 'json'
        include_data = data.get('include_data', True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        exported_files = []
        
        if export_format == 'csv':
            # ì„ê³„ê°’ ìš”ì•½
            if 'threshold_summary' in current_results:
                threshold_df = pd.DataFrame(current_results['threshold_summary'])
                threshold_file = os.path.join(OUTPUT_DIR, f'threshold_export_{timestamp}.csv')
                threshold_df.to_csv(threshold_file, index=False, encoding='utf-8')
                exported_files.append(threshold_file)
            
            # ìµœì¢… ë°ì´í„°
            if include_data and 'final_data' in current_results:
                final_data_file = os.path.join(OUTPUT_DIR, f'final_data_export_{timestamp}.csv')
                current_results['final_data'].to_csv(final_data_file, index=False, encoding='utf-8')
                exported_files.append(final_data_file)
        
        elif export_format == 'json':
            # JSON í˜•íƒœë¡œ ê²°ê³¼ ì €ì¥
            export_data = {
                'timestamp': timestamp,
                'threshold_results': current_results.get('threshold_summary', []),
                'thresholds_dict': current_results.get('thresholds_dict', {}),
                'performance_summary': current_results.get('performance_summary', {})
            }
            
            if include_data and 'final_data' in current_results:
                export_data['final_data'] = current_results['final_data'].to_dict('records')
            
            json_file = os.path.join(OUTPUT_DIR, f'results_export_{timestamp}.json')
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
            exported_files.append(json_file)
        
        return jsonify({
            'success': True,
            'message': 'ê²°ê³¼ê°€ ì„±ê³µì ìœ¼ë¡œ ë‚´ë³´ë‚´ì¡ŒìŠµë‹ˆë‹¤.',
            'exported_files': exported_files,
            'format': export_format,
            'timestamp': timestamp
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ê²°ê³¼ ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/generate_report', methods=['POST'])
def generate_report():
    """ê°œë³„ ì§ì› ë ˆí¬íŠ¸ ìƒì„±"""
    try:
        data = request.get_json()
        employee_id = data.get('employee_id')
        agent_scores = data.get('agent_scores', {})
        format_type = data.get('format', 'json')  # 'json', 'text', 'both'
        save_file = data.get('save_file', False)
        use_llm = data.get('use_llm', True)  # LLM ì‚¬ìš© ì—¬ë¶€
        
        if not employee_id:
            return jsonify({
                'success': False,
                'error': 'ì§ì› IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        if not agent_scores:
            return jsonify({
                'success': False,
                'error': 'ì—ì´ì „íŠ¸ ì ìˆ˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        # ì ìˆ˜ ì„¤ì •
        report_generator.set_agent_scores(employee_id, agent_scores)
        
        # ë ˆí¬íŠ¸ ìƒì„±
        if format_type == 'text':
            report_content = report_generator.generate_text_report(employee_id, use_llm)
            result = {
                'success': True,
                'employee_id': employee_id,
                'format': 'text',
                'report': report_content,
                'llm_used': use_llm and report_generator.client is not None
            }
        else:
            report_content = report_generator.generate_employee_report(employee_id, use_llm)
            result = {
                'success': True,
                'employee_id': employee_id,
                'format': 'json',
                'report': report_content,
                'llm_used': use_llm and report_generator.client is not None
            }
        
        # íŒŒì¼ ì €ì¥ ì˜µì…˜
        if save_file:
            saved_files = report_generator.save_report(
                employee_id, 
                os.path.join(OUTPUT_DIR, 'reports'), 
                format_type
            )
            
            if 'error' in saved_files:
                result['file_save_error'] = saved_files['error']
            else:
                result['saved_files'] = saved_files
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ë ˆí¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/generate_batch_reports', methods=['POST'])
def generate_batch_reports():
    """ì—¬ëŸ¬ ì§ì›ì˜ ë ˆí¬íŠ¸ ì¼ê´„ ìƒì„±"""
    try:
        data = request.get_json()
        employees_data = data.get('employees', [])  # [{'employee_id': 'EMP001', 'agent_scores': {...}}, ...]
        
        if not employees_data:
            return jsonify({
                'success': False,
                'error': 'ì§ì› ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        # ê° ì§ì›ì˜ ì ìˆ˜ ì„¤ì •
        employee_ids = []
        for emp_data in employees_data:
            employee_id = emp_data.get('employee_id')
            agent_scores = emp_data.get('agent_scores', {})
            
            if employee_id and agent_scores:
                report_generator.set_agent_scores(employee_id, agent_scores)
                employee_ids.append(employee_id)
        
        if not employee_ids:
            return jsonify({
                'success': False,
                'error': 'ìœ íš¨í•œ ì§ì› ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
            }), 400
        
        # ì¼ê´„ ë ˆí¬íŠ¸ ìƒì„±
        batch_results = report_generator.generate_batch_reports(
            employee_ids, 
            os.path.join(OUTPUT_DIR, 'reports')
        )
        
        return jsonify({
            'success': True,
            'message': 'ì¼ê´„ ë ˆí¬íŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'results': batch_results
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ì¼ê´„ ë ˆí¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/load_employee_data', methods=['POST'])
def load_employee_data():
    """ì§ì› ê¸°ë³¸ ë°ì´í„° ë¡œë“œ (ë ˆí¬íŠ¸ ìƒì„±ìš©)"""
    try:
        data = request.get_json()
        file_path = data.get('file_path')
        
        if not file_path:
            return jsonify({
                'success': False,
                'error': 'íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        # ì ˆëŒ€ ê²½ë¡œ ìƒì„±
        if not os.path.isabs(file_path):
            file_path = os.path.join(DATA_DIR, file_path)
        
        # ë°ì´í„° ë¡œë“œ
        success = report_generator.load_employee_data(file_path)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'ì§ì› ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'file_path': file_path,
                'total_employees': len(report_generator.employee_data) if report_generator.employee_data is not None else 0
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ì§ì› ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
            }), 500
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ì§ì› ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


@app.route('/upload/employee_data', methods=['POST'])
def upload_employee_data():
    """ì§ì› ë°ì´í„° CSV íŒŒì¼ ì—…ë¡œë“œ"""
    try:
        # íŒŒì¼ í™•ì¸
        if 'file' not in request.files:
            return jsonify({
                "success": False,
                "error": "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({
                "success": False,
                "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }), 400
        
        # íŒŒì¼ í™•ì¥ì í™•ì¸
        if not file.filename.lower().endswith('.csv'):
            return jsonify({
                "success": False,
                "error": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            }), 400
        
        # íŒŒì¼ ì €ì¥
        filename = secure_filename(file.filename)
        upload_dir = os.path.join(os.path.dirname(__file__), '..', 'uploads', 'Integration')
        os.makedirs(upload_dir, exist_ok=True)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥ (ê¸°ì¡´ íŒŒì¼ ë³´ì¡´)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = os.path.splitext(filename)[0]
        new_filename = f"{base_name}_{timestamp}.csv"
        file_path = os.path.join(upload_dir, new_filename)
        
        # ìµœì‹  íŒŒì¼ ë§í¬ë„ ìƒì„±
        latest_link = os.path.join(upload_dir, 'latest_employee_data.csv')
        file.save(file_path)
        
        # ìµœì‹  íŒŒì¼ ë§í¬ ìƒì„±
        try:
            if os.path.exists(latest_link):
                os.remove(latest_link)
            import shutil
            shutil.copy2(file_path, latest_link)
        except Exception as e:
            print(f"ìµœì‹  íŒŒì¼ ë§í¬ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ë°ì´í„° ê²€ì¦ ë° ë¡œë“œ
        try:
            df = pd.read_csv(file_path)
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_columns = ['employee_id']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                return jsonify({
                    "success": False,
                    "error": f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}",
                    "required_columns": required_columns,
                    "found_columns": list(df.columns)
                }), 400
            
            # ReportGeneratorì— ë°ì´í„° ë¡œë“œ
            success = report_generator.load_employee_data(file_path)
            
            if success:
                # ë°ì´í„° í†µê³„
                employee_stats = {
                    "total_employees": len(df),
                    "unique_employees": df['employee_id'].nunique(),
                    "columns": len(df.columns),
                    "column_names": list(df.columns)
                }
                
                # ë¶€ì„œë³„ í†µê³„ (ë¶€ì„œ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
                if 'Department' in df.columns:
                    employee_stats["departments"] = df['Department'].value_counts().to_dict()
                
                return jsonify({
                    "success": True,
                    "message": "ì§ì› ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ê³  ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "file_info": {
                        "original_filename": filename,
                        "saved_filename": new_filename,
                        "upload_path": upload_dir,
                        "file_path": file_path,
                        "latest_link": latest_link
                    },
                    "employee_stats": employee_stats,
                    "note": "ì´ì œ ì—ì´ì „íŠ¸ ì ìˆ˜ë¥¼ ì„¤ì •í•˜ê³  ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                })
            else:
                return jsonify({
                    "success": False,
                    "error": "ë°ì´í„° ì—…ë¡œë“œëŠ” ì„±ê³µí–ˆì§€ë§Œ ì‹œìŠ¤í…œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }), 500
                
        except Exception as e:
            return jsonify({
                "success": False,
                "error": f"ë°ì´í„° íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
            }), 400
            
    except Exception as e:
        return jsonify({
            "success": False,
            "error": f"íŒŒì¼ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}"
        }), 500


@app.route('/get_employee_list', methods=['GET'])
def get_employee_list():
    """ë¡œë“œëœ ì§ì› ëª©ë¡ ì¡°íšŒ"""
    try:
        if report_generator.employee_data is None:
            return jsonify({
                'success': False,
                'error': 'ì§ì› ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            }), 400
        
        # ì§ì› ëª©ë¡ ì¶”ì¶œ
        if 'employee_id' in report_generator.employee_data.columns:
            employee_list = report_generator.employee_data['employee_id'].tolist()
        else:
            # employee_id ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ì‚¬ìš©
            employee_list = report_generator.employee_data.index.tolist()
        
        return jsonify({
            'success': True,
            'total_employees': len(employee_list),
            'employee_ids': employee_list[:100],  # ì²˜ìŒ 100ëª…ë§Œ ë°˜í™˜
            'has_more': len(employee_list) > 100
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ì§ì› ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


if __name__ == '__main__':
    print("ğŸš€ Integration Flask ì„œë²„ ì‹œì‘")
    print(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}")
    print("ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:5007")
    
    # API í‚¤ ìƒíƒœ í™•ì¸ (Sentio/Agoraì™€ ë™ì¼)
    if report_generator.client:
        print("âœ… OpenAI API ì—°ê²° ì„±ê³µ - LLM ê¸°ë°˜ ë¶„ì„ ê°€ëŠ¥")
    else:
        print("âš ï¸  OpenAI API í‚¤ ì—†ìŒ - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ ë™ì‘")
        print("   ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ /set_api_key ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
    print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:")
    print("  GET  /health - ì„œë²„ ìƒíƒœ í™•ì¸")
    print("  POST /set_api_key - OpenAI API í‚¤ ì„¤ì •")
    print("  POST /load_data - ë°ì´í„° ë¡œë“œ")
    print("  POST /calculate_thresholds - ì„ê³„ê°’ ê³„ì‚°")
    print("  POST /optimize_weights - ê°€ì¤‘ì¹˜ ìµœì í™”")
    print("  POST /predict_employee - ê°œë³„ ì§ì› ì˜ˆì¸¡")
    print("  GET  /get_results - í˜„ì¬ ê²°ê³¼ ì¡°íšŒ")
    print("  POST /compare_methods - ìµœì í™” ë°©ë²• ë¹„êµ")
    print("  POST /export_results - ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
    print("  POST /load_employee_data - ì§ì› ê¸°ë³¸ ë°ì´í„° ë¡œë“œ")
    print("  GET  /get_employee_list - ì§ì› ëª©ë¡ ì¡°íšŒ")
    print("  POST /generate_report - ê°œë³„ ì§ì› ë ˆí¬íŠ¸ ìƒì„± (LLM ì§€ì›)")
    print("  POST /generate_batch_reports - ì¼ê´„ ë ˆí¬íŠ¸ ìƒì„±")
    
    app.run(host='0.0.0.0', port=5007, debug=True)
