#!/usr/bin/env python3
"""
Agentic AI System ì˜ì¡´ì„± ì„¤ì¹˜ ë° ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ëª¨ë“  í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  import í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import subprocess
import sys
import os
from pathlib import Path

def install_requirements():
    """requirements_agentic.txt íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì¡´ì„± ì„¤ì¹˜"""
    
    requirements_file = Path(__file__).parent / "requirements_agentic.txt"
    
    if not requirements_file.exists():
        print("âŒ requirements_agentic.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    print("ğŸš€ Agentic AI System ì˜ì¡´ì„± ì„¤ì¹˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“ Requirements íŒŒì¼: {requirements_file}")
    
    try:
        # pip install ì‹¤í–‰
        result = subprocess.run([
            sys.executable, "-m", "pip", "install", "-r", str(requirements_file)
        ], check=True, capture_output=True, text=True)
        
        print("âœ… ëª¨ë“  ì˜ì¡´ì„±ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"stdout: {e.stdout}")
        print(f"stderr: {e.stderr}")
        return False

def test_imports():
    """ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ§ª ë¼ì´ë¸ŒëŸ¬ë¦¬ import í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    test_modules = {
        # ê¸°ë³¸ ë°ì´í„° ì²˜ë¦¬
        'numpy': 'numpy',
        'pandas': 'pandas', 
        'scipy': 'scipy',
        
        # ë¨¸ì‹ ëŸ¬ë‹
        'scikit-learn': 'sklearn',
        'xgboost': 'xgboost',
        'torch': 'torch',
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        'optuna': 'optuna',
        
        # XAI
        'shap': 'shap',
        'lime': 'lime',
        
        # ë¶ˆê· í˜• ë°ì´í„°
        'imbalanced-learn': 'imblearn',
        
        # ê·¸ë˜í”„ DB
        'neo4j': 'neo4j',
        
        # Flask
        'flask': 'flask',
        'flask-cors': 'flask_cors',
        
        # LLM & LangChain
        'openai': 'openai',
        'langchain': 'langchain',
        'langchain-openai': 'langchain_openai',
        'langchain-core': 'langchain_core',
        'langgraph': 'langgraph',
        
        # ì‹œê°í™”
        'matplotlib': 'matplotlib',
        'seaborn': 'seaborn',
        'plotly': 'plotly',
        
        # ìœ í‹¸ë¦¬í‹°
        'python-dotenv': 'dotenv',
        'requests': 'requests',
        'joblib': 'joblib',
        'tqdm': 'tqdm',
        'pydantic': 'pydantic',
        
        # ë¹„ë™ê¸°
        'aiohttp': 'aiohttp'
    }
    
    success_count = 0
    total_count = len(test_modules)
    
    for package_name, import_name in test_modules.items():
        try:
            __import__(import_name)
            print(f"âœ… {package_name} ({import_name})")
            success_count += 1
        except ImportError as e:
            print(f"âŒ {package_name} ({import_name}): {e}")
    
    print(f"\nğŸ“Š Import í…ŒìŠ¤íŠ¸ ê²°ê³¼: {success_count}/{total_count} ì„±ê³µ")
    
    if success_count == total_count:
        print("ğŸ‰ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return True
    else:
        print("âš ï¸ ì¼ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        return False

def check_gpu_support():
    """GPU ì§€ì› í™•ì¸ (PyTorch)"""
    
    print("\nğŸ” GPU ì§€ì› í™•ì¸...")
    
    try:
        import torch
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            current_device = torch.cuda.current_device()
            gpu_name = torch.cuda.get_device_name(current_device)
            
            print(f"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥!")
            print(f"   GPU ê°œìˆ˜: {gpu_count}")
            print(f"   í˜„ì¬ GPU: {gpu_name}")
            print(f"   CUDA ë²„ì „: {torch.version.cuda}")
        else:
            print("âš ï¸ CUDA ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            
    except ImportError:
        print("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("=" * 60)
    print("ğŸ¤– Agentic AI System ì˜ì¡´ì„± ì„¤ì¹˜ ë° ê²€ì¦")
    print("=" * 60)
    
    # 1. ì˜ì¡´ì„± ì„¤ì¹˜
    if not install_requirements():
        print("\nâŒ ì„¤ì¹˜ ì‹¤íŒ¨ë¡œ ì¸í•´ í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        sys.exit(1)
    
    # 2. Import í…ŒìŠ¤íŠ¸
    if not test_imports():
        print("\nâš ï¸ ì¼ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë¬¸ì œê°€ ìˆì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # 3. GPU ì§€ì› í™•ì¸
    check_gpu_support()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ ì„¤ì¹˜ ë° ê²€ì¦ ì™„ë£Œ!")
    print("=" * 60)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •: OPENAI_API_KEY")
    print("2. Neo4j ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •")
    print("3. python run_agentic_system.py ì‹¤í–‰")

if __name__ == "__main__":
    main()
