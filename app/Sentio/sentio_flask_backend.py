# -*- coding: utf-8 -*-
"""
Sentio HR í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ Flask ë°±ì—”ë“œ ì„œë¹„ìŠ¤
í‚¤ì›Œë“œ ë¶„ì„ + í‡´ì§ ìœ„í—˜ ì‹ í˜¸ íƒì§€ + í…ìŠ¤íŠ¸ ìƒì„± ì‹œìŠ¤í…œ
React ì—°ë™ì— ìµœì í™”ëœ REST API ì„œë²„
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.exceptions import HTTPException
import logging
import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple, Any
from collections import Counter, defaultdict
import re
import traceback

# ë¡œì»¬ ëª¨ë“ˆ import
from sentio_processor import SentioTextProcessor
from sentio_analyzer import SentioKeywordAnalyzer
from sentio_generator import SentioTextGenerator

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì „ì—­ ë³€ìˆ˜
text_processor = None
keyword_analyzer = None
text_generator = None

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
DATA_PATH = {
    'hr_data': '../../data/IBM_HR_personas_assigned.csv',
    'text_data': '../../data/IBM_HR_text.csv',
    'sample_texts': '../../sample_hr_texts.csv'
}

MODEL_PATH = 'app/Sentio/models'
os.makedirs(MODEL_PATH, exist_ok=True)

@dataclass
class SentioAnalysisResult:
    """Sentio ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    employee_id: str
    text_type: str
    original_text: str
    keywords: List[str]
    sentiment_score: float
    attrition_risk_score: float
    risk_factors: List[str]
    analysis_timestamp: str

@dataclass
class SentioGenerationResult:
    """Sentio í…ìŠ¤íŠ¸ ìƒì„± ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    employee_id: str
    persona_code: str
    persona_name: str
    text_type: str
    generated_text: str
    keywords_used: List[str]
    generation_timestamp: str

def initialize_system():
    """
    Sentio ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    """
    global text_processor, keyword_analyzer, text_generator
    
    try:
        logger.info("Sentio ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        
        # í…ìŠ¤íŠ¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        text_processor = SentioTextProcessor()
        logger.info("âœ… í…ìŠ¤íŠ¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í‚¤ì›Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™”
        if os.path.exists(DATA_PATH['sample_texts']):
            keyword_analyzer = SentioKeywordAnalyzer(DATA_PATH['sample_texts'])
            keyword_analyzer.load_data()
            logger.info("âœ… í‚¤ì›Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ í…ìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # í…ìŠ¤íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” (API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        api_key = os.environ.get('OPENAI_API_KEY')
        if api_key and os.path.exists(DATA_PATH['hr_data']):
            text_generator = SentioTextGenerator(api_key, DATA_PATH['hr_data'])
            logger.info("âœ… í…ìŠ¤íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ OpenAI API í‚¤ ë˜ëŠ” HR ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info("ğŸ‰ Sentio ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        logger.error(traceback.format_exc())
        return False

# ============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@app.route('/')
def home():
    """í™ˆí˜ì´ì§€"""
    return jsonify({
        "service": "Sentio HR Text Analysis API",
        "version": "1.0.0",
        "status": "running",
        "description": "HR í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ë° í‡´ì§ ìœ„í—˜ ì‹ í˜¸ íƒì§€ ì„œë¹„ìŠ¤",
        "endpoints": {
            "/analyze/text": "í…ìŠ¤íŠ¸ ë¶„ì„ (í‚¤ì›Œë“œ ì¶”ì¶œ + ê°ì • ë¶„ì„)",
            "/analyze/keywords": "í‚¤ì›Œë“œ ë¶„ì„ (í‡´ì§ì vs ì¬ì§ì)",
            "/analyze/risk": "í‡´ì§ ìœ„í—˜ ì‹ í˜¸ ë¶„ì„",
            "/generate/text": "í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„±",
            "/health": "ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"
        }
    })

@app.route('/health')
def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    status = {
        "service": "Sentio",
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "text_processor": text_processor is not None,
            "keyword_analyzer": keyword_analyzer is not None,
            "text_generator": text_generator is not None
        }
    }
    
    # ì „ì²´ ìƒíƒœ í™•ì¸
    all_healthy = all(status["components"].values())
    status["status"] = "healthy" if all_healthy else "degraded"
    
    return jsonify(status)

@app.route('/analyze/text', methods=['POST'])
def analyze_text():
    """
    í…ìŠ¤íŠ¸ ë¶„ì„ API
    ì…ë ¥: í…ìŠ¤íŠ¸, ì§ì›ID (ì„ íƒ)
    ì¶œë ¥: í‚¤ì›Œë“œ, ê°ì •ì ìˆ˜, í‡´ì§ìœ„í—˜ì ìˆ˜
    """
    try:
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({"error": "í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        text = data['text']
        employee_id = data.get('employee_id', 'unknown')
        text_type = data.get('text_type', 'general')
        
        if not text_processor:
            return jsonify({"error": "í…ìŠ¤íŠ¸ í”„ë¡œì„¸ì„œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500
        
        # í…ìŠ¤íŠ¸ ë¶„ì„ ìˆ˜í–‰
        analysis_result = text_processor.analyze_text(
            text=text,
            employee_id=employee_id,
            text_type=text_type
        )
        
        # ê²°ê³¼ ë°˜í™˜
        result = SentioAnalysisResult(
            employee_id=employee_id,
            text_type=text_type,
            original_text=text,
            keywords=analysis_result['keywords'],
            sentiment_score=analysis_result['sentiment_score'],
            attrition_risk_score=analysis_result['attrition_risk_score'],
            risk_factors=analysis_result['risk_factors'],
            analysis_timestamp=datetime.now().isoformat()
        )
        
        return jsonify(asdict(result))
        
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/analyze/keywords', methods=['POST'])
def analyze_keywords():
    """
    í‚¤ì›Œë“œ ë¶„ì„ API
    ì…ë ¥: ë¶„ì„ ì˜µì…˜
    ì¶œë ¥: í‡´ì§ì vs ì¬ì§ì ì°¨ë³„ì  í‚¤ì›Œë“œ
    """
    try:
        data = request.get_json() or {}
        min_frequency = data.get('min_frequency', 5)
        text_columns = data.get('text_columns', None)
        
        if not keyword_analyzer:
            return jsonify({"error": "í‚¤ì›Œë“œ ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500
        
        # í‚¤ì›Œë“œ ë¶„ì„ ìˆ˜í–‰
        results = keyword_analyzer.analyze_text_columns(text_columns)
        if not results:
            return jsonify({"error": "ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        # ì°¨ë³„ì  í‚¤ì›Œë“œ ì°¾ê¸°
        distinctive_keywords = keyword_analyzer.find_distinctive_keywords(
            results, min_frequency=min_frequency
        )
        
        # ê²°ê³¼ ì •ë¦¬
        analysis_summary = {
            "analysis_timestamp": datetime.now().isoformat(),
            "min_frequency": min_frequency,
            "columns_analyzed": list(results.keys()),
            "distinctive_keywords": distinctive_keywords,
            "summary": {
                col: {
                    "resigned_total_keywords": data['resigned_total'],
                    "stayed_total_keywords": data['stayed_total'],
                    "resigned_unique_count": len(distinctive_keywords[col]['resigned_unique']),
                    "stayed_unique_count": len(distinctive_keywords[col]['stayed_unique'])
                }
                for col, data in results.items()
            }
        }
        
        return jsonify(analysis_summary)
        
    except Exception as e:
        logger.error(f"í‚¤ì›Œë“œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/analyze/risk', methods=['POST'])
def analyze_attrition_risk():
    """
    í‡´ì§ ìœ„í—˜ ì‹ í˜¸ ë¶„ì„ API
    ì…ë ¥: ì§ì› í…ìŠ¤íŠ¸ ë°ì´í„°
    ì¶œë ¥: ìœ„í—˜ ì ìˆ˜ ë° ì£¼ìš” ì‹ í˜¸
    """
    try:
        data = request.get_json()
        
        if not data or 'texts' not in data:
            return jsonify({"error": "ë¶„ì„í•  í…ìŠ¤íŠ¸ ëª©ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        texts = data['texts']  # List of {employee_id, text, text_type}
        
        if not text_processor:
            return jsonify({"error": "í…ìŠ¤íŠ¸ í”„ë¡œì„¸ì„œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500
        
        risk_analysis_results = []
        
        for text_data in texts:
            employee_id = text_data.get('employee_id', 'unknown')
            text = text_data.get('text', '')
            text_type = text_data.get('text_type', 'general')
            
            if not text:
                continue
            
            # ìœ„í—˜ ì‹ í˜¸ ë¶„ì„
            risk_result = text_processor.analyze_attrition_risk(
                text=text,
                employee_id=employee_id
            )
            
            risk_analysis_results.append({
                "employee_id": employee_id,
                "text_type": text_type,
                "risk_score": risk_result['risk_score'],
                "risk_level": risk_result['risk_level'],
                "risk_factors": risk_result['risk_factors'],
                "keywords_detected": risk_result['keywords_detected']
            })
        
        # ì „ì²´ ìš”ì•½ í†µê³„
        risk_scores = [r['risk_score'] for r in risk_analysis_results]
        summary_stats = {
            "total_analyzed": len(risk_analysis_results),
            "average_risk_score": np.mean(risk_scores) if risk_scores else 0,
            "high_risk_count": len([r for r in risk_analysis_results if r['risk_level'] == 'high']),
            "medium_risk_count": len([r for r in risk_analysis_results if r['risk_level'] == 'medium']),
            "low_risk_count": len([r for r in risk_analysis_results if r['risk_level'] == 'low'])
        }
        
        return jsonify({
            "analysis_timestamp": datetime.now().isoformat(),
            "summary": summary_stats,
            "individual_results": risk_analysis_results
        })
        
    except Exception as e:
        logger.error(f"ìœ„í—˜ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/generate/text', methods=['POST'])
def generate_text():
    """
    í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„± API
    ì…ë ¥: ì§ì› ì •ë³´, í…ìŠ¤íŠ¸ íƒ€ì…
    ì¶œë ¥: ìƒì„±ëœ í…ìŠ¤íŠ¸
    """
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({"error": "ìš”ì²­ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        if not text_generator:
            return jsonify({"error": "í…ìŠ¤íŠ¸ ìƒì„±ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."}), 500
        
        # ë‹¨ì¼ ì§ì› í…ìŠ¤íŠ¸ ìƒì„±
        if 'employee_data' in data:
            employee_data = data['employee_data']
            text_type = data.get('text_type', 'SELF_REVIEW')
            
            generated_text = text_generator.generate_text_for_employee(
                employee_data=employee_data,
                text_type=text_type
            )
            
            result = SentioGenerationResult(
                employee_id=employee_data.get('EmployeeNumber', 'unknown'),
                persona_code=employee_data.get('softmax_Persona_Code', 'unknown'),
                persona_name=employee_data.get('softmax_Persona', 'unknown'),
                text_type=text_type,
                generated_text=generated_text,
                keywords_used=text_generator.get_attrition_keywords_for_persona(
                    employee_data.get('softmax_Persona_Code', 'N01')
                )[:5],  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ
                generation_timestamp=datetime.now().isoformat()
            )
            
            return jsonify(asdict(result))
        
        # ë°°ì¹˜ í…ìŠ¤íŠ¸ ìƒì„±
        elif 'batch_size' in data:
            batch_size = data['batch_size']
            text_types = data.get('text_types', ['SELF_REVIEW'])
            
            text_generator.generate_all_texts(
                text_types=text_types,
                sample_size=batch_size
            )
            
            return jsonify({
                "message": f"{batch_size}ëª…ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "generated_count": len(text_generator.generated_texts),
                "text_types": text_types,
                "generation_timestamp": datetime.now().isoformat()
            })
        
        else:
            return jsonify({"error": "employee_data ë˜ëŠ” batch_sizeê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": f"ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/data/personas', methods=['GET'])
def get_personas():
    """í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¡°íšŒ API"""
    try:
        if not text_generator:
            return jsonify({"error": "í…ìŠ¤íŠ¸ ìƒì„±ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500
        
        # í˜ë¥´ì†Œë‚˜ë³„ í†µê³„ ì •ë³´
        df = text_generator.df
        persona_stats = df.groupby(['softmax_Persona_Code', 'softmax_Persona']).agg({
            'EmployeeNumber': 'count',
            'Attrition': lambda x: (x == 'Yes').sum()
        }).reset_index()
        
        persona_stats.columns = ['persona_code', 'persona_name', 'total_count', 'attrition_count']
        persona_stats['attrition_rate'] = persona_stats['attrition_count'] / persona_stats['total_count']
        
        return jsonify({
            "personas": persona_stats.to_dict('records'),
            "total_employees": len(df),
            "total_attrition": (df['Attrition'] == 'Yes').sum()
        })
        
    except Exception as e:
        logger.error(f"í˜ë¥´ì†Œë‚˜ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": f"ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

# ============================================================================
# ì˜¤ë¥˜ ì²˜ë¦¬
# ============================================================================

@app.errorhandler(HTTPException)
def handle_http_exception(e):
    """HTTP ì˜ˆì™¸ ì²˜ë¦¬"""
    return jsonify({
        "error": e.description,
        "status_code": e.code
    }), e.code

@app.errorhandler(Exception)
def handle_general_exception(e):
    """ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬"""
    logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
    logger.error(traceback.format_exc())
    
    return jsonify({
        "error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "message": str(e)
    }), 500

# ============================================================================
# ì•± ì‹¤í–‰
# ============================================================================

if __name__ == '__main__':
    print("ğŸš€ Sentio HR Text Analysis API ì„œë²„ ì‹œì‘...")
    print("=" * 60)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if initialize_system():
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print("ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:5003")
        print("ğŸ“š API ë¬¸ì„œ: http://localhost:5003/")
        print("=" * 60)
        
        app.run(
            host='0.0.0.0',
            port=5003,
            debug=True,
            threaded=True
        )
    else:
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        print("ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
