# -*- coding: utf-8 -*-
"""
Agentic AI Master Server
ì›Œì»¤ ì—ì´ì „íŠ¸ë“¤ì„ í†µí•© ê´€ë¦¬í•˜ëŠ” ë§ˆìŠ¤í„° ì„œë²„

í˜„ì¬ êµ¬í˜„ëœ ì›Œì»¤ ì—ì´ì „íŠ¸:
- ì›Œì»¤ ì—ì´ì „íŠ¸ 1: ì •í˜• ë°ì´í„° ë¶„ì„ (Structura) - XGBoost ê¸°ë°˜ ì´ì§ ì˜ˆì¸¡
- ì›Œì»¤ ì—ì´ì „íŠ¸ 2: ê´€ê³„í˜• ë°ì´í„° ë¶„ì„ (Cognita) - Neo4j ê¸°ë°˜ ê´€ê³„ ë¶„ì„
- ì›Œì»¤ ì—ì´ì „íŠ¸ 3: ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ (Chronos) - GRU+CNN+Attention ê¸°ë°˜ ì‹œê°„ íŒ¨í„´ ë¶„ì„
- ì›Œì»¤ ì—ì´ì „íŠ¸ 4: í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ (Sentio) - NLP ê¸°ë°˜ í‡´ì§ ìœ„í—˜ ì‹ í˜¸ íƒì§€
- ì›Œì»¤ ì—ì´ì „íŠ¸ 5: ì™¸ë¶€ ì‹œì¥ ë¶„ì„ (Agora) - ì‹œì¥ ì••ë ¥ ì§€ìˆ˜ ë° ê²½ìŸë ¥ í‰ê°€

ì¶”ê°€ êµ¬í˜„ëœ ì—ì´ì „íŠ¸:
- Supervisor ì—ì´ì „íŠ¸: âœ… LangGraph ê¸°ë°˜ ì „ì²´ ì¡°ì • ë° ì˜ì‚¬ê²°ì •
- Integration ì—ì´ì „íŠ¸: âœ… ê²°ê³¼ í†µí•© ë° ë¦¬í¬íŠ¸ ìƒì„±
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.exceptions import HTTPException
from werkzeug.utils import secure_filename
import logging
import os
import json
import threading
import time
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
from queue import Queue
import sys
from pathlib import Path
import pandas as pd

# ê²°ê³¼ ê´€ë¦¬ì import
from result_manager import AgenticResultManager, result_manager

# ì›Œì»¤ ì—ì´ì „íŠ¸ import
sys.path.append(str(Path(__file__).parent / "Structura"))
sys.path.append(str(Path(__file__).parent / "Cognita"))
sys.path.append(str(Path(__file__).parent / "Sentio"))
sys.path.append(str(Path(__file__).parent / "Chronos"))
sys.path.append(str(Path(__file__).parent / "Agora"))

try:
    from Structura.structura_flask_backend import StructuraHRPredictor
    STRUCTURA_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Structura ì›Œì»¤ ì—ì´ì „íŠ¸ import ì‹¤íŒ¨: {e}")
    STRUCTURA_AVAILABLE = False

try:
    from Cognita.cognita_flask_backend import CognitaRiskAnalyzer, Neo4jManager
    COGNITA_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Cognita ì›Œì»¤ ì—ì´ì „íŠ¸ import ì‹¤íŒ¨: {e}")
    COGNITA_AVAILABLE = False

try:
    from Sentio.sentio_processor import SentioTextProcessor
    from Sentio.sentio_analyzer import SentioKeywordAnalyzer
    from Sentio.sentio_generator import SentioTextGenerator
    SENTIO_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Sentio ì›Œì»¤ ì—ì´ì „íŠ¸ import ì‹¤íŒ¨: {e}")
    SENTIO_AVAILABLE = False

try:
    from Chronos.chronos_processor_fixed import ChronosDataProcessor
    from Chronos.chronos_models import ChronosModelTrainer, GRU_CNN_HybridModel as ChronosHybridModel
    CHRONOS_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Chronos ì›Œì»¤ ì—ì´ì „íŠ¸ import ì‹¤íŒ¨: {e}")
    CHRONOS_AVAILABLE = False

try:
    from Agora.agora_processor import AgoraMarketProcessor
    from Agora.agora_analyzer import AgoraMarketAnalyzer
    from Agora.agora_llm_generator import AgoraLLMGenerator
    AGORA_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Agora ì›Œì»¤ ì—ì´ì „íŠ¸ import ì‹¤íŒ¨: {e}")
    AGORA_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì „ì—­ ì›Œì»¤ ë§¤ë‹ˆì € (Flask ì•± ë‚´ë¶€ì—ì„œ ê´€ë¦¬ë¨)

# ------------------------------------------------------
# ë°ì´í„° ëª¨ë¸ ì •ì˜
# ------------------------------------------------------

@dataclass
class WorkerStatus:
    """ì›Œì»¤ ì—ì´ì „íŠ¸ ìƒíƒœ"""
    agent_id: str
    agent_name: str
    status: str  # 'running', 'stopped', 'error', 'busy'
    last_heartbeat: str
    tasks_completed: int
    current_task: Optional[str]
    error_message: Optional[str] = None

class AgenticTask:
    """ì—ì´ì „í‹± ì‘ì—… - ë™ì  ì†ì„± ì§€ì›"""
    
    def __init__(self, task_id: str, task_type: str, **kwargs):
        self.task_id = task_id
        self.task_type = task_type
        
        # ê¸°ë³¸ ì†ì„±ë“¤
        self.employee_data = kwargs.get('employee_data', None)
        self.department_name = kwargs.get('department_name', None)
        self.sample_size = kwargs.get('sample_size', None)
        self.text_data = kwargs.get('text_data', None)
        self.timeseries_data = kwargs.get('timeseries_data', None)
        self.market_data = kwargs.get('market_data', None)
        self.use_structura = kwargs.get('use_structura', True)
        self.use_cognita = kwargs.get('use_cognita', True)
        self.use_sentio = kwargs.get('use_sentio', False)
        self.use_chronos = kwargs.get('use_chronos', False)
        self.use_agora = kwargs.get('use_agora', False)
        self.priority = kwargs.get('priority', 1)
        self.created_at = kwargs.get('created_at', datetime.now().isoformat())
        
        # ì¶”ê°€ ë™ì  ì†ì„±ë“¤ (ì§ì› ë°ì´í„° ë“±)
        for key, value in kwargs.items():
            if not hasattr(self, key):
                setattr(self, key, value)
    
    def to_dict(self):
        """ë”•ì…”ë„ˆë¦¬ ë³€í™˜ì„ ìœ„í•œ ë©”ì„œë“œ"""
        return {key: value for key, value in self.__dict__.items()}

@dataclass
class AgenticResult:
    """ì—ì´ì „í‹± ë¶„ì„ ê²°ê³¼"""
    task_id: str
    task_type: str
    structura_result: Optional[Dict] = None
    cognita_result: Optional[Dict] = None
    sentio_result: Optional[Dict] = None
    chronos_result: Optional[Dict] = None
    agora_result: Optional[Dict] = None
    combined_analysis: Optional[Dict] = None
    execution_time: float = 0.0
    status: str = "completed"  # 'completed', 'partial', 'failed'
    error_message: Optional[str] = None
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()

# ------------------------------------------------------
# ì›Œì»¤ ì—ì´ì „íŠ¸ ê´€ë¦¬ì
# ------------------------------------------------------

class WorkerAgentManager:
    """ì›Œì»¤ ì—ì´ì „íŠ¸ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.workers = {}
        self.task_queue = Queue()
        self.result_cache = {}
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self._initialize_workers()
    
    def _initialize_workers(self):
        """ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        logger.info("ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹œì‘...")
        
        # ì›Œì»¤ ì—ì´ì „íŠ¸ 1: Structura (ì •í˜• ë°ì´í„° ë¶„ì„)
        if STRUCTURA_AVAILABLE:
            try:
                structura_predictor = StructuraHRPredictor()
                self.workers['structura'] = {
                    'agent': structura_predictor,
                    'status': WorkerStatus(
                        agent_id='structura',
                        agent_name='ì •í˜• ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='running',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None
                    ),
                    'type': 'structured_data'
                }
                logger.info("âœ… Structura ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ Structura ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.workers['structura'] = {
                    'agent': None,
                    'status': WorkerStatus(
                        agent_id='structura',
                        agent_name='ì •í˜• ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='error',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None,
                        error_message=str(e)
                    ),
                    'type': 'structured_data'
                }
        
        # ì›Œì»¤ ì—ì´ì „íŠ¸ 2: Cognita (ê´€ê³„í˜• ë°ì´í„° ë¶„ì„)
        if COGNITA_AVAILABLE:
            try:
                # Neo4j ì—°ê²° ì„¤ì • (Cognita ì„œë²„ì™€ ë™ì¼í•˜ê²Œ í†µì¼)
                neo4j_config = {
                    "uri": os.getenv("NEO4J_URI", "bolt://44.212.67.74:7687"),
                    "username": os.getenv("NEO4J_USERNAME", "neo4j"),
                    "password": os.getenv("NEO4J_PASSWORD", "legs-augmentations-cradle")
                }
                
                neo4j_manager = Neo4jManager(
                    neo4j_config['uri'],
                    neo4j_config['username'],
                    neo4j_config['password']
                )
                
                cognita_analyzer = CognitaRiskAnalyzer(neo4j_manager)
                
                self.workers['cognita'] = {
                    'agent': cognita_analyzer,
                    'status': WorkerStatus(
                        agent_id='cognita',
                        agent_name='ê´€ê³„í˜• ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='running',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None
                    ),
                    'type': 'relational_data'
                }
                logger.info("âœ… Cognita ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ Cognita ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.workers['cognita'] = {
                    'agent': None,
                    'status': WorkerStatus(
                        agent_id='cognita',
                        agent_name='ê´€ê³„í˜• ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='error',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None,
                        error_message=str(e)
                    ),
                    'type': 'relational_data'
                }
        
        # ì›Œì»¤ ì—ì´ì „íŠ¸ 3: Chronos (ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„)
        if CHRONOS_AVAILABLE:
            try:
                chronos_processor = ChronosDataProcessor(sequence_length=6, aggregation_unit='week')
                
                # ë°ì´í„° ë¡œë“œ ì‹œë„ (ì„ íƒì )
                try:
                    chronos_processor.load_data('data/IBM_HR_timeseries.csv', 'data/IBM_HR.csv')
                    chronos_processor.preprocess_data()
                    
                    # ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
                    if hasattr(chronos_processor, 'X_train') and chronos_processor.X_train is not None:
                        # ëª¨ë¸ ìƒì„±
                        input_size = chronos_processor.X_train.shape[2] if len(chronos_processor.X_train.shape) > 2 else 10
                        model = ChronosHybridModel(input_size=input_size)
                        chronos_trainer = ChronosModelTrainer(model)
                    else:
                        chronos_trainer = None
                        logger.info("Chronos ë°ì´í„°ê°€ ì—†ì–´ íŠ¸ë ˆì´ë„ˆëŠ” ë‚˜ì¤‘ì— ì´ˆê¸°í™”ë©ë‹ˆë‹¤.")
                        
                except Exception as data_e:
                    logger.warning(f"Chronos ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {data_e}")
                    logger.info("ChronosëŠ” ë°ì´í„° ì—…ë¡œë“œ í›„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                    chronos_trainer = None
                
                self.workers['chronos'] = {
                    'agent': {
                        'processor': chronos_processor,
                        'trainer': chronos_trainer
                    },
                    'status': WorkerStatus(
                        agent_id='chronos',
                        agent_name='ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='running',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None
                    ),
                    'type': 'timeseries_analysis'
                }
                logger.info("âœ… Chronos ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ Chronos ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.workers['chronos'] = {
                    'agent': None,
                    'status': WorkerStatus(
                        agent_id='chronos',
                        agent_name='ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='error',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None,
                        error_message=str(e)
                    ),
                    'type': 'timeseries_analysis'
                }
        
        # ì›Œì»¤ ì—ì´ì „íŠ¸ 4: Sentio (í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„)
        if SENTIO_AVAILABLE:
            try:
                # í‚¤ì›Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” (JD-R ëª¨ë¸ í¬í•¨)
                sentio_analyzer = None
                try:
                    sentio_analyzer = SentioKeywordAnalyzer("sample_hr_texts.csv")
                    sentio_analyzer.load_data()
                    logger.info("âœ… Sentio í‚¤ì›Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as ana_e:
                    logger.warning(f"Sentio í‚¤ì›Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {ana_e}")
                
                # í…ìŠ¤íŠ¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” (analyzer ì—°ê²°)
                sentio_processor = SentioTextProcessor(analyzer=sentio_analyzer)
                
                # OpenAI API í‚¤ê°€ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ ìƒì„±ê¸°ë„ ì´ˆê¸°í™”
                api_key = os.environ.get('OPENAI_API_KEY')
                sentio_generator = None
                if api_key:
                    try:
                        sentio_generator = SentioTextGenerator(api_key, None)  # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì—†ì´ ë™ì‘
                    except Exception as gen_e:
                        logger.warning(f"Sentio í…ìŠ¤íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {gen_e}")
                
                self.workers['sentio'] = {
                    'agent': {
                        'processor': sentio_processor,
                        'analyzer': sentio_analyzer,
                        'generator': sentio_generator
                    },
                    'status': WorkerStatus(
                        agent_id='sentio',
                        agent_name='í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='running',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None
                    ),
                    'type': 'text_analysis'
                }
                logger.info("âœ… Sentio ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ Sentio ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.workers['sentio'] = {
                    'agent': None,
                    'status': WorkerStatus(
                        agent_id='sentio',
                        agent_name='í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='error',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None,
                        error_message=str(e)
                    ),
                    'type': 'text_analysis'
                }
        
        # ì›Œì»¤ ì—ì´ì „íŠ¸ 5: Agora (ì™¸ë¶€ ì‹œì¥ ë¶„ì„)
        if AGORA_AVAILABLE:
            try:
                # ì‹œì¥ ë°ì´í„° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
                agora_processor = AgoraMarketProcessor()
                
                # ì‹œì¥ ë¶„ì„ê¸° ì´ˆê¸°í™” (HR ë°ì´í„° ê²½ë¡œ)
                hr_data_path = "data/IBM_HR.csv"
                agora_analyzer = None
                if Path(hr_data_path).exists():
                    agora_analyzer = AgoraMarketAnalyzer(hr_data_path)
                    logger.info("âœ… Agora ì‹œì¥ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    logger.warning(f"HR ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {hr_data_path}")
                
                # LLM ìƒì„±ê¸° ì´ˆê¸°í™” (OpenAI API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
                api_key = os.environ.get('OPENAI_API_KEY')
                agora_llm_generator = None
                if api_key:
                    try:
                        agora_llm_generator = AgoraLLMGenerator(api_key)
                        logger.info("âœ… Agora LLM ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
                    except Exception as llm_e:
                        logger.warning(f"Agora LLM ìƒì„±ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {llm_e}")
                
                self.workers['agora'] = {
                    'agent': {
                        'processor': agora_processor,
                        'analyzer': agora_analyzer,
                        'llm_generator': agora_llm_generator
                    },
                    'status': WorkerStatus(
                        agent_id='agora',
                        agent_name='ì™¸ë¶€ ì‹œì¥ ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='running',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None
                    ),
                    'type': 'market_analysis'
                }
                logger.info("âœ… Agora ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ Agora ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.workers['agora'] = {
                    'agent': None,
                    'status': WorkerStatus(
                        agent_id='agora',
                        agent_name='ì™¸ë¶€ ì‹œì¥ ë¶„ì„ ì—ì´ì „íŠ¸',
                        status='error',
                        last_heartbeat=datetime.now().isoformat(),
                        tasks_completed=0,
                        current_task=None,
                        error_message=str(e)
                    ),
                    'type': 'market_analysis'
                }
        
        logger.info(f"ì›Œì»¤ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.workers)}ê°œ ì—ì´ì „íŠ¸")
    
    def get_worker_status(self) -> Dict[str, WorkerStatus]:
        """ëª¨ë“  ì›Œì»¤ ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ"""
        status_dict = {}
        for worker_id, worker_info in self.workers.items():
            # í•˜íŠ¸ë¹„íŠ¸ ì—…ë°ì´íŠ¸
            worker_info['status'].last_heartbeat = datetime.now().isoformat()
            status_dict[worker_id] = worker_info['status']
        return status_dict
    
    def execute_task(self, task: AgenticTask) -> AgenticResult:
        """ì—ì´ì „í‹± ì‘ì—… ì‹¤í–‰"""
        logger.info(f"ì‘ì—… ì‹¤í–‰ ì‹œì‘: {task.task_id} ({task.task_type})")
        
        start_time = time.time()
        result = AgenticResult(
            task_id=task.task_id,
            task_type=task.task_type
        )
        
        try:
            # ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ Future ë¦¬ìŠ¤íŠ¸
            futures = []
            
            # Structura ì›Œì»¤ ì‹¤í–‰
            if task.use_structura and 'structura' in self.workers:
                if self.workers['structura']['agent'] is not None:
                    future = self.executor.submit(self._execute_structura_task, task)
                    futures.append(('structura', future))
                    
                    # ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self.workers['structura']['status'].status = 'busy'
                    self.workers['structura']['status'].current_task = task.task_id
            
            # Cognita ì›Œì»¤ ì‹¤í–‰
            if task.use_cognita and 'cognita' in self.workers:
                if self.workers['cognita']['agent'] is not None:
                    future = self.executor.submit(self._execute_cognita_task, task)
                    futures.append(('cognita', future))
                    
                    # ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self.workers['cognita']['status'].status = 'busy'
                    self.workers['cognita']['status'].current_task = task.task_id
            
            # Agora ì›Œì»¤ ì‹¤í–‰
            if task.use_agora and 'agora' in self.workers:
                if self.workers['agora']['agent'] is not None:
                    future = self.executor.submit(self._execute_agora_task, task)
                    futures.append(('agora', future))
                    
                    # ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self.workers['agora']['status'].status = 'busy'
                    self.workers['agora']['status'].current_task = task.task_id
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for worker_name, future in futures:
                try:
                    worker_result = future.result(timeout=60)  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
                    
                    if worker_name == 'structura':
                        result.structura_result = worker_result
                    elif worker_name == 'cognita':
                        result.cognita_result = worker_result
                    elif worker_name == 'agora':
                        result.agora_result = worker_result
                    
                    # ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self.workers[worker_name]['status'].status = 'running'
                    self.workers[worker_name]['status'].current_task = None
                    self.workers[worker_name]['status'].tasks_completed += 1
                    
                except Exception as e:
                    logger.error(f"ì›Œì»¤ {worker_name} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    
                    # ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸ (ì—ëŸ¬)
                    self.workers[worker_name]['status'].status = 'error'
                    self.workers[worker_name]['status'].current_task = None
                    self.workers[worker_name]['status'].error_message = str(e)
            
            # ê²°í•© ë¶„ì„ ìˆ˜í–‰
            if result.structura_result and result.cognita_result:
                result.combined_analysis = self._combine_analysis_results(
                    result.structura_result, 
                    result.cognita_result,
                    task
                )
            
            result.execution_time = time.time() - start_time
            result.status = 'completed'
            
            # ê²°ê³¼ ìºì‹œì— ì €ì¥
            self.result_cache[task.task_id] = result
            
            logger.info(f"ì‘ì—… ì™„ë£Œ: {task.task_id} (ì†Œìš”ì‹œê°„: {result.execution_time:.2f}ì´ˆ)")
            
        except Exception as e:
            result.status = 'failed'
            result.error_message = str(e)
            result.execution_time = time.time() - start_time
            logger.error(f"ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {task.task_id} - {e}")
        
        return result

    def execute_sequential_workflow(self, task: AgenticTask) -> AgenticResult:
        """ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ - Supervisor íŒ¨í„´ (ê°œì„ ëœ ë²„ì „)"""
        logger.info(f"ğŸ”„ ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ì‹œì‘: {task.task_id}")
        
        start_time = time.time()
        result = AgenticResult(
            task_id=task.task_id,
            task_type=task.task_type
        )
        
        try:
            # ìˆœì°¨ì  ì—ì´ì „íŠ¸ ì‹¤í–‰ ìˆœì„œ ì •ì˜ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
            agent_pipeline = []
            if task.use_structura and 'structura' in self.workers: agent_pipeline.append('structura')
            if task.use_cognita and 'cognita' in self.workers: agent_pipeline.append('cognita')
            if task.use_chronos and 'chronos' in self.workers: agent_pipeline.append('chronos')
            if task.use_sentio and 'sentio' in self.workers: agent_pipeline.append('sentio')
            if task.use_agora and 'agora' in self.workers: agent_pipeline.append('agora')
            
            # ëˆ„ì  ë°ì´í„° ì €ì¥ì†Œ
            accumulated_data = {}
            pipeline_results = {}
            successful_agents = []
            failed_agents = []
            
            # 1ë‹¨ê³„ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
            for step, agent_name in enumerate(agent_pipeline, 1):
                try:
                    logger.info(f"ğŸ“Š {step}/{len(agent_pipeline)}ë‹¨ê³„: {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
                    
                    # ì—ì´ì „íŠ¸ ê°€ìš©ì„± í™•ì¸
                    if not self._is_agent_available(agent_name):
                        logger.warning(f"âš ï¸ {agent_name} ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        failed_agents.append(agent_name)
                        continue
                    
                    # ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self._update_worker_status(agent_name, 'busy', task.task_id)
                    
                    # ì´ì „ ë‹¨ê³„ ê²°ê³¼ë¥¼ í˜„ì¬ ë‹¨ê³„ì— ì „ë‹¬
                    enhanced_task = self._enhance_task_with_accumulated_data(task, accumulated_data)
                    
                    # ì—ì´ì „íŠ¸ë³„ ì‹¤í–‰ (ì—ëŸ¬ ë³µêµ¬ í¬í•¨)
                    agent_result = self._execute_agent_with_retry(agent_name, enhanced_task)
                    
                    if agent_result:
                        # ê²°ê³¼ ì €ì¥
                        setattr(result, f'{agent_name}_result', agent_result)
                        pipeline_results[f'{agent_name}_analysis'] = agent_result
                        
                        # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë°ì´í„° ì¶”ì¶œ
                        self._extract_accumulated_data(agent_name, agent_result, accumulated_data)
                        
                        # ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸ (ì™„ë£Œ)
                        self._update_worker_status(agent_name, 'running', None, completed=True)
                        successful_agents.append(agent_name)
                        
                        logger.info(f"âœ… {step}ë‹¨ê³„ ì™„ë£Œ: {agent_name}")
                    else:
                        raise Exception("ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤")
                    
                except Exception as e:
                    logger.error(f"âŒ {step}ë‹¨ê³„ ì‹¤íŒ¨: {agent_name} - {str(e)}")
                    pipeline_results[f'{agent_name}_analysis'] = {'error': str(e), 'status': 'failed'}
                    failed_agents.append(agent_name)
                    
                    # ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸ (ì—ëŸ¬)
                    self._update_worker_status(agent_name, 'error', None, error_msg=str(e))
                    
                    # ì¤‘ìš”í•œ ì—ì´ì „íŠ¸ ì‹¤íŒ¨ ì‹œ ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨ ì—¬ë¶€ ê²°ì •
                    if agent_name in ['structura', 'cognita'] and len(successful_agents) == 0:
                        logger.warning(f"í•µì‹¬ ì—ì´ì „íŠ¸ {agent_name} ì‹¤íŒ¨ë¡œ ì›Œí¬í”Œë¡œìš° ê³„ì† ì§„í–‰")
            
            # ìµœì¢… í†µí•© ë¶„ì„ (ê°œì„ ëœ ë¡œì§)
            result.combined_analysis = self._generate_comprehensive_analysis(
                result, accumulated_data, successful_agents, failed_agents
            )
            
            # ì›Œí¬í”Œë¡œìš° ë©”íƒ€ë°ì´í„° ì¶”ê°€
            result.workflow_metadata = {
                'execution_mode': 'sequential',
                'pipeline_order': agent_pipeline,
                'successful_agents': successful_agents,
                'failed_agents': failed_agents,
                'execution_steps': len(agent_pipeline),
                'accumulated_data': accumulated_data,
                'success_rate': len(successful_agents) / len(agent_pipeline) if agent_pipeline else 0
            }
            
            result.execution_time = time.time() - start_time
            result.status = 'completed' if successful_agents else 'failed'
            
            # ê²°ê³¼ ìºì‹œì— ì €ì¥
            self.result_cache[task.task_id] = result
            
            logger.info(f"ğŸ‰ ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: {task.task_id} (ì„±ê³µ: {len(successful_agents)}/{len(agent_pipeline)}, ì†Œìš”ì‹œê°„: {result.execution_time:.2f}ì´ˆ)")
            
        except Exception as e:
            result.status = 'failed'
            result.error_message = str(e)
            result.execution_time = time.time() - start_time
            logger.error(f"ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ì‹¤íŒ¨: {task.task_id} - {e}")
        
        return result

    def _is_agent_available(self, agent_name: str) -> bool:
        """ì—ì´ì „íŠ¸ ê°€ìš©ì„± í™•ì¸"""
        if agent_name not in self.workers:
            return False
        
        worker_info = self.workers[agent_name]
        agent = worker_info.get('agent')
        status = worker_info.get('status')
        
        # ì—ì´ì „íŠ¸ ê°ì²´ ì¡´ì¬ í™•ì¸
        if not agent:
            return False
        
        # ìƒíƒœ í™•ì¸
        if status and status.status == 'error':
            return False
        
        return True

    def _update_worker_status(self, agent_name: str, status: str, task_id: Optional[str], 
                            completed: bool = False, error_msg: Optional[str] = None):
        """ì›Œì»¤ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if agent_name in self.workers:
            worker_status = self.workers[agent_name]['status']
            worker_status.status = status
            worker_status.current_task = task_id
            worker_status.last_heartbeat = datetime.now().isoformat()
            
            if completed:
                worker_status.tasks_completed += 1
            
            if error_msg:
                worker_status.error_message = error_msg

    def _enhance_task_with_accumulated_data(self, original_task: AgenticTask, accumulated_data: Dict) -> AgenticTask:
        """ëˆ„ì  ë°ì´í„°ë¡œ ì‘ì—… ê°•í™”"""
        # ì›ë³¸ ì‘ì—…ì˜ ì†ì„± ë³µì‚¬ (task_id, task_type ì œì™¸)
        task_dict = original_task.__dict__.copy()
        task_dict.pop('task_id', None)
        task_dict.pop('task_type', None)
        
        # ì›ë³¸ ì‘ì—… ë³µì‚¬
        enhanced_task = AgenticTask(
            task_id=original_task.task_id,
            task_type=original_task.task_type,
            **task_dict
        )
        
        # ëˆ„ì  ë°ì´í„° ì¶”ê°€
        for key, value in accumulated_data.items():
            setattr(enhanced_task, key, value)
        
        return enhanced_task

    def _is_agent_available(self, agent_name: str) -> bool:
        """ì—ì´ì „íŠ¸ ê°€ìš©ì„± ì²´í¬"""
        if agent_name == 'structura':
            return STRUCTURA_AVAILABLE and agent_name in self.workers and self.workers[agent_name]['agent'] is not None
        elif agent_name == 'cognita':
            return COGNITA_AVAILABLE and agent_name in self.workers and self.workers[agent_name]['agent'] is not None
        elif agent_name == 'chronos':
            return CHRONOS_AVAILABLE and agent_name in self.workers and self.workers[agent_name]['agent'] is not None
        elif agent_name == 'sentio':
            return SENTIO_AVAILABLE and agent_name in self.workers and self.workers[agent_name]['agent'] is not None
        elif agent_name == 'agora':
            return AGORA_AVAILABLE and agent_name in self.workers and self.workers[agent_name]['agent'] is not None
        return False

    def _execute_agent_with_retry(self, agent_name: str, task: AgenticTask, max_retries: int = 2) -> Optional[Dict]:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ (ì¬ì‹œë„ í¬í•¨)"""
        
        # ì—ì´ì „íŠ¸ ê°€ìš©ì„± ë¨¼ì € ì²´í¬
        if not self._is_agent_available(agent_name):
            error_msg = f"âŒ {agent_name} ì—ì´ì „íŠ¸ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤ (import ì‹¤íŒ¨ ë˜ëŠ” ì´ˆê¸°í™” ì˜¤ë¥˜)"
            logger.error(error_msg)
            print(f"[DEBUG] {error_msg}")  # Console ì¶œë ¥ìš©
            return None
        
        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    logger.info(f"ğŸ”„ {agent_name} ì—ì´ì „íŠ¸ ì¬ì‹œë„ {attempt}/{max_retries}")
                    print(f"[DEBUG] ğŸ”„ {agent_name} ì—ì´ì „íŠ¸ ì¬ì‹œë„ {attempt}/{max_retries}")
                
                logger.info(f"â–¶ï¸ {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘ (ì‹œë„ {attempt + 1})")
                print(f"[DEBUG] â–¶ï¸ {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘ (ì‹œë„ {attempt + 1})")
                
                # ì—ì´ì „íŠ¸ë³„ ì‹¤í–‰
                if agent_name == 'structura':
                    result = self._execute_structura_task(task)
                elif agent_name == 'cognita':
                    result = self._execute_cognita_task(task)
                elif agent_name == 'chronos':
                    result = self._execute_chronos_task(task)
                elif agent_name == 'sentio':
                    result = self._execute_sentio_task(task)
                elif agent_name == 'agora':
                    result = self._execute_agora_task(task)
                else:
                    raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì—ì´ì „íŠ¸: {agent_name}")
                
                logger.info(f"âœ… {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì„±ê³µ")
                print(f"[DEBUG] âœ… {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì„±ê³µ")
                return result
                    
            except Exception as e:
                error_msg = f"âš ï¸ {agent_name} ì‹¤í–‰ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}"
                logger.warning(error_msg)
                print(f"[DEBUG] {error_msg}")  # Console ì¶œë ¥ìš©
                
                if attempt < max_retries:
                    time.sleep(1)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                else:
                    final_error = f"âŒ {agent_name} ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ - ìµœì¢… ì˜¤ë¥˜: {str(e)}"
                    logger.error(final_error)
                    print(f"[DEBUG] {final_error}")  # Console ì¶œë ¥ìš©
                    return None
        
        return None

    def _extract_accumulated_data(self, agent_name: str, agent_result: Dict, accumulated_data: Dict):
        """ì—ì´ì „íŠ¸ ê²°ê³¼ì—ì„œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë°ì´í„° ì¶”ì¶œ"""
        
        if agent_name == 'structura':
            accumulated_data['structura_risk_score'] = agent_result.get('attrition_probability', 0)
            accumulated_data['structura_factors'] = agent_result.get('key_factors', [])
            accumulated_data['structura_confidence'] = agent_result.get('confidence_score', 0)
            
        elif agent_name == 'cognita':
            if 'risk_analysis' in agent_result:
                risk_data = agent_result['risk_analysis']
                accumulated_data['cognita_risk_score'] = risk_data.get('overall_risk_score', 0)
                accumulated_data['network_metrics'] = risk_data.get('network_centrality_score', 0)
                accumulated_data['social_isolation'] = risk_data.get('social_isolation_index', 0)
            else:
                accumulated_data['cognita_risk_score'] = agent_result.get('overall_risk_score', 0)
                accumulated_data['network_metrics'] = agent_result.get('network_centrality_score', 0)
                
        elif agent_name == 'chronos':
            accumulated_data['chronos_trend'] = agent_result.get('trend_score', 0)
            accumulated_data['time_patterns'] = agent_result.get('time_series_pattern', 'stable')
            accumulated_data['chronos_confidence'] = agent_result.get('prediction_confidence', 0)
            
        elif agent_name == 'sentio':
            accumulated_data['sentio_sentiment'] = agent_result.get('sentiment_score', 0)
            accumulated_data['emotional_state'] = agent_result.get('emotional_state', 'neutral')
            accumulated_data['risk_keywords'] = agent_result.get('risk_keywords', [])
            
        elif agent_name == 'agora':
            if 'market_analysis' in agent_result:
                market_data = agent_result['market_analysis']
                accumulated_data['agora_market_pressure'] = market_data.get('market_pressure_index', 0)
                accumulated_data['compensation_gap'] = market_data.get('compensation_gap', 0)
            else:
                accumulated_data['agora_market_pressure'] = agent_result.get('market_pressure_index', 0)
                accumulated_data['compensation_gap'] = agent_result.get('compensation_gap', 0)

    def _generate_comprehensive_analysis(self, result: AgenticResult, accumulated_data: Dict, 
                                       successful_agents: List[str], failed_agents: List[str]) -> Dict:
        """ì¢…í•©ì ì¸ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        
        analysis = {
            'analysis_type': 'comprehensive_sequential',
            'task_type': result.task_type,
            'execution_summary': {
                'successful_agents': successful_agents,
                'failed_agents': failed_agents,
                'total_agents': len(successful_agents) + len(failed_agents),
                'success_rate': len(successful_agents) / (len(successful_agents) + len(failed_agents)) if (successful_agents or failed_agents) else 0
            },
            'integrated_assessment': {},
            'recommendations': [],
            'risk_factors': [],
            'protective_factors': []
        }
        
        # ì„±ê³µí•œ ì—ì´ì „íŠ¸ë“¤ì˜ ê²°ê³¼ í†µí•©
        risk_scores = []
        confidence_scores = []
        
        # Structura ê²°ê³¼ í†µí•©
        if 'structura' in successful_agents and result.structura_result:
            structura_risk = result.structura_result.get('attrition_probability', 0)
            risk_scores.append(('structura', structura_risk, 0.4))  # ê°€ì¤‘ì¹˜ 40%
            confidence_scores.append(result.structura_result.get('confidence_score', 0))
            
            analysis['structura_insights'] = [
                f"ì´ì§ í™•ë¥ : {structura_risk:.1%}",
                f"ìœ„í—˜ ë²”ì£¼: {result.structura_result.get('risk_category', 'UNKNOWN')}",
                f"ì‹ ë¢°ë„: {result.structura_result.get('confidence_score', 0):.1%}"
            ]
        
        # Cognita ê²°ê³¼ í†µí•©
        if 'cognita' in successful_agents and result.cognita_result:
            cognita_data = result.cognita_result.get('risk_analysis', result.cognita_result)
            cognita_risk = cognita_data.get('overall_risk_score', 0)
            risk_scores.append(('cognita', cognita_risk, 0.3))  # ê°€ì¤‘ì¹˜ 30%
            
            analysis['cognita_insights'] = [
                f"ì¢…í•© ìœ„í—˜ë„: {cognita_risk:.3f}",
                f"ì‚¬íšŒì  ê³ ë¦½: {cognita_data.get('social_isolation_index', 0):.3f}",
                f"ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„±: {cognita_data.get('network_centrality_score', 0):.3f}"
            ]
        
        # ì¶”ê°€ ì—ì´ì „íŠ¸ ê²°ê³¼ í†µí•©
        if 'chronos' in successful_agents and result.chronos_result:
            chronos_risk = result.chronos_result.get('trend_score', 0)
            risk_scores.append(('chronos', chronos_risk, 0.15))  # ê°€ì¤‘ì¹˜ 15%
        
        if 'sentio' in successful_agents and result.sentio_result:
            sentio_risk = abs(result.sentio_result.get('sentiment_score', 0))  # ì ˆëŒ“ê°’ìœ¼ë¡œ ìœ„í—˜ë„ ë³€í™˜
            risk_scores.append(('sentio', sentio_risk, 0.1))  # ê°€ì¤‘ì¹˜ 10%
        
        if 'agora' in successful_agents and result.agora_result:
            agora_data = result.agora_result.get('market_analysis', result.agora_result)
            agora_risk = agora_data.get('market_pressure_index', 0)
            risk_scores.append(('agora', agora_risk, 0.05))  # ê°€ì¤‘ì¹˜ 5%
        
        # í†µí•© ìœ„í—˜ë„ ê³„ì‚°
        if risk_scores:
            weighted_risk = sum(score * weight for _, score, weight in risk_scores)
            total_weight = sum(weight for _, _, weight in risk_scores)
            integrated_risk = weighted_risk / total_weight if total_weight > 0 else 0
            
            # ìœ„í—˜ ë ˆë²¨ ê²°ì •
            if integrated_risk >= 0.7:
                risk_level = 'HIGH'
            elif integrated_risk >= 0.4:
                risk_level = 'MEDIUM'
            else:
                risk_level = 'LOW'
            
            analysis['integrated_assessment'] = {
                'integrated_risk_score': integrated_risk,
                'risk_level': risk_level,
                'confidence_score': sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0,
                'contributing_factors': [f"{agent}: {score:.3f}" for agent, score, _ in risk_scores],
                'data_completeness': len(successful_agents) / 5  # ì „ì²´ 5ê°œ ì—ì´ì „íŠ¸ ëŒ€ë¹„
            }
            
            # í†µí•© ê¶Œì¥ì‚¬í•­ ìƒì„±
            analysis['recommendations'] = self._generate_integrated_recommendations(
                integrated_risk, risk_level, successful_agents, accumulated_data
            )
        
        return analysis

    def _generate_integrated_recommendations(self, integrated_risk: float, risk_level: str, 
                                          successful_agents: List[str], accumulated_data: Dict) -> List[str]:
        """í†µí•© ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        # ìœ„í—˜ ë ˆë²¨ë³„ ê¸°ë³¸ ê¶Œì¥ì‚¬í•­
        if risk_level == 'HIGH':
            recommendations.extend([
                "ğŸš¨ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”: 1:1 ê¸´ê¸‰ ë©´ë‹´ ì‹¤ì‹œ",
                "ğŸ’° ë³´ìƒ íŒ¨í‚¤ì§€ ì¬ê²€í†  ë° ê°œì„  ë°©ì•ˆ ìˆ˜ë¦½",
                "ğŸ¯ ë‹¨ê¸° ë° ì¥ê¸° ê²½ë ¥ ê°œë°œ ê³„íš ë…¼ì˜"
            ])
        elif risk_level == 'MEDIUM':
            recommendations.extend([
                "âš ï¸ ì£¼ì˜ ê¹Šì€ ëª¨ë‹ˆí„°ë§ ë° ì •ê¸° ë©´ë‹´",
                "ğŸ“ˆ ì„±ì¥ ê¸°íšŒ ë° ì—­í•  í™•ëŒ€ ê²€í† ",
                "ğŸ¤ íŒ€ ë‚´ ì†Œí†µ ë° í˜‘ì—… ê°•í™”"
            ])
        else:
            recommendations.extend([
                "âœ… í˜„ì¬ ìƒíƒœ ìœ ì§€ ë° ì§€ì†ì  ë™ê¸°ë¶€ì—¬",
                "ğŸŒŸ ìš°ìˆ˜ ì„±ê³¼ ì¸ì • ë° ë¦¬ë”ì‹­ ê¸°íšŒ ì œê³µ"
            ])
        
        # ì—ì´ì „íŠ¸ë³„ íŠ¹í™” ê¶Œì¥ì‚¬í•­
        if 'structura' in successful_agents:
            structura_risk = accumulated_data.get('structura_risk_score', 0)
            if structura_risk > 0.6:
                recommendations.append("ğŸ“Š Structura ë¶„ì„: ê°œì¸ íŠ¹ì„± ê¸°ë°˜ ë§ì¶¤í˜• ê´€ë¦¬ í•„ìš”")
        
        if 'cognita' in successful_agents:
            social_isolation = accumulated_data.get('social_isolation', 0)
            if social_isolation > 0.5:
                recommendations.append("ğŸ¤ Cognita ë¶„ì„: ì‚¬íšŒì  ë„¤íŠ¸ì›Œí¬ ê°•í™” í”„ë¡œê·¸ë¨ ì°¸ì—¬")
        
        if 'agora' in successful_agents:
            market_pressure = accumulated_data.get('agora_market_pressure', 0)
            if market_pressure > 0.6:
                recommendations.append("ğŸ’¼ Agora ë¶„ì„: ì‹œì¥ ê²½ìŸë ¥ ìˆëŠ” ì¡°ê±´ ì¬ê²€í† ")
        
        return recommendations
    
    def _structura_heuristic_analysis(self, employee_data: Dict) -> Dict:
        """Structura íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ (ëª¨ë¸ ë¯¸í›ˆë ¨ ì‹œ)"""
        try:
            # ì•ˆì „í•œ ë°ì´í„° íƒ€ì… ë³€í™˜ í•¨ìˆ˜
            def safe_int(value, default=0):
                try:
                    if value is None or value == '':
                        return default
                    return int(float(str(value)))
                except (ValueError, TypeError):
                    return default
            
            def safe_float(value, default=0.0):
                try:
                    if value is None or value == '':
                        return default
                    return float(str(value))
                except (ValueError, TypeError):
                    return default
            
            # ì£¼ìš” ìœ„í—˜ ìš”ì¸ë“¤
            risk_score = 0.0
            risk_factors = []
            protective_factors = []
            
            # 1. ê¸‰ì—¬ ê´€ë ¨ (30% ê°€ì¤‘ì¹˜)
            monthly_income = safe_float(employee_data.get('MonthlyIncome'), 5000)
            if monthly_income < 3000:
                risk_score += 0.3
                risk_factors.append("ë‚®ì€ ê¸‰ì—¬ ìˆ˜ì¤€")
            elif monthly_income > 8000:
                protective_factors.append("ë†’ì€ ê¸‰ì—¬ ìˆ˜ì¤€")
            
            # 2. ì§ë¬´ ë§Œì¡±ë„ (25% ê°€ì¤‘ì¹˜)
            job_satisfaction = safe_int(employee_data.get('JobSatisfaction'), 2)
            if job_satisfaction <= 2:
                risk_score += 0.25
                risk_factors.append("ë‚®ì€ ì§ë¬´ ë§Œì¡±ë„")
            elif job_satisfaction >= 4:
                protective_factors.append("ë†’ì€ ì§ë¬´ ë§Œì¡±ë„")
            
            # 3. ê·¼ë¬´ í™˜ê²½ (20% ê°€ì¤‘ì¹˜)
            environment_satisfaction = safe_int(employee_data.get('EnvironmentSatisfaction'), 2)
            if environment_satisfaction <= 2:
                risk_score += 0.2
                risk_factors.append("ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ìš´ ê·¼ë¬´ í™˜ê²½")
            elif environment_satisfaction >= 4:
                protective_factors.append("ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê·¼ë¬´ í™˜ê²½")
            
            # 4. ì•¼ê·¼ ë¹ˆë„ (15% ê°€ì¤‘ì¹˜)
            overtime = str(employee_data.get('OverTime', 'No')).strip()
            if overtime.lower() in ['yes', 'y', '1', 'true']:
                risk_score += 0.15
                risk_factors.append("ì¦ì€ ì•¼ê·¼")
            else:
                protective_factors.append("ì ì ˆí•œ ê·¼ë¬´ ì‹œê°„")
            
            # 5. ê²½ë ¥ ë° ìŠ¹ì§„ (10% ê°€ì¤‘ì¹˜)
            years_since_promotion = safe_int(employee_data.get('YearsSinceLastPromotion'), 2)
            if years_since_promotion > 3:
                risk_score += 0.1
                risk_factors.append("ì¥ê¸°ê°„ ìŠ¹ì§„ ì—†ìŒ")
            elif years_since_promotion <= 1:
                protective_factors.append("ìµœê·¼ ìŠ¹ì§„")
            
            # ìœ„í—˜ë„ ë ˆë²¨ ê²°ì •
            if risk_score >= 0.7:
                risk_level = 'HIGH'
            elif risk_score >= 0.4:
                risk_level = 'MEDIUM'
            else:
                risk_level = 'LOW'
            
            # ì‹ ë¢°ë„ ê³„ì‚° (íœ´ë¦¬ìŠ¤í‹±ì´ë¯€ë¡œ ì¤‘ê°„ ìˆ˜ì¤€)
            confidence = 0.65
            
            return {
                'prediction': {
                    'attrition_probability': min(0.95, risk_score),
                    'risk_level': risk_level,
                    'confidence': confidence,
                    'note': 'Structura íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ ê²°ê³¼'
                },
                'explanation': {
                    'top_risk_factors': risk_factors[:3],
                    'top_protective_factors': protective_factors[:3],
                    'feature_importance': {
                        'MonthlyIncome': 0.3,
                        'JobSatisfaction': 0.25,
                        'EnvironmentSatisfaction': 0.2,
                        'OverTime': 0.15,
                        'YearsSinceLastPromotion': 0.1
                    },
                    'note': 'Structura íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ì„¤ëª…'
                },
                'agent_type': 'structura',
                'analysis_type': 'individual'
            }
            
        except Exception as e:
            logger.error(f"Structura íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            # ìµœì†Œí•œì˜ ê¸°ë³¸ê°’
            return {
                'prediction': {
                    'attrition_probability': 0.3,
                    'risk_level': 'MEDIUM',
                    'confidence': 0.5,
                    'note': 'Structura ë¶„ì„ ì˜¤ë¥˜ - ê¸°ë³¸ê°’'
                },
                'explanation': {
                    'top_risk_factors': ['ë¶„ì„ ì˜¤ë¥˜'],
                    'top_protective_factors': ['ê¸°ë³¸ ë³´í˜¸ ìš”ì¸'],
                    'feature_importance': {},
                    'note': 'Structura ë¶„ì„ ì˜¤ë¥˜'
                },
                'agent_type': 'structura',
                'analysis_type': 'individual'
            }
    
    def _train_structura_from_batch_data(self, structura_agent, batch_data: List[Dict]) -> bool:
        """ë°°ì¹˜ ë°ì´í„°ë¡œ Structura ëª¨ë¸ í•™ìŠµ"""
        try:
            import pandas as pd
            from sklearn.model_selection import train_test_split
            
            logger.info(f"ë°°ì¹˜ ë°ì´í„° {len(batch_data)}ê°œë¡œ Structura ëª¨ë¸ í•™ìŠµ ì‹œì‘")
            
            # 1. ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df = pd.DataFrame(batch_data)
            
            # 2. Attrition ë¼ë²¨ í™•ì¸
            if 'Attrition' not in df.columns:
                logger.error("Attrition ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ë¶ˆê°€ëŠ¥")
                return False
            
            # 3. í•™ìŠµ ë°ì´í„°ì™€ ë¼ë²¨ì´ ìˆëŠ”ì§€ í™•ì¸
            labeled_data = df[df['Attrition'].notna()]
            if len(labeled_data) < 10:  # ìµœì†Œ 10ê°œ ìƒ˜í”Œ í•„ìš”
                logger.warning(f"ë¼ë²¨ëœ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {len(labeled_data)}ê°œ")
                return False
            
            logger.info(f"ë¼ë²¨ëœ ë°ì´í„°: {len(labeled_data)}ê°œ (Yes: {(labeled_data['Attrition'] == 'Yes').sum()}ê°œ)")
            
            # 4. ì „ì²˜ë¦¬
            X, y = structura_agent.preprocess_data(labeled_data)
            
            # 5. í›ˆë ¨/ê²€ì¦ ë¶„í• 
            if len(X) < 20:
                # ë°ì´í„°ê°€ ì ìœ¼ë©´ ì „ì²´ë¥¼ í›ˆë ¨ì— ì‚¬ìš©
                X_train, y_train = X, y
                logger.info("ë°ì´í„°ê°€ ì ì–´ ì „ì²´ë¥¼ í›ˆë ¨ì— ì‚¬ìš©")
            else:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, stratify=y
                )
                logger.info(f"í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")
            
            # 6. ëª¨ë¸ í›ˆë ¨
            logger.info("XGBoost ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            hyperparams = {
                'n_estimators': min(100, len(X_train) * 2),  # ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ì¡°ì •
                'max_depth': 4,
                'learning_rate': 0.1,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'reg_alpha': 1,
                'reg_lambda': 1,
                'min_child_weight': 3
            }
            
            model = structura_agent.train_model(X_train, y_train, hyperparams)
            
            # 7. ê°„ë‹¨í•œ ì„±ëŠ¥ í™•ì¸
            if len(X) >= 20:
                from sklearn.metrics import roc_auc_score, accuracy_score
                y_pred_proba = structura_agent.predict(X_test, return_proba=True)
                y_pred = structura_agent.predict(X_test, return_proba=False)
                
                auc = roc_auc_score(y_test, y_pred_proba)
                acc = accuracy_score(y_test, y_pred)
                
                logger.info(f"ëª¨ë¸ ì„±ëŠ¥ - AUC: {auc:.3f}, Accuracy: {acc:.3f}")
            
            logger.info("âœ… ë°°ì¹˜ ë°ì´í„° í•™ìŠµ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ë°ì´í„° í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            
            # ê¸°ì¡´ ëª¨ë¸ ë¡œë”© ì‹œë„
            try:
                logger.info("ê¸°ì¡´ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë”© ì‹œë„...")
                model_paths = [
                    "hr_attrition_model.pkl",
                    "hr_attrition_model_xai.pkl",
                    "app/Structura/hr_attrition_model.pkl"
                ]
                
                for model_path in model_paths:
                    if os.path.exists(model_path):
                        structura_agent.load_model(model_path)
                        logger.info(f"âœ… ê¸°ì¡´ ëª¨ë¸ ë¡œë”© ì„±ê³µ: {model_path}")
                        return True
                
                # ê¸°ë³¸ ë°ì´í„°ë¡œ ê°„ë‹¨í•œ ëª¨ë¸ í›ˆë ¨ ì‹œë„
                logger.info("ê¸°ë³¸ ë°ì´í„°ë¡œ ê°„ë‹¨í•œ ëª¨ë¸ í›ˆë ¨ ì‹œë„...")
                if hasattr(structura_agent, 'data_path') and os.path.exists(structura_agent.data_path):
                    df = structura_agent.load_data()
                    X, y = structura_agent.preprocess_data(df)
                    
                    # ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¹ ë¥¸ í›ˆë ¨
                    sample_size = min(200, len(X))
                    X_sample = X.head(sample_size)
                    y_sample = y.head(sample_size)
                    
                    simple_params = {
                        'n_estimators': 50,
                        'max_depth': 3,
                        'learning_rate': 0.1
                    }
                    
                    structura_agent.train_model(X_sample, y_sample, simple_params)
                    logger.info("âœ… ê¸°ë³¸ ë°ì´í„°ë¡œ ê°„ë‹¨í•œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
                    return True
                    
            except Exception as fallback_e:
                logger.warning(f"ëŒ€ì•ˆ ì²˜ë¦¬ë„ ì‹¤íŒ¨: {str(fallback_e)}")
            
            return False
    
    def _chronos_heuristic_analysis(self, employee_data: Dict) -> Dict:
        """Chronos íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ (ì‹œê³„ì—´ ëª¨ë¸ ë¯¸í›ˆë ¨ ì‹œ)"""
        try:
            # ì§ì› íŠ¹ì„± ê¸°ë°˜ ì‹œê³„ì—´ íŒ¨í„´ ì¶”ì •
            trend_score = 0.5  # ê¸°ë³¸ê°’
            risk_factors = []
            
            # ì•ˆì „í•œ ë°ì´í„° íƒ€ì… ë³€í™˜ í•¨ìˆ˜
            def safe_int(value, default=0):
                try:
                    if value is None or value == '':
                        return default
                    return int(float(str(value)))  # ë¬¸ìì—´ â†’ ì‹¤ìˆ˜ â†’ ì •ìˆ˜ ë³€í™˜
                except (ValueError, TypeError):
                    return default
            
            # 1. ê·¼ë¬´ ì—°ìˆ˜ì™€ ì„±ê³¼ ê´€ë ¨ (40% ê°€ì¤‘ì¹˜)
            years_at_company = safe_int(employee_data.get('YearsAtCompany'), 5)
            performance_rating = safe_int(employee_data.get('PerformanceRating'), 3)
            
            if years_at_company < 2:  # ì‹ ì…ì‚¬ì›
                trend_score += 0.2
                risk_factors.append("ì‹ ì…ì‚¬ì› ì ì‘ ê¸°ê°„")
            elif years_at_company > 10 and performance_rating <= 3:
                trend_score += 0.3
                risk_factors.append("ì¥ê¸° ê·¼ë¬´ì ì„±ê³¼ ì •ì²´")
            
            # 2. ìŠ¹ì§„ ì£¼ê¸° (30% ê°€ì¤‘ì¹˜)
            years_since_promotion = safe_int(employee_data.get('YearsSinceLastPromotion'), 2)
            if years_since_promotion > 4:
                trend_score += 0.25
                risk_factors.append("ìŠ¹ì§„ ì •ì²´ë¡œ ì¸í•œ ë™ê¸° ì €í•˜")
            elif years_since_promotion <= 1:
                trend_score -= 0.1  # ë³´í˜¸ ìš”ì¸
            
            # 3. êµìœ¡ ë° ì„±ì¥ (20% ê°€ì¤‘ì¹˜)
            training_times = safe_int(employee_data.get('TrainingTimesLastYear'), 2)
            if training_times == 0:
                trend_score += 0.15
                risk_factors.append("êµìœ¡ ê¸°íšŒ ë¶€ì¡±")
            elif training_times >= 4:
                trend_score -= 0.1  # ë³´í˜¸ ìš”ì¸
            
            # 4. ì›Œë¼ë°¸ (10% ê°€ì¤‘ì¹˜)
            work_life_balance = safe_int(employee_data.get('WorkLifeBalance'), 2)
            if work_life_balance <= 2:
                trend_score += 0.1
                risk_factors.append("ì›Œë¼ë°¸ ë¶ˆê· í˜•")
            
            # íŠ¸ë Œë“œ íŒ¨í„´ ê²°ì •
            if trend_score >= 0.7:
                pattern = 'declining'
                confidence = 0.75
            elif trend_score >= 0.4:
                pattern = 'unstable'
                confidence = 0.65
            else:
                pattern = 'stable'
                confidence = 0.7
            
            return {
                'trend_score': min(0.95, max(0.05, trend_score)),
                'prediction_confidence': confidence,
                'time_series_pattern': pattern,
                'temporal_risk_factors': risk_factors[:3],
                'analysis_timestamp': datetime.now().isoformat(),
                'note': 'Chronos íœ´ë¦¬ìŠ¤í‹± ì‹œê³„ì—´ ë¶„ì„'
            }
            
        except Exception as e:
            logger.error(f"Chronos íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {
                'trend_score': 0.5,
                'prediction_confidence': 0.5,
                'time_series_pattern': 'stable',
                'temporal_risk_factors': ['ë¶„ì„ ì˜¤ë¥˜'],
                'analysis_timestamp': datetime.now().isoformat(),
                'note': 'Chronos ë¶„ì„ ì˜¤ë¥˜ - ê¸°ë³¸ê°’'
            }
    
    def _train_chronos_from_batch_data(self, chronos_agent, batch_timeseries_data: List[Dict]) -> bool:
        """ë°°ì¹˜ ì‹œê³„ì—´ ë°ì´í„°ë¡œ Chronos ëª¨ë¸ í•™ìŠµ"""
        try:
            import pandas as pd
            import numpy as np
            
            logger.info(f"ë°°ì¹˜ ì‹œê³„ì—´ ë°ì´í„° {len(batch_timeseries_data)}ê°œë¡œ Chronos ëª¨ë¸ í•™ìŠµ ì‹œì‘")
            
            # ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ (ê°„ë‹¨í•œ ë²„ì „)
            df = pd.DataFrame(batch_timeseries_data)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
            required_cols = ['employee_id', 'date', 'work_focused_ratio', 'meeting_collaboration_ratio']
            if not all(col in df.columns for col in required_cols):
                logger.warning("í•„ìš”í•œ ì‹œê³„ì—´ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤")
                return False
            
            # ê°„ë‹¨í•œ ì‹œê³„ì—´ íŠ¹ì„± ì¶”ì¶œ
            employee_features = []
            for emp_id in df['employee_id'].unique():
                emp_data = df[df['employee_id'] == emp_id].sort_values('date')
                
                if len(emp_data) >= 3:  # ìµœì†Œ 3ê°œì›” ë°ì´í„°
                    # íŠ¸ë Œë“œ ê³„ì‚°
                    work_trend = np.polyfit(range(len(emp_data)), emp_data['work_focused_ratio'], 1)[0]
                    collab_trend = np.polyfit(range(len(emp_data)), emp_data['meeting_collaboration_ratio'], 1)[0]
                    
                    # ë³€ë™ì„± ê³„ì‚°
                    work_volatility = emp_data['work_focused_ratio'].std()
                    collab_volatility = emp_data['meeting_collaboration_ratio'].std()
                    
                    employee_features.append({
                        'employee_id': emp_id,
                        'work_trend': work_trend,
                        'collab_trend': collab_trend,
                        'work_volatility': work_volatility,
                        'collab_volatility': collab_volatility
                    })
            
            if len(employee_features) < 10:
                logger.warning(f"ì‹œê³„ì—´ íŠ¹ì„± ë°ì´í„° ë¶€ì¡±: {len(employee_features)}ê°œ")
                return False
            
            logger.info(f"âœ… Chronos ì‹œê³„ì—´ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {len(employee_features)}ëª…")
            
            # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì‹œê³„ì—´ ëª¨ë¸ í•™ìŠµì´ í•„ìš”í•˜ì§€ë§Œ,
            # ì—¬ê¸°ì„œëŠ” íŠ¹ì„± ì¶”ì¶œ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
            return True
            
        except Exception as e:
            logger.error(f"Chronos ì‹œê³„ì—´ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _chronos_model_prediction(self, chronos_agent, employee_data: Dict) -> Dict:
        """í•™ìŠµëœ Chronos ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
        try:
            # ì‹¤ì œ ëª¨ë¸ ì˜ˆì¸¡ ë¡œì§ (ê°„ë‹¨í•œ ë²„ì „)
            # ì—¬ê¸°ì„œëŠ” íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í–¥ìƒëœ ê²°ê³¼ ë°˜í™˜
            heuristic_result = self._chronos_heuristic_analysis(employee_data)
            
            # ëª¨ë¸ í•™ìŠµ ì™„ë£Œ í‘œì‹œ
            heuristic_result['note'] = 'Chronos í•™ìŠµëœ ëª¨ë¸ ê¸°ë°˜ ì˜ˆì¸¡'
            heuristic_result['prediction_confidence'] = min(0.9, heuristic_result['prediction_confidence'] + 0.15)
            
            return heuristic_result
            
        except Exception as e:
            logger.error(f"Chronos ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            return self._chronos_heuristic_analysis(employee_data)
    
    def _generate_timeseries_from_batch_data(self, employees: List[Dict]) -> List[Dict]:
        """ë°°ì¹˜ ë°ì´í„°ì—ì„œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)"""
        try:
            import numpy as np
            from datetime import datetime, timedelta
            
            # ì•ˆì „í•œ ë°ì´í„° íƒ€ì… ë³€í™˜ í•¨ìˆ˜
            def safe_int(value, default=0):
                try:
                    if value is None or value == '':
                        return default
                    return int(float(str(value)))
                except (ValueError, TypeError):
                    return default
            
            timeseries_data = []
            
            for employee in employees:
                employee_id = employee.get('EmployeeNumber', employee.get('employee_id', 'unknown'))
                attrition = str(employee.get('Attrition', 'No')).strip()
                
                # ì§ì› íŠ¹ì„± ê¸°ë°˜ ì‹œê³„ì—´ íŒ¨í„´ ìƒì„± (ì•ˆì „í•œ íƒ€ì… ë³€í™˜)
                years_at_company = safe_int(employee.get('YearsAtCompany'), 5)
                job_satisfaction = safe_int(employee.get('JobSatisfaction'), 3)
                performance_rating = safe_int(employee.get('PerformanceRating'), 3)
                overtime = str(employee.get('OverTime', 'No')).strip()
                
                # 6ê°œì›”ê°„ì˜ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
                base_date = datetime(2024, 1, 1)
                
                for month in range(6):
                    date = base_date + timedelta(days=month * 30)
                    
                    # ê¸°ë³¸ ì„±ê³¼ ì§€í‘œ
                    base_work_focused = 0.7
                    base_meeting_collab = 0.6
                    
                    # ì§ì› íŠ¹ì„± ë°˜ì˜
                    if job_satisfaction >= 4:
                        base_work_focused += 0.1
                        base_meeting_collab += 0.1
                    elif job_satisfaction <= 2:
                        base_work_focused -= 0.15
                        base_meeting_collab -= 0.1
                    
                    if performance_rating >= 4:
                        base_work_focused += 0.1
                    elif performance_rating <= 2:
                        base_work_focused -= 0.1
                    
                    if overtime.lower() in ['yes', 'y', '1', 'true']:
                        base_work_focused -= 0.05  # ì•¼ê·¼ìœ¼ë¡œ ì¸í•œ íš¨ìœ¨ì„± ì €í•˜
                        base_meeting_collab -= 0.05
                    
                    # ì´ì§ìì˜ ê²½ìš° ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì„±ê³¼ ì €í•˜
                    if attrition.lower() in ['yes', 'y', '1', 'true']:
                        decline_factor = month * 0.08  # ì›”ë³„ 8% ì €í•˜
                        base_work_focused -= decline_factor
                        base_meeting_collab -= decline_factor * 0.6
                    
                    # ë…¸ì´ì¦ˆ ì¶”ê°€
                    work_focused = max(0.1, min(0.95, base_work_focused + np.random.normal(0, 0.05)))
                    meeting_collab = max(0.1, min(0.95, base_meeting_collab + np.random.normal(0, 0.05)))
                    
                    timeseries_data.append({
                        'employee_id': str(employee_id),
                        'date': date.strftime('%Y-%m-%d'),
                        'work_focused_ratio': round(work_focused, 3),
                        'meeting_collaboration_ratio': round(meeting_collab, 3),
                        'attrition': attrition
                    })
            
            logger.info(f"ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(timeseries_data)}ê°œ ë ˆì½”ë“œ")
            return timeseries_data
            
        except Exception as e:
            logger.error(f"ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _create_combined_analysis(self, structura_result, cognita_result, chronos_result, sentio_result, agora_result) -> Dict:
        """ê°œë³„ ì—ì´ì „íŠ¸ ê²°ê³¼ë“¤ì„ í†µí•©í•˜ì—¬ ì¢…í•© ë¶„ì„ ìƒì„±"""
        try:
            # ê¸°ë³¸ í†µí•© ë¶„ì„ êµ¬ì¡°
            combined_analysis = {
                'analysis_type': 'comprehensive_sequential',
                'task_type': 'individual_analysis',
                'execution_summary': {
                    'total_agents': 5,
                    'successful_agents': [],
                    'failed_agents': [],
                    'success_rate': 0
                },
                'integrated_assessment': {},
                'risk_factors': [],
                'protective_factors': [],
                'recommendations': []
            }
            
            # ê° ì—ì´ì „íŠ¸ ê²°ê³¼ í™•ì¸ ë° í†µí•©
            results = {
                'structura': structura_result,
                'cognita': cognita_result,
                'chronos': chronos_result,
                'sentio': sentio_result,
                'agora': agora_result
            }
            
            risk_scores = []
            
            for agent_name, result in results.items():
                if result and isinstance(result, dict):
                    combined_analysis['execution_summary']['successful_agents'].append(agent_name)
                    
                    # ê° ì—ì´ì „íŠ¸ë³„ ìœ„í—˜ë„ ì¶”ì¶œ
                    if agent_name == 'structura' and 'prediction' in result:
                        risk_score = result['prediction'].get('attrition_probability', 0.5)
                        risk_scores.append(risk_score)
                        combined_analysis['integrated_assessment']['structura_risk'] = risk_score
                        
                        # ìœ„í—˜ ìš”ì¸ ì¶”ê°€
                        if 'explanation' in result and 'top_risk_factors' in result['explanation']:
                            combined_analysis['risk_factors'].extend(result['explanation']['top_risk_factors'][:2])
                    
                    elif agent_name == 'cognita' and 'risk_analysis' in result:
                        risk_score = result['risk_analysis'].get('overall_risk_score', 0.5)
                        risk_scores.append(risk_score)
                        combined_analysis['integrated_assessment']['cognita_risk'] = risk_score
                    
                    elif agent_name == 'chronos':
                        trend_score = result.get('trend_score', 0.5)
                        risk_scores.append(trend_score)
                        combined_analysis['integrated_assessment']['chronos_trend'] = trend_score
                        
                        # ì‹œê³„ì—´ ìœ„í—˜ ìš”ì¸ ì¶”ê°€
                        if 'temporal_risk_factors' in result:
                            combined_analysis['risk_factors'].extend(result['temporal_risk_factors'][:2])
                    
                    elif agent_name == 'sentio':
                        sentiment_score = result.get('sentiment_score', 0.0)
                        # ê°ì • ì ìˆ˜ë¥¼ ìœ„í—˜ë„ë¡œ ë³€í™˜ (ìŒìˆ˜ì¼ìˆ˜ë¡ ìœ„í—˜)
                        sentiment_risk = max(0, -sentiment_score + 0.5)
                        risk_scores.append(sentiment_risk)
                        combined_analysis['integrated_assessment']['sentio_sentiment'] = sentiment_risk
                    
                    elif agent_name == 'agora' and 'market_analysis' in result:
                        market_pressure = result['market_analysis'].get('market_pressure_index', 0.5)
                        risk_scores.append(market_pressure)
                        combined_analysis['integrated_assessment']['agora_market_pressure'] = market_pressure
                else:
                    combined_analysis['execution_summary']['failed_agents'].append(agent_name)
            
            # ì„±ê³µë¥  ê³„ì‚°
            success_count = len(combined_analysis['execution_summary']['successful_agents'])
            combined_analysis['execution_summary']['success_rate'] = success_count / 5
            
            # í†µí•© ìœ„í—˜ë„ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
            if risk_scores:
                # ê¸°ë³¸ ê°€ì¤‘ì¹˜ (ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆìŒ)
                weights = [0.3216, 0.1, 0.369, 0.1, 0.1094]  # structura, cognita, chronos, sentio, agora
                
                weighted_risk = 0
                total_weight = 0
                
                for i, score in enumerate(risk_scores):
                    if i < len(weights):
                        weighted_risk += score * weights[i]
                        total_weight += weights[i]
                
                if total_weight > 0:
                    overall_risk = weighted_risk / total_weight
                else:
                    overall_risk = sum(risk_scores) / len(risk_scores)
                
                combined_analysis['integrated_assessment']['overall_risk_score'] = overall_risk
                
                # ìœ„í—˜ë„ ë ˆë²¨ ê²°ì •
                if overall_risk >= 0.7:
                    risk_level = 'HIGH'
                elif overall_risk >= 0.4:
                    risk_level = 'MEDIUM'
                else:
                    risk_level = 'LOW'
                
                combined_analysis['integrated_assessment']['overall_risk_level'] = risk_level
            else:
                combined_analysis['integrated_assessment']['overall_risk_score'] = 0.5
                combined_analysis['integrated_assessment']['overall_risk_level'] = 'MEDIUM'
            
            # ê¸°ë³¸ ê¶Œì¥ì‚¬í•­ ì¶”ê°€
            if combined_analysis['integrated_assessment']['overall_risk_level'] == 'HIGH':
                combined_analysis['recommendations'] = [
                    "ì¦‰ì‹œ ê°œë³„ ë©´ë‹´ì„ í†µí•œ ì´ì§ ì˜ë„ íŒŒì•…",
                    "ì—…ë¬´ í™˜ê²½ ê°œì„  ë° ë™ê¸°ë¶€ì—¬ ë°©ì•ˆ ë§ˆë ¨",
                    "ê²½ë ¥ ê°œë°œ ê¸°íšŒ ì œê³µ ê²€í† "
                ]
            elif combined_analysis['integrated_assessment']['overall_risk_level'] == 'MEDIUM':
                combined_analysis['recommendations'] = [
                    "ì •ê¸°ì ì¸ ë§Œì¡±ë„ ì¡°ì‚¬ ì‹¤ì‹œ",
                    "ì—…ë¬´ ë¶€ë‹´ ì¡°ì • ê²€í† ",
                    "íŒ€ ë‚´ ì†Œí†µ ê°•í™”"
                ]
            else:
                combined_analysis['recommendations'] = [
                    "í˜„ì¬ ìƒíƒœ ìœ ì§€",
                    "ì§€ì†ì ì¸ ì„±ê³¼ ê´€ë¦¬",
                    "ë¦¬ë”ì‹­ ê¸°íšŒ ì œê³µ ê²€í† "
                ]
            
            return combined_analysis
            
        except Exception as e:
            logger.error(f"í†µí•© ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                'analysis_type': 'comprehensive_sequential',
                'execution_summary': {'total_agents': 5, 'successful_agents': [], 'failed_agents': [], 'success_rate': 0},
                'integrated_assessment': {'overall_risk_score': 0.5, 'overall_risk_level': 'MEDIUM'},
                'risk_factors': [],
                'protective_factors': [],
                'recommendations': ['ë¶„ì„ ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ê¶Œì¥ì‚¬í•­']
            }
    
    def _execute_structura_task(self, task: AgenticTask) -> Dict:
        """Structura ì›Œì»¤ ì‘ì—… ì‹¤í–‰"""
        try:
            logger.info(f"Structura ì‘ì—… ì‹¤í–‰ ì‹œì‘: {task.task_id}")
            
            if 'structura' not in self.workers:
                raise Exception("Structura ì›Œì»¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            structura_agent = self.workers['structura']['agent']
            if not structura_agent:
                raise Exception("Structura ì—ì´ì „íŠ¸ê°€ Noneì…ë‹ˆë‹¤")
            
            if task.task_type == 'individual_analysis' and task.employee_data:
                logger.info(f"Structura ê°œë³„ ì§ì› ë¶„ì„: {task.employee_data.get('EmployeeNumber', 'Unknown')}")
                
                # ëª¨ë¸ ìƒíƒœ í™•ì¸ ë° ë™ì  í•™ìŠµ
                if not hasattr(structura_agent, 'model') or structura_agent.model is None:
                    logger.info("Structura ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•ŠìŒ. ë°°ì¹˜ ë°ì´í„°ë¡œ í•™ìŠµ ì‹œë„")
                    
                    # ë°°ì¹˜ ë°ì´í„°ì—ì„œ í•™ìŠµ ë°ì´í„° ì¶”ì¶œ ì‹œë„
                    if hasattr(task, 'batch_training_data') and task.batch_training_data:
                        try:
                            logger.info("ë°°ì¹˜ ë°ì´í„°ë¡œ Structura ëª¨ë¸ í•™ìŠµ ì¤‘...")
                            training_success = self._train_structura_from_batch_data(structura_agent, task.batch_training_data)
                            
                            if training_success:
                                logger.info("ë°°ì¹˜ ë°ì´í„° í•™ìŠµ ì„±ê³µ! ì •ìƒ ì˜ˆì¸¡ ì§„í–‰")
                                prediction_result = structura_agent.predict_single(task.employee_data)
                                explanation_result = structura_agent.explain_prediction(task.employee_data)
                                
                                result = {
                                    'prediction': prediction_result.to_dict(),
                                    'explanation': explanation_result.to_dict(),
                                    'agent_type': 'structura',
                                    'analysis_type': 'individual',
                                    'note': 'ë°°ì¹˜ ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©'
                                }
                                logger.info(f"Structura ì‘ì—… ì™„ë£Œ (ë°°ì¹˜ í•™ìŠµ): {task.task_id}")
                                return result
                        except Exception as e:
                            logger.warning(f"ë°°ì¹˜ ë°ì´í„° í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
                    
                    # í•™ìŠµ ì‹¤íŒ¨ ì‹œ íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ í´ë°±
                    logger.warning("ë°°ì¹˜ í•™ìŠµ ì‹¤íŒ¨. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                    result = self._structura_heuristic_analysis(task.employee_data)
                    logger.info(f"Structura ì‘ì—… ì™„ë£Œ (íœ´ë¦¬ìŠ¤í‹±): {task.task_id}")
                    return result
                
                # ì •ìƒ ë¶„ì„ (ëª¨ë¸ ìƒíƒœ ì¬í™•ì¸)
                if hasattr(structura_agent, 'model') and structura_agent.model is not None:
                    prediction_result = structura_agent.predict_single(task.employee_data)
                    explanation_result = structura_agent.explain_prediction(task.employee_data)
                else:
                    # ëª¨ë¸ì´ ì—¬ì „íˆ ì—†ìœ¼ë©´ íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ í´ë°±
                    logger.warning("ëª¨ë¸ì´ ì—¬ì „íˆ ì—†ìŠµë‹ˆë‹¤. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                    result = self._structura_heuristic_analysis(task.employee_data)
                    logger.info(f"Structura ì‘ì—… ì™„ë£Œ (íœ´ë¦¬ìŠ¤í‹±): {task.task_id}")
                    return result
                
                result = {
                    'prediction': prediction_result.to_dict(),
                    'explanation': explanation_result.to_dict(),
                    'agent_type': 'structura',
                    'analysis_type': 'individual'
                }
                
                logger.info(f"Structura ì‘ì—… ì™„ë£Œ: {task.task_id}")
                return result
                
            elif task.task_type == 'department_analysis' and task.department_name:
                # ë¶€ì„œ ë¶„ì„ (StructuraëŠ” ê°œë³„ ì§ì› ê¸°ë°˜ì´ë¯€ë¡œ ì‹œë®¬ë ˆì´ì…˜)
                result = {
                    'message': 'StructuraëŠ” ê°œë³„ ì§ì› ë¶„ì„ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.',
                    'agent_type': 'structura',
                    'analysis_type': 'department',
                    'recommendation': 'ë¶€ì„œë³„ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ê°œë³„ ì§ì› ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
                }
                logger.info(f"Structura ë¶€ì„œ ë¶„ì„ ì™„ë£Œ: {task.task_id}")
                return result
            else:
                raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… ìœ í˜•: {task.task_type}")
                
        except Exception as e:
            logger.error(f"Structura ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {task.task_id} - {str(e)}")
            raise
    
    def _execute_cognita_task(self, task: AgenticTask) -> Dict:
        """Cognita ì›Œì»¤ ì‘ì—… ì‹¤í–‰"""
        try:
            logger.info(f"Cognita ì‘ì—… ì‹¤í–‰ ì‹œì‘: {task.task_id}")
            
            if 'cognita' not in self.workers:
                raise Exception("Cognita ì›Œì»¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            cognita_agent = self.workers['cognita']['agent']
            if not cognita_agent:
                raise Exception("Cognita ì—ì´ì „íŠ¸ê°€ Noneì…ë‹ˆë‹¤")
            
            if task.task_type == 'individual_analysis' and task.employee_data:
                # ê°œë³„ ì§ì› ë¶„ì„ (employee_id í•„ìš”)
                employee_id = task.employee_data.get('employee_id') or task.employee_data.get('EmployeeNumber', '1')
                logger.info(f"Cognita ê°œë³„ ì§ì› ë¶„ì„: {employee_id}")
                
                risk_metrics = cognita_agent.analyze_employee_risk(str(employee_id))
                
                result = {
                    'risk_analysis': asdict(risk_metrics),
                    'agent_type': 'cognita',
                    'analysis_type': 'individual'
                }
                
                logger.info(f"Cognita ì‘ì—… ì™„ë£Œ: {task.task_id}")
                return result
        
            elif task.task_type == 'department_analysis' and task.department_name:
                # ë¶€ì„œ ë¶„ì„
                sample_size = task.sample_size or 20
                logger.info(f"Cognita ë¶€ì„œ ë¶„ì„: {task.department_name}, ìƒ˜í”Œ í¬ê¸°: {sample_size}")
                
                risk_analyses = cognita_agent.batch_analyze_department(task.department_name, sample_size)
                
                if risk_analyses:
                    report = cognita_agent.generate_risk_report(risk_analyses)
                    result = {
                        'department_report': report,
                        'agent_type': 'cognita',
                        'analysis_type': 'department',
                        'analyzed_employees': len(risk_analyses)
                    }
                    logger.info(f"Cognita ë¶€ì„œ ë¶„ì„ ì™„ë£Œ: {task.task_id}")
                    return result
                else:
                    result = {
                        'message': f'ë¶€ì„œ "{task.department_name}"ì—ì„œ ë¶„ì„í•  ì§ì›ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                        'agent_type': 'cognita',
                        'analysis_type': 'department'
                    }
                    logger.warning(f"Cognita ë¶€ì„œ ë¶„ì„ - ì§ì› ì—†ìŒ: {task.task_id}")
                    return result
            else:
                raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… ìœ í˜•: {task.task_type}")
                
        except Exception as e:
            logger.error(f"Cognita ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {task.task_id} - {str(e)}")
            raise
    
    def _execute_agora_task(self, task: AgenticTask) -> Dict:
        """Agora ì›Œì»¤ ì‘ì—… ì‹¤í–‰"""
        try:
            logger.info(f"Agora ì‘ì—… ì‹¤í–‰ ì‹œì‘: {task.task_id}")
            
            if 'agora' not in self.workers:
                raise Exception("Agora ì›Œì»¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            agora_agent = self.workers['agora']['agent']
            if not agora_agent:
                raise Exception("Agora ì—ì´ì „íŠ¸ê°€ Noneì…ë‹ˆë‹¤")
            
            if task.task_type == 'individual_analysis' and task.employee_data:
                logger.info(f"Agora ê°œë³„ ì§ì› ë¶„ì„: {task.employee_data.get('EmployeeNumber', 'Unknown')}")
                
                # ê°œë³„ ì§ì› ì‹œì¥ ë¶„ì„
                analyzer = agora_agent.get('analyzer')
                if analyzer:
                    market_analysis = analyzer.analyze_employee_market(
                        employee_data=task.employee_data,
                        include_llm=task.market_data.get('use_llm', False) if task.market_data else False
                    )
                    
                    result = {
                        'market_analysis': market_analysis,
                        'agent_type': 'agora',
                        'analysis_type': 'individual'
                    }
                    
                    logger.info(f"Agora ì‘ì—… ì™„ë£Œ: {task.task_id}")
                    return result
                else:
                    # ë¶„ì„ê¸°ê°€ ì—†ìœ¼ë©´ í”„ë¡œì„¸ì„œë§Œ ì‚¬ìš©
                    processor = agora_agent.get('processor')
                    if processor:
                        job_role = task.employee_data.get('JobRole', '')
                        monthly_income = task.employee_data.get('MonthlyIncome', 0)
                        
                        market_pressure = processor.calculate_market_pressure_index(job_role, monthly_income)
                        compensation_gap = processor.calculate_compensation_gap(job_role, monthly_income)
                        
                        result = {
                            'market_analysis': {
                                'market_pressure_index': market_pressure,
                                'compensation_gap': compensation_gap,
                                'job_role': job_role,
                                'risk_level': 'HIGH' if market_pressure > 0.7 else 'MEDIUM' if market_pressure > 0.4 else 'LOW'
                            },
                            'agent_type': 'agora',
                            'analysis_type': 'individual'
                        }
                        
                        logger.info(f"Agora ì‘ì—… ì™„ë£Œ (í”„ë¡œì„¸ì„œ): {task.task_id}")
                        return result
        
            elif task.task_type == 'department_analysis' and task.department_name:
                # ë¶€ì„œë³„ ì‹œì¥ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
                result = {
                    'message': f'ë¶€ì„œ "{task.department_name}"ì˜ ì‹œì¥ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ê°œë³„ ì§ì› ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
                    'agent_type': 'agora',
                    'analysis_type': 'department',
                    'recommendation': 'ê°œë³„ ì§ì›ë³„ë¡œ ì‹œì¥ ë¶„ì„ì„ ìˆ˜í–‰í•œ í›„ ë¶€ì„œ ë‹¨ìœ„ë¡œ ì§‘ê³„í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.'
                }
                logger.info(f"Agora ë¶€ì„œ ë¶„ì„ ì™„ë£Œ: {task.task_id}")
                return result
            
            else:
                raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… ìœ í˜•: {task.task_type}")
                
        except Exception as e:
            logger.error(f"Agora ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {task.task_id} - {str(e)}")
            raise

    def _execute_chronos_task(self, task: AgenticTask) -> Dict:
        """Chronos ì›Œì»¤ ì‘ì—… ì‹¤í–‰ (ì‹œê³„ì—´ ë¶„ì„)"""
        try:
            logger.info(f"Chronos ì‘ì—… ì‹¤í–‰ ì‹œì‘: {task.task_id}")
            
            # Chronos ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ë° ë™ì  í•™ìŠµ
            if 'chronos' not in self.workers or not self.workers['chronos']['agent']:
                logger.warning("Chronos ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ ìˆ˜í–‰")
                return self._chronos_heuristic_analysis(task.employee_data)
            
            chronos_agent = self.workers['chronos']['agent']
            
            # ëª¨ë¸ ìƒíƒœ í™•ì¸ ë° ë™ì  í•™ìŠµ
            if not hasattr(chronos_agent, 'model') or chronos_agent.model is None:
                logger.info("Chronos ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•ŠìŒ. ë°°ì¹˜ ë°ì´í„°ë¡œ í•™ìŠµ ì‹œë„")
                
                # ë°°ì¹˜ ë°ì´í„°ì—ì„œ ì‹œê³„ì—´ í•™ìŠµ ë°ì´í„° ì¶”ì¶œ ì‹œë„
                if hasattr(task, 'batch_timeseries_data') and task.batch_timeseries_data:
                    try:
                        logger.info("ë°°ì¹˜ ì‹œê³„ì—´ ë°ì´í„°ë¡œ Chronos ëª¨ë¸ í•™ìŠµ ì¤‘...")
                        training_success = self._train_chronos_from_batch_data(chronos_agent, task.batch_timeseries_data)
                        
                        if training_success:
                            logger.info("ë°°ì¹˜ ì‹œê³„ì—´ í•™ìŠµ ì„±ê³µ! ì •ìƒ ì˜ˆì¸¡ ì§„í–‰")
                            # ì‹¤ì œ Chronos ëª¨ë¸ ì˜ˆì¸¡ ë¡œì§ (êµ¬í˜„ í•„ìš”)
                            return self._chronos_model_prediction(chronos_agent, task.employee_data)
                    except Exception as e:
                        logger.warning(f"ë°°ì¹˜ ì‹œê³„ì—´ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
                
                # í•™ìŠµ ì‹¤íŒ¨ ì‹œ íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ í´ë°±
                logger.warning("ë°°ì¹˜ ì‹œê³„ì—´ í•™ìŠµ ì‹¤íŒ¨. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                return self._chronos_heuristic_analysis(task.employee_data)
            
            # ì‹œê³„ì—´ ë¶„ì„ ì‹¤í–‰ (ì‹¤ì œ êµ¬í˜„ ì‹œ Chronos ì—ì´ì „íŠ¸ ë¡œì§ ì‚¬ìš©)
            chronos_result = {
                'trend_score': 0.65,  # ì´ì „ ë‹¨ê³„ ê²°ê³¼ë¥¼ ê³ ë ¤í•œ íŠ¸ë Œë“œ ì ìˆ˜
                'prediction_confidence': 0.78,
                'time_series_pattern': 'declining' if getattr(task, 'structura_risk_score', 0) > 0.5 else 'stable',
                'temporal_risk_factors': ['workload_increase', 'performance_decline'],
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            logger.info(f"Chronos ì‹œê³„ì—´ ë¶„ì„ ì™„ë£Œ: {task.task_id}")
            return chronos_result
            
        except Exception as e:
            logger.error(f"Chronos ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {task.task_id} - {str(e)}")
            return {
                'error': str(e),
                'trend_score': 0.5,
                'analysis_timestamp': datetime.now().isoformat()
            }

    def _execute_sentio_task(self, task: AgenticTask) -> Dict:
        """Sentio ì›Œì»¤ ì‘ì—… ì‹¤í–‰ (í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„)"""
        try:
            logger.info(f"Sentio ì‘ì—… ì‹¤í–‰ ì‹œì‘: {task.task_id}")
            
            # Sentio ì—ì´ì „íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
            if 'sentio' not in self.workers or not self.workers['sentio']['agent']:
                logger.warning("Sentio ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return {
                    'sentiment_score': 0.0,
                    'risk_keywords': [],
                    'emotional_state': 'neutral',
                    'analysis_timestamp': datetime.now().isoformat(),
                    'note': 'Sentio ì—ì´ì „íŠ¸ ë¯¸ì‚¬ìš© - ê¸°ë³¸ê°’'
                }
            
            # ì´ì „ ë‹¨ê³„ ê²°ê³¼ë¥¼ ê³ ë ¤í•œ ê°ì • ë¶„ì„
            overall_risk = max(
                getattr(task, 'structura_risk_score', 0),
                getattr(task, 'cognita_risk_score', 0),
                getattr(task, 'chronos_trend', 0)
            )
            
            # ê°ì • ë¶„ì„ ì‹¤í–‰ (ì‹¤ì œ êµ¬í˜„ ì‹œ Sentio ì—ì´ì „íŠ¸ ë¡œì§ ì‚¬ìš©)
            sentio_result = {
                'sentiment_score': -0.2 if overall_risk > 0.6 else 0.1,
                'risk_keywords': ['stress', 'workload'] if overall_risk > 0.5 else ['satisfaction', 'team'],
                'emotional_state': 'negative' if overall_risk > 0.6 else 'neutral_positive',
                'confidence_score': 0.82,
                'text_analysis_summary': f"ì „ë°˜ì  ìœ„í—˜ë„ {overall_risk:.2f}ë¥¼ ë°˜ì˜í•œ ê°ì • ìƒíƒœ ë¶„ì„",
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            logger.info(f"Sentio í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì™„ë£Œ: {task.task_id}")
            return sentio_result
            
        except Exception as e:
            logger.error(f"Sentio ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {task.task_id} - {str(e)}")
            return {
                'error': str(e),
                'sentiment_score': 0.0,
                'analysis_timestamp': datetime.now().isoformat()
            }
    
    def _combine_analysis_results(self, structura_result: Dict, cognita_result: Dict, task: AgenticTask) -> Dict:
        """ë‘ ì›Œì»¤ ì—ì´ì „íŠ¸ ê²°ê³¼ ê²°í•© ë¶„ì„"""
        
        combined = {
            'analysis_type': 'combined',
            'task_type': task.task_type,
            'structura_insights': [],
            'cognita_insights': [],
            'integrated_assessment': {},
            'recommendations': []
        }
        
        if task.task_type == 'individual_analysis':
            # ê°œë³„ ì§ì› í†µí•© ë¶„ì„
            
            # Structura ì¸ì‚¬ì´íŠ¸
            if 'prediction' in structura_result:
                pred = structura_result['prediction']
                combined['structura_insights'] = [
                    f"ì´ì§ í™•ë¥ : {pred['attrition_probability']:.1%}",
                    f"ìœ„í—˜ ë²”ì£¼: {pred['risk_category']}",
                    f"ì‹ ë¢°ë„: {pred['confidence_score']:.1%}"
                ]
            
            # Cognita ì¸ì‚¬ì´íŠ¸
            if 'risk_analysis' in cognita_result:
                risk = cognita_result['risk_analysis']
                combined['cognita_insights'] = [
                    f"ì¢…í•© ìœ„í—˜ë„: {risk['overall_risk_score']:.3f}",
                    f"ì‚¬íšŒì  ê³ ë¦½: {risk['social_isolation_index']:.3f}",
                    f"ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„±: {risk['network_centrality_score']:.3f}"
                ]
            
            # í†µí•© í‰ê°€
            structura_prob = structura_result.get('prediction', {}).get('attrition_probability', 0)
            cognita_risk = cognita_result.get('risk_analysis', {}).get('overall_risk_score', 0)
            
            # ê°€ì¤‘ í‰ê·  (Structura 60%, Cognita 40%)
            integrated_risk = (structura_prob * 0.6) + (cognita_risk * 0.4)
            
            combined['integrated_assessment'] = {
                'integrated_risk_score': integrated_risk,
                'risk_level': 'HIGH' if integrated_risk >= 0.7 else 'MEDIUM' if integrated_risk >= 0.4 else 'LOW',
                'structura_weight': 0.6,
                'cognita_weight': 0.4,
                'consensus': 'HIGH' if structura_prob > 0.6 and cognita_risk > 0.6 else 'MIXED'
            }
            
            # í†µí•© ê¶Œì¥ì‚¬í•­
            if integrated_risk >= 0.7:
                combined['recommendations'] = [
                    "ì¦‰ì‹œ 1:1 ë©´ë‹´ ì‹¤ì‹œ",
                    "ì—…ë¬´ í™˜ê²½ ê°œì„  ë°©ì•ˆ ê²€í† ",
                    "íŒ€ ë‚´ ì—­í•  ë° ê´€ê³„ ê°œì„ "
                ]
            elif integrated_risk >= 0.4:
                combined['recommendations'] = [
                    "ì •ê¸°ì  ëª¨ë‹ˆí„°ë§ ê°•í™”",
                    "ë©˜í† ë§ í”„ë¡œê·¸ë¨ ì°¸ì—¬ ê²€í† ",
                    "ì—…ë¬´ ë§Œì¡±ë„ ê°œì„  ë°©ì•ˆ ëª¨ìƒ‰"
                ]
            else:
                combined['recommendations'] = [
                    "í˜„ì¬ ìƒíƒœ ìœ ì§€",
                    "ì§€ì†ì  ê´€ì°°",
                    "ê¸ì •ì  ìš”ì¸ ê°•í™”"
                ]
        
        return combined

# ------------------------------------------------------
# Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
# ------------------------------------------------------

def create_app():
    """Flask ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ©í† ë¦¬"""
    
    app = Flask(__name__)
    
    # CORS ì„¤ì • (React ì—°ë™)
    CORS(app, resources={
        r"/*": {
            "origins": ["http://localhost:3000", "http://127.0.0.1:3000"],
            "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
            "allow_headers": ["Content-Type", "Authorization", "Access-Control-Allow-Origin"],
            "supports_credentials": True
        }
    })
    
    # ì„¤ì •
    app.config['JSON_AS_ASCII'] = False
    app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True
    app.config['MAX_CONTENT_LENGTH'] = 300 * 1024 * 1024  # 300MB íŒŒì¼ ì—…ë¡œë“œ ì œí•œ
    
    # ì›Œì»¤ ì—ì´ì „íŠ¸ ê´€ë¦¬ì
    worker_manager = None
    
    # ------------------------------------------------------
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”
    # ------------------------------------------------------
    
    def initialize_services():
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        nonlocal worker_manager
        
        try:
            logger.info("Agentic AI Master Server ì´ˆê¸°í™” ì¤‘...")
            
            # ì›Œì»¤ ì—ì´ì „íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™”
            worker_manager = WorkerAgentManager()
            
            # Flask ì•±ì— ì €ì¥
            app.worker_manager = worker_manager
            
            logger.info("Agentic AI Master Server ì¤€ë¹„ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    
    # ì•± ìƒì„± ì‹œ ì¦‰ì‹œ ì´ˆê¸°í™”
    initialize_services()
    
    # ------------------------------------------------------
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    # ------------------------------------------------------
    
    def get_worker_manager():
        """ì›Œì»¤ ê´€ë¦¬ì ê°€ì ¸ì˜¤ê¸°"""
        if not hasattr(app, 'worker_manager') or app.worker_manager is None:
            return None
        return app.worker_manager
    
    # ------------------------------------------------------
    # ì—ëŸ¬ í•¸ë“¤ëŸ¬
    # ------------------------------------------------------
    
    @app.errorhandler(404)
    def not_found(error):
        return jsonify({
            "error": "Not Found",
            "message": "ìš”ì²­í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            "status_code": 404
        }), 404
    
    @app.errorhandler(500)
    def internal_error(error):
        return jsonify({
            "error": "Internal Server Error", 
            "message": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            "status_code": 500
        }), 500
    
    # ------------------------------------------------------
    # API ë¼ìš°íŠ¸
    # ------------------------------------------------------
    
    @app.route('/')
    def index():
        """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
        return jsonify({
            "service": "Agentic AI Master Server",
            "version": "1.0.0",
            "status": "running",
            "description": "ì›Œì»¤ ì—ì´ì „íŠ¸ë“¤ì„ í†µí•© ê´€ë¦¬í•˜ëŠ” ë§ˆìŠ¤í„° ì„œë²„",
            "architecture": {
                "supervisor_agent": "âœ… êµ¬í˜„ë¨ (LangGraph ì›Œí¬í”Œë¡œìš°)",
                "worker_agents": {
                    "agent_1": "ì •í˜• ë°ì´í„° ë¶„ì„ (Structura)",
                    "agent_2": "ê´€ê³„í˜• ë°ì´í„° ë¶„ì„ (Cognita)",
                    "agent_3": "ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ (Chronos)",
                    "agent_4": "ìì—°ì–´ ë°ì´í„° ë¶„ì„ (Sentio)",
                    "agent_5": "ì™¸ë¶€ ì‹œì¥ ë¶„ì„ (Agora)"
                },
                "integration_agent": "âœ… êµ¬í˜„ë¨ (ê²°ê³¼ í†µí•© ë° ìµœì í™”)"
            },
            "endpoints": {
                "health": "/api/health",
                "workers_status": "/api/workers/status",
                "analyze_individual": "/api/analyze/individual",
                "analyze_department": "/api/analyze/department",
                "task_status": "/api/task/{task_id}/status",
                "task_result": "/api/task/{task_id}/result"
            }
        })
    
    @app.route('/api/health')
    def health_check():
        """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
        
        worker_mgr = get_worker_manager()
        
        if not worker_mgr:
            return jsonify({
                "status": "error",
                "message": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "timestamp": datetime.now().isoformat()
            }), 503
        
        # ì›Œì»¤ ìƒíƒœ í™•ì¸
        worker_status = worker_mgr.get_worker_status()
        
        # ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ê²°ì •
        all_running = all(status.status == 'running' for status in worker_status.values())
        any_error = any(status.status == 'error' for status in worker_status.values())
        
        system_status = "healthy" if all_running else "degraded" if not any_error else "error"
        
        return jsonify({
            "status": system_status,
            "service": "Agentic AI Master Server",
            "version": "1.0.0",
            "worker_count": len(worker_status),
            "workers": {worker_id: asdict(status) for worker_id, status in worker_status.items()},
            "capabilities": {
                "structura_available": STRUCTURA_AVAILABLE,
                "cognita_available": COGNITA_AVAILABLE,
                "sentio_available": SENTIO_AVAILABLE,
                "chronos_available": CHRONOS_AVAILABLE,
                "agora_available": AGORA_AVAILABLE
            },
            "timestamp": datetime.now().isoformat()
        })
    
    @app.route('/api/cognita/setup/neo4j', methods=['POST'])
    def setup_cognita_neo4j():
        """Cognita Neo4j ì—°ê²° ì„¤ì • - í†µí•© ë§ˆìŠ¤í„° ì„œë²„ ë²„ì „"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr:
                return jsonify({
                    "success": False,
                    "error": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 503
            
            # ìš”ì²­ ë°ì´í„° íŒŒì‹±
            neo4j_config = request.get_json()
            if not neo4j_config:
                return jsonify({
                    "success": False,
                    "error": "Neo4j ì—°ê²° ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                }), 400
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ['uri', 'username', 'password']
            for field in required_fields:
                if field not in neo4j_config:
                    return jsonify({
                        "success": False,
                        "error": f"í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {field}"
                    }), 400
            
            # Cognita ì›Œì»¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            if 'cognita' not in worker_mgr.workers:
                return jsonify({
                    "success": False,
                    "error": "Cognita ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 503
            
            # Neo4j ì—°ê²° í…ŒìŠ¤íŠ¸
            try:
                from Cognita.cognita_flask_backend import Neo4jManager
                
                # ìƒˆë¡œìš´ Neo4j ì—°ê²° í…ŒìŠ¤íŠ¸
                test_manager = Neo4jManager(
                    neo4j_config['uri'],
                    neo4j_config['username'],
                    neo4j_config['password']
                )
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                with test_manager.driver.session() as session:
                    result = session.run("RETURN 1 as test")
                    test_result = result.single()
                    if test_result and test_result['test'] == 1:
                        # ì—°ê²° ì„±ê³µ - ê¸°ì¡´ Cognita ì›Œì»¤ ì—…ë°ì´íŠ¸
                        from Cognita.cognita_flask_backend import CognitaRiskAnalyzer
                        
                        # ìƒˆë¡œìš´ ë¶„ì„ê¸°ë¡œ ì—…ë°ì´íŠ¸
                        new_analyzer = CognitaRiskAnalyzer(test_manager)
                        worker_mgr.workers['cognita']['agent'] = new_analyzer
                        worker_mgr.workers['cognita']['status'].status = 'running'
                        worker_mgr.workers['cognita']['status'].error_message = None
                        
                        return jsonify({
                            "success": True,
                            "message": "Neo4j ì—°ê²°ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
                            "connection_info": {
                                "uri": neo4j_config['uri'],
                                "username": neo4j_config['username'],
                                "status": "connected"
                            }
                        })
                    else:
                        raise Exception("ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                        
            except Exception as neo4j_error:
                # Neo4j ì—°ê²° ì‹¤íŒ¨
                worker_mgr.workers['cognita']['status'].status = 'error'
                worker_mgr.workers['cognita']['status'].error_message = f"Neo4j ì—°ê²° ì‹¤íŒ¨: {str(neo4j_error)}"
                
                return jsonify({
                    "success": False,
                    "error": f"Neo4j ì—°ê²° ì‹¤íŒ¨: {str(neo4j_error)}",
                    "details": "ì—°ê²° ì •ë³´ë¥¼ í™•ì¸í•˜ê³  Neo4j ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                }), 400
                
        except Exception as e:
            logger.error(f"Neo4j ì„¤ì • ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"Neo4j ì—°ê²° ì„¤ì • ì¤‘ ì˜¤ë¥˜: {str(e)}"
            }), 500
    
    @app.route('/api/cognita/network-analysis', methods=['POST'])
    def cognita_network_analysis():
        """Cognita ë„¤íŠ¸ì›Œí¬ ë¶„ì„ - Neo4j ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr or 'cognita' not in worker_mgr.workers:
                return jsonify({
                    "success": False,
                    "error": "Cognita ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 503
            
            # Cognita ì›Œì»¤ ìƒíƒœ í™•ì¸
            cognita_worker = worker_mgr.workers['cognita']
            if cognita_worker['status'].status != 'running':
                return jsonify({
                    "success": False,
                    "error": f"Cognita ì—ì´ì „íŠ¸ ìƒíƒœ: {cognita_worker['status'].status}",
                    "details": cognita_worker['status'].error_message
                }), 503
            
            # ìš”ì²­ ë°ì´í„° íŒŒì‹±
            request_data = request.get_json()
            analysis_type = request_data.get('analysis_type', 'collaboration')
            search_term = request_data.get('search_term', '')
            neo4j_config = request_data.get('neo4j_config', {})
            
            # Neo4jì—ì„œ ë„¤íŠ¸ì›Œí¬ ë°ì´í„° ì¡°íšŒ
            try:
                cognita_agent = cognita_worker['agent']
                
                # ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì‹¤í–‰
                network_data = cognita_agent.analyze_network_relationships(
                    analysis_type=analysis_type,
                    search_term=search_term
                )
                
                return jsonify({
                    "success": True,
                    "network_data": network_data,
                    "analysis_type": analysis_type,
                    "timestamp": datetime.now().isoformat()
                })
                
            except Exception as analysis_error:
                logger.error(f"ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì‹¤íŒ¨: {str(analysis_error)}")
                return jsonify({
                    "success": False,
                    "error": f"ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì‹¤íŒ¨: {str(analysis_error)}"
                }), 500
                
        except Exception as e:
            logger.error(f"ë„¤íŠ¸ì›Œí¬ ë¶„ì„ API ì˜¤ë¥˜: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"ë„¤íŠ¸ì›Œí¬ ë¶„ì„ API ì˜¤ë¥˜: {str(e)}"
            }), 500
    
    @app.route('/api/cognita/analyze', methods=['POST'])
    def cognita_analyze():
        """Cognita ê°œë³„ ë¶„ì„ - í†µí•© ë§ˆìŠ¤í„° ì„œë²„ ë²„ì „"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr or 'cognita' not in worker_mgr.workers:
                return jsonify({
                    "success": False,
                    "error": "Cognita ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }), 503
            
            # ìš”ì²­ ë°ì´í„° íŒŒì‹±
            data = request.get_json()
            if not data or 'employee_id' not in data:
                return jsonify({
                    "success": False,
                    "error": "employee_idê°€ í•„ìš”í•©ë‹ˆë‹¤."
                }), 400
            
            # Cognita ì‘ì—… ìƒì„± ë° ì‹¤í–‰
            task_id = f"cognita_{int(time.time() * 1000)}"
            task = AgenticTask(
                task_id=task_id,
                task_type='individual_analysis',
                employee_data=data,
                use_cognita=True,
                use_structura=False,
                use_chronos=False,
                use_sentio=False,
                use_agora=False
            )
            
            # Cognita ì›Œì»¤ ì‹¤í–‰
            cognita_result = worker_mgr._execute_cognita_task(task)
            
            return jsonify({
                "success": True,
                "result": cognita_result,
                "timestamp": datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Cognita ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"Cognita ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            }), 500
    
    @app.route('/api/cognita/status')
    def cognita_status():
        """Cognita ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr or 'cognita' not in worker_mgr.workers:
                return jsonify({
                    "success": False,
                    "error": "Cognita ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "status": "unavailable"
                }), 503
            
            cognita_status = worker_mgr.workers['cognita']['status']
            
            return jsonify({
                "success": True,
                "status": asdict(cognita_status),
                "agent_available": worker_mgr.workers['cognita']['agent'] is not None,
                "timestamp": datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Cognita ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
            }), 500
    
    @app.route('/api/chronos/upload', methods=['POST'])
    def chronos_upload():
        """Chronos ì‹œê³„ì—´ ë°ì´í„° ì—…ë¡œë“œ - í†µí•© ë§ˆìŠ¤í„° ì„œë²„ ë²„ì „"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr or 'chronos' not in worker_mgr.workers:
                return jsonify({
                    "success": False,
                    "error": "Chronos ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }), 503
            
            # íŒŒì¼ í™•ì¸
            if 'file' not in request.files:
                return jsonify({
                    "success": False,
                    "error": "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({
                    "success": False,
                    "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 400
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            if not file.filename.lower().endswith('.csv'):
                return jsonify({
                    "success": False,
                    "error": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                }), 400
            
            # íŒŒì¼ í¬ê¸° í™•ì¸ (300MB ì œí•œ)
            file.seek(0, 2)  # íŒŒì¼ ëìœ¼ë¡œ ì´ë™
            file_size = file.tell()
            file.seek(0)  # íŒŒì¼ ì‹œì‘ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°
            
            max_size = 300 * 1024 * 1024  # 300MB
            if file_size > max_size:
                return jsonify({
                    "success": False,
                    "error": f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 300MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (í˜„ì¬: {file_size / (1024*1024):.1f}MB)"
                }), 413
            
            # íŒŒì¼ ì €ì¥
            filename = secure_filename(file.filename)
            upload_dir = os.path.join(os.path.dirname(__file__), 'uploads', 'chronos')
            os.makedirs(upload_dir, exist_ok=True)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = os.path.splitext(filename)[0]
            new_filename = f"{base_name}_{timestamp}.csv"
            file_path = os.path.join(upload_dir, new_filename)
            
            file.save(file_path)
            
            # CSV íŒŒì¼ ê²€ì¦
            try:
                import pandas as pd
                df = pd.read_csv(file_path)
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
                required_columns = ['employee_id', 'week']
                missing_columns = [col for col in required_columns if col not in df.columns]
                
                if missing_columns:
                    os.remove(file_path)  # ì˜ëª»ëœ íŒŒì¼ ì‚­ì œ
                    return jsonify({
                        "success": False,
                        "error": f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}",
                        "required_columns": required_columns,
                        "found_columns": list(df.columns)
                    }), 400
                
                # Chronos ì›Œì»¤ì— ë°ì´í„° ë¡œë“œ ì‹œë„
                chronos_agent = worker_mgr.workers['chronos']['agent']
                if chronos_agent and 'processor' in chronos_agent:
                    try:
                        processor = chronos_agent['processor']
                        # ë°ì´í„° ë¡œë“œ (HR ë°ì´í„°ëŠ” ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
                        hr_data_path = os.path.join(os.path.dirname(__file__), 'data', 'IBM_HR.csv')
                        processor.load_data(file_path, hr_data_path if os.path.exists(hr_data_path) else None)
                        processor.preprocess_data()
                        
                        logger.info(f"Chronos ë°ì´í„° ë¡œë“œ ì„±ê³µ: {file_path}")
                    except Exception as load_error:
                        logger.warning(f"Chronos ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {load_error}")
                        # ë¡œë“œ ì‹¤íŒ¨í•´ë„ íŒŒì¼ ì—…ë¡œë“œëŠ” ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                
                return jsonify({
                    "success": True,
                    "message": "ì‹œê³„ì—´ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "file_info": {
                        "original_filename": filename,
                        "saved_filename": new_filename,
                        "file_path": file_path,
                        "file_size_mb": round(file_size / (1024*1024), 2),
                        "rows": len(df),
                        "columns": len(df.columns),
                        "upload_time": datetime.now().isoformat()
                    },
                    "data_info": {
                        "total_rows": len(df),
                        "columns": list(df.columns),
                        "required_columns_present": all(col in df.columns for col in required_columns)
                    }
                })
                
            except Exception as csv_error:
                # CSV íŒŒì‹± ì‹¤íŒ¨ ì‹œ íŒŒì¼ ì‚­ì œ
                if os.path.exists(file_path):
                    os.remove(file_path)
                return jsonify({
                    "success": False,
                    "error": f"CSV íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(csv_error)}"
                }), 400
            
        except Exception as e:
            logger.error(f"Chronos íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
            }), 500
    
    @app.route('/api/chronos/status')
    def chronos_status():
        """Chronos ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr or 'chronos' not in worker_mgr.workers:
                return jsonify({
                    "success": False,
                    "error": "Chronos ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "status": "unavailable"
                }), 503
            
            chronos_status = worker_mgr.workers['chronos']['status']
            chronos_agent = worker_mgr.workers['chronos']['agent']
            
            # ë°ì´í„° ë¡œë“œ ìƒíƒœ í™•ì¸
            data_loaded = False
            data_info = {}
            
            if chronos_agent and 'processor' in chronos_agent:
                processor = chronos_agent['processor']
                if hasattr(processor, 'X_train') and processor.X_train is not None:
                    data_loaded = True
                    data_info = {
                        "training_samples": len(processor.X_train) if processor.X_train is not None else 0,
                        "features": processor.X_train.shape[2] if len(processor.X_train.shape) > 2 else 0,
                        "sequence_length": processor.sequence_length if hasattr(processor, 'sequence_length') else 0
                    }
            
            return jsonify({
                "success": True,
                "status": asdict(chronos_status),
                "agent_available": chronos_agent is not None,
                "data_loaded": data_loaded,
                "data_info": data_info,
                "timestamp": datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Chronos ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
            }), 500
    
    @app.route('/api/structura/upload', methods=['POST'])
    def structura_upload():
        """Structura HR ë°ì´í„° ì—…ë¡œë“œ - í†µí•© ë§ˆìŠ¤í„° ì„œë²„ ë²„ì „"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr or 'structura' not in worker_mgr.workers:
                return jsonify({
                    "success": False,
                    "error": "Structura ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }), 503
            
            # íŒŒì¼ í™•ì¸
            if 'file' not in request.files:
                return jsonify({
                    "success": False,
                    "error": "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({
                    "success": False,
                    "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 400
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            if not file.filename.lower().endswith('.csv'):
                return jsonify({
                    "success": False,
                    "error": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                }), 400
            
            # íŒŒì¼ í¬ê¸° í™•ì¸ (300MB ì œí•œ)
            file.seek(0, 2)
            file_size = file.tell()
            file.seek(0)
            
            max_size = 300 * 1024 * 1024  # 300MB
            if file_size > max_size:
                return jsonify({
                    "success": False,
                    "error": f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 300MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (í˜„ì¬: {file_size / (1024*1024):.1f}MB)"
                }), 413
            
            # íŒŒì¼ ì €ì¥
            filename = secure_filename(file.filename)
            upload_dir = os.path.join(os.path.dirname(__file__), 'uploads', 'structura')
            os.makedirs(upload_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = os.path.splitext(filename)[0]
            new_filename = f"{base_name}_{timestamp}.csv"
            file_path = os.path.join(upload_dir, new_filename)
            
            file.save(file_path)
            
            # CSV íŒŒì¼ ê²€ì¦
            try:
                import pandas as pd
                df = pd.read_csv(file_path)
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (HR ë°ì´í„°)
                required_columns = ['EmployeeNumber', 'Age', 'JobRole', 'Department']
                missing_columns = [col for col in required_columns if col not in df.columns]
                
                if missing_columns:
                    os.remove(file_path)
                    return jsonify({
                        "success": False,
                        "error": f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}",
                        "required_columns": required_columns,
                        "found_columns": list(df.columns)
                    }), 400
                
                return jsonify({
                    "success": True,
                    "message": "HR ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "file_info": {
                        "original_filename": filename,
                        "saved_filename": new_filename,
                        "file_path": file_path,
                        "file_size_mb": round(file_size / (1024*1024), 2),
                        "rows": len(df),
                        "columns": len(df.columns),
                        "upload_time": datetime.now().isoformat()
                    },
                    "data_info": {
                        "total_employees": len(df),
                        "columns": list(df.columns),
                        "required_columns_present": all(col in df.columns for col in required_columns)
                    }
                })
                
            except Exception as csv_error:
                if os.path.exists(file_path):
                    os.remove(file_path)
                return jsonify({
                    "success": False,
                    "error": f"CSV íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(csv_error)}"
                }), 400
            
        except Exception as e:
            logger.error(f"Structura íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
            }), 500
    
    @app.route('/api/sentio/upload', methods=['POST'])
    def sentio_upload():
        """Sentio í…ìŠ¤íŠ¸ ë°ì´í„° ì—…ë¡œë“œ - í†µí•© ë§ˆìŠ¤í„° ì„œë²„ ë²„ì „"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr or 'sentio' not in worker_mgr.workers:
                return jsonify({
                    "success": False,
                    "error": "Sentio ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }), 503
            
            # íŒŒì¼ í™•ì¸
            if 'file' not in request.files:
                return jsonify({
                    "success": False,
                    "error": "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({
                    "success": False,
                    "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 400
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            if not file.filename.lower().endswith('.csv'):
                return jsonify({
                    "success": False,
                    "error": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                }), 400
            
            # íŒŒì¼ í¬ê¸° í™•ì¸ (300MB ì œí•œ)
            file.seek(0, 2)
            file_size = file.tell()
            file.seek(0)
            
            max_size = 300 * 1024 * 1024  # 300MB
            if file_size > max_size:
                return jsonify({
                    "success": False,
                    "error": f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 300MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (í˜„ì¬: {file_size / (1024*1024):.1f}MB)"
                }), 413
            
            # íŒŒì¼ ì €ì¥
            filename = secure_filename(file.filename)
            upload_dir = os.path.join(os.path.dirname(__file__), 'uploads', 'sentio')
            os.makedirs(upload_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = os.path.splitext(filename)[0]
            new_filename = f"{base_name}_{timestamp}.csv"
            file_path = os.path.join(upload_dir, new_filename)
            
            file.save(file_path)
            
            # CSV íŒŒì¼ ê²€ì¦
            try:
                import pandas as pd
                df = pd.read_csv(file_path)
                
                # í…ìŠ¤íŠ¸ ë°ì´í„° ì»¬ëŸ¼ í™•ì¸ (ì‹¤ì œ íŒŒì¼ êµ¬ì¡°ì— ë§ê²Œ)
                text_columns = [col for col in df.columns if 'text' in col.lower() or 'comment' in col.lower() or 'feedback' in col.lower() or 'review' in col.lower() or 'survey' in col.lower()]
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (ìœ ì—°í•œ ê²€ì¦)
                required_text_columns = ['SELF_REVIEW_text', 'PEER_FEEDBACK_text', 'WEEKLY_SURVEY_text']
                alternative_columns = ['FeedbackText', 'text', 'comment', 'feedback']
                
                # ì‹¤ì œ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
                has_text_data = any(col in df.columns for col in required_text_columns) or any(col in df.columns for col in alternative_columns) or len(text_columns) > 0
                
                if not has_text_data:
                    os.remove(file_path)
                    return jsonify({
                        "success": False,
                        "error": "í…ìŠ¤íŠ¸ ë°ì´í„° ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "expected_columns": "SELF_REVIEW_text, PEER_FEEDBACK_text, WEEKLY_SURVEY_text ë˜ëŠ” FeedbackText, text, comment ë“±",
                        "found_columns": list(df.columns)
                    }), 400
                
                # ì§ì› ì‹ë³„ ì»¬ëŸ¼ í™•ì¸
                employee_id_columns = ['EmployeeNumber', 'employee_id', 'Employee_ID', 'ID']
                has_employee_id = any(col in df.columns for col in employee_id_columns)
                
                return jsonify({
                    "success": True,
                    "message": "í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "file_info": {
                        "original_filename": filename,
                        "saved_filename": new_filename,
                        "file_path": file_path,
                        "file_size_mb": round(file_size / (1024*1024), 2),
                        "rows": len(df),
                        "columns": len(df.columns),
                        "upload_time": datetime.now().isoformat()
                    },
                    "data_info": {
                        "total_records": len(df),
                        "columns": list(df.columns),
                        "text_columns": text_columns,
                        "text_columns_count": len(text_columns),
                        "has_employee_id": has_employee_id,
                        "detected_text_types": {
                            "self_review": any('SELF_REVIEW' in col for col in df.columns),
                            "peer_feedback": any('PEER_FEEDBACK' in col for col in df.columns),
                            "weekly_survey": any('WEEKLY_SURVEY' in col for col in df.columns),
                            "general_text": any(col in df.columns for col in alternative_columns)
                        }
                    }
                })
                
            except Exception as csv_error:
                if os.path.exists(file_path):
                    os.remove(file_path)
                return jsonify({
                    "success": False,
                    "error": f"CSV íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(csv_error)}"
                }), 400
            
        except Exception as e:
            logger.error(f"Sentio íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
            }), 500
    
    @app.route('/api/workers/status')
    def get_workers_status():
        """ì›Œì»¤ ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ"""
        
        worker_mgr = get_worker_manager()
        if not worker_mgr:
            return jsonify({"error": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 503
        
        worker_status = worker_mgr.get_worker_status()
        
        return jsonify({
            "workers": {worker_id: asdict(status) for worker_id, status in worker_status.items()},
            "summary": {
                "total_workers": len(worker_status),
                "running": len([s for s in worker_status.values() if s.status == 'running']),
                "busy": len([s for s in worker_status.values() if s.status == 'busy']),
                "error": len([s for s in worker_status.values() if s.status == 'error'])
            },
            "timestamp": datetime.now().isoformat()
        })

    @app.route('/api/agents/debug')
    def debug_agents():
        """ì—ì´ì „íŠ¸ ë””ë²„ê¹… ì •ë³´ ì¡°íšŒ"""
        worker_mgr = get_worker_manager()
        
        if not worker_mgr:
            return jsonify({
                "error": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 503
        
        debug_info = {
            "timestamp": datetime.now().isoformat(),
            "agents": {}
        }
        
        # ê° ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì •ë³´
        for agent_name in ['structura', 'cognita', 'chronos', 'sentio', 'agora']:
            agent_info = {
                "import_available": False,
                "initialized": False,
                "agent_object": None,
                "error_message": None
            }
            
            # Import ê°€ìš©ì„± ì²´í¬
            if agent_name == 'structura':
                agent_info["import_available"] = STRUCTURA_AVAILABLE
            elif agent_name == 'cognita':
                agent_info["import_available"] = COGNITA_AVAILABLE
            elif agent_name == 'chronos':
                agent_info["import_available"] = CHRONOS_AVAILABLE
            elif agent_name == 'sentio':
                agent_info["import_available"] = SENTIO_AVAILABLE
            elif agent_name == 'agora':
                agent_info["import_available"] = AGORA_AVAILABLE
            
            # ì´ˆê¸°í™” ìƒíƒœ ì²´í¬
            if agent_name in worker_mgr.workers:
                worker_info = worker_mgr.workers[agent_name]
                agent_info["initialized"] = True
                agent_info["agent_object"] = worker_info['agent'] is not None
                agent_info["status"] = asdict(worker_info['status'])
                
                if worker_info['status'].error_message:
                    agent_info["error_message"] = worker_info['status'].error_message
            
            debug_info["agents"][agent_name] = agent_info
        
        return jsonify(debug_info)
    
    @app.route('/api/analyze/individual', methods=['POST'])
    def analyze_individual():
        """ê°œë³„ ì§ì› í†µí•© ë¶„ì„"""
        
        worker_mgr = get_worker_manager()
        if not worker_mgr:
            return jsonify({"error": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 503
        
        try:
            # ìš”ì²­ ë°ì´í„° íŒŒì‹±
            data = request.get_json()
            if not data:
                return jsonify({"error": "ë¶„ì„í•  ì§ì› ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
            
            # ì‘ì—… ìƒì„±
            task_id = f"individual_{int(time.time() * 1000)}"
            task = AgenticTask(
                task_id=task_id,
                task_type='individual_analysis',
                employee_data=data,
                text_data=data.get('text_data'),
                timeseries_data=data.get('timeseries_data'),
                market_data=data.get('market_data'),
                use_structura=data.get('use_structura', True),
                use_cognita=data.get('use_cognita', True),
                use_sentio=data.get('use_sentio', False),
                use_chronos=data.get('use_chronos', False),
                use_agora=data.get('use_agora', False)
            )
            
            # ì‘ì—… ì‹¤í–‰
            result = worker_mgr.execute_task(task)
            
            # ê²°ê³¼ ì €ì¥ (ì„±ê³µí•œ ê²½ìš°ì—ë§Œ)
            if result.status == "completed":
                try:
                    employee_id = data.get('EmployeeNumber') or data.get('employee_id', 'unknown')
                    department = data.get('Department', 'Unknown')
                    position = data.get('JobRole', 'Unknown')
                    
                    # ì›Œì»¤ ê²°ê³¼ ì •ë¦¬
                    worker_results = {}
                    if result.structura_result:
                        worker_results['structura'] = result.structura_result
                    if result.cognita_result:
                        worker_results['cognita'] = result.cognita_result
                    if result.sentio_result:
                        worker_results['sentio'] = result.sentio_result
                    if result.chronos_result:
                        worker_results['chronos'] = result.chronos_result
                    if result.agora_result:
                        worker_results['agora'] = result.agora_result
                    
                    # ê²°ê³¼ ì €ì¥
                    saved_path = result_manager.save_employee_result(
                        employee_id=str(employee_id),
                        employee_data=data,
                        worker_results=worker_results,
                        department=department,
                        position=position
                    )
                    
                    # ì‘ë‹µì— ì €ì¥ ê²½ë¡œ ì¶”ê°€
                    result_dict = asdict(result)
                    result_dict['saved_path'] = str(saved_path)
                    result_dict['visualizations_available'] = result_manager.list_available_visualizations(str(employee_id))
                    
                    return jsonify(result_dict)
                    
                except Exception as save_error:
                    logger.warning(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {save_error}")
                    # ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¶„ì„ ê²°ê³¼ëŠ” ë°˜í™˜
                    return jsonify(asdict(result))
            else:
                return jsonify(asdict(result))
            
        except Exception as e:
            logger.error(f"ê°œë³„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return jsonify({"error": f"ê°œë³„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}), 500
    
    @app.route('/api/analyze/department', methods=['POST'])
    def analyze_department():
        """ë¶€ì„œë³„ í†µí•© ë¶„ì„"""
        
        worker_mgr = get_worker_manager()
        if not worker_mgr:
            return jsonify({"error": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 503
        
        try:
            # ìš”ì²­ ë°ì´í„° íŒŒì‹±
            data = request.get_json()
            if not data or not data.get('department_name'):
                return jsonify({"error": "ë¶€ì„œëª…ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400
            
            # ì‘ì—… ìƒì„±
            task_id = f"department_{int(time.time() * 1000)}"
            task = AgenticTask(
                task_id=task_id,
                task_type='department_analysis',
                department_name=data['department_name'],
                sample_size=data.get('sample_size', 20),
                use_structura=data.get('use_structura', True),
                use_cognita=data.get('use_cognita', True)
            )
            
            # ì‘ì—… ì‹¤í–‰
            result = worker_mgr.execute_task(task)
            
            return jsonify(asdict(result))
            
        except Exception as e:
            logger.error(f"ë¶€ì„œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return jsonify({"error": f"ë¶€ì„œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}), 500

    # ë°°ì¹˜ ë¶„ì„ ì§„í–‰ë¥  ì¶”ì ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
    batch_progress_tracker = {
        'current_batch_id': None,
        'total_employees': 0,
        'completed_employees': 0,
        'current_agent': None,
        'agent_progress': {
            'structura': {'completed': 0, 'total': 0},
            'cognita': {'completed': 0, 'total': 0},
            'chronos': {'completed': 0, 'total': 0},
            'sentio': {'completed': 0, 'total': 0},
            'agora': {'completed': 0, 'total': 0}
        },
        'status': 'idle',
        'start_time': None,
        'estimated_completion': None
    }

    @app.route('/api/analyze/batch/progress', methods=['GET'])
    def get_batch_progress():
        """ë°°ì¹˜ ë¶„ì„ ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì¡°íšŒ"""
        try:
            progress = batch_progress_tracker.copy()
            
            # ì „ì²´ ì§„í–‰ë¥  ê³„ì‚°
            if progress['total_employees'] > 0:
                overall_progress = (progress['completed_employees'] / progress['total_employees']) * 100
            else:
                overall_progress = 0
            
            # ê° ì—ì´ì „íŠ¸ë³„ ì§„í–‰ë¥  ê³„ì‚°
            agent_percentages = {}
            for agent, data in progress['agent_progress'].items():
                if data['total'] > 0:
                    agent_percentages[agent] = (data['completed'] / data['total']) * 100
                else:
                    agent_percentages[agent] = 0
            
            return jsonify({
                'success': True,
                'batch_id': progress['current_batch_id'],
                'status': progress['status'],
                'overall_progress': round(overall_progress, 1),
                'completed_employees': progress['completed_employees'],
                'total_employees': progress['total_employees'],
                'current_agent': progress['current_agent'],
                'agent_progress': agent_percentages,
                'start_time': progress['start_time'],
                'estimated_completion': progress['estimated_completion']
            })
            
        except Exception as e:
            logger.error(f"ì§„í–‰ë¥  ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                'success': False,
                'error': str(e)
            }), 500

    @app.route('/api/analyze/batch', methods=['POST'])
    def analyze_batch():
        """ë°°ì¹˜ ë¶„ì„ - Supervisorê°€ ìˆœì°¨ì ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        
        worker_mgr = get_worker_manager()
        if not worker_mgr:
            return jsonify({"error": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 503
        
        try:
            # ìš”ì²­ ë°ì´í„° íŒŒì‹±
            data = request.get_json()
            logger.info(f"ë°°ì¹˜ ë¶„ì„ ìš”ì²­ ë°ì´í„°: {data}")
            
            if not data:
                return jsonify({"error": "ìš”ì²­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}), 400
                
            if 'employees' not in data:
                return jsonify({"error": "employees í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
                
            employees = data['employees']
            if not isinstance(employees, list):
                return jsonify({"error": "employeesëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤"}), 400
                
            if len(employees) == 0:
                return jsonify({"error": "ìµœì†Œ 1ëª…ì˜ ì§ì› ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
            agent_config = {
                'use_structura': data.get('use_structura', True),
                'use_cognita': data.get('use_cognita', True), 
                'use_chronos': data.get('use_chronos', True),
                'use_sentio': data.get('use_sentio', True),
                'use_agora': data.get('use_agora', True)
            }
            
            # ì—ì´ì „íŠ¸ ê°€ìš©ì„± ì²´í¬ ë° ë¡œê¹…
            logger.info("ğŸ” ë°°ì¹˜ ë¶„ì„ ì‹œì‘ - ì—ì´ì „íŠ¸ ê°€ìš©ì„± ì²´í¬")
            print(f"[DEBUG] ğŸ” ë°°ì¹˜ ë¶„ì„ ì‹œì‘ - ì—ì´ì „íŠ¸ ê°€ìš©ì„± ì²´í¬")
            
            agent_status = {
                'structura': {'available': STRUCTURA_AVAILABLE, 'initialized': 'structura' in worker_mgr.workers and worker_mgr.workers['structura']['agent'] is not None},
                'cognita': {'available': COGNITA_AVAILABLE, 'initialized': 'cognita' in worker_mgr.workers and worker_mgr.workers['cognita']['agent'] is not None},
                'chronos': {'available': CHRONOS_AVAILABLE, 'initialized': 'chronos' in worker_mgr.workers and worker_mgr.workers['chronos']['agent'] is not None},
                'sentio': {'available': SENTIO_AVAILABLE, 'initialized': 'sentio' in worker_mgr.workers and worker_mgr.workers['sentio']['agent'] is not None},
                'agora': {'available': AGORA_AVAILABLE, 'initialized': 'agora' in worker_mgr.workers and worker_mgr.workers['agora']['agent'] is not None}
            }
            
            for agent_name, status in agent_status.items():
                status_msg = f"  {agent_name}: ê°€ìš©ì„±={status['available']}, ì´ˆê¸°í™”={status['initialized']}"
                logger.info(status_msg)
                print(f"[DEBUG] {status_msg}")
                
                if agent_config.get(f'use_{agent_name}') and not (status['available'] and status['initialized']):
                    warning_msg = f"  âš ï¸ {agent_name} ì—ì´ì „íŠ¸ê°€ í™œì„±í™”ë˜ì—ˆì§€ë§Œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!"
                    logger.warning(warning_msg)
                    print(f"[DEBUG] {warning_msg}")
            
            # ì§„í–‰ë¥  ì¶”ì  ì´ˆê¸°í™”
            batch_id = f"batch_{int(time.time() * 1000)}"
            batch_progress_tracker['current_batch_id'] = batch_id
            batch_progress_tracker['total_employees'] = len(employees)
            batch_progress_tracker['completed_employees'] = 0
            batch_progress_tracker['status'] = 'running'
            batch_progress_tracker['start_time'] = datetime.now().isoformat()
            batch_progress_tracker['current_agent'] = 'initializing'
            
            # ê° ì—ì´ì „íŠ¸ë³„ ì‘ì—…ëŸ‰ ì„¤ì •
            for agent in ['structura', 'cognita', 'chronos', 'sentio', 'agora']:
                if agent_config.get(f'use_{agent}', False):
                    batch_progress_tracker['agent_progress'][agent]['total'] = len(employees)
                    batch_progress_tracker['agent_progress'][agent]['completed'] = 0
                else:
                    batch_progress_tracker['agent_progress'][agent]['total'] = 0
                    batch_progress_tracker['agent_progress'][agent]['completed'] = 0

            # ë°°ì¹˜ ë¶„ì„ ê²°ê³¼ ì €ì¥
            batch_results = []
            total_employees = len(employees)
            
            logger.info(f"ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì‹œì‘: {total_employees}ëª…ì˜ ì§ì› ë°ì´í„° ì²˜ë¦¬ (ë°°ì¹˜ ID: {batch_id})")
            print(f"[DEBUG] ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì‹œì‘: {total_employees}ëª…ì˜ ì§ì› ë°ì´í„° ì²˜ë¦¬ (ë°°ì¹˜ ID: {batch_id})")
            
            # ğŸ¯ ë°°ì¹˜ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ (ì²« ë²ˆì§¸ ë¶„ì„ ì „ì— ìˆ˜í–‰)
            logger.info("ğŸ¤– ë°°ì¹˜ ë°ì´í„°ë¡œ Structura ëª¨ë¸ í•™ìŠµ ì‹œë„...")
            print(f"[DEBUG] ğŸ¤– ë°°ì¹˜ ë°ì´í„°ë¡œ Structura ëª¨ë¸ í•™ìŠµ ì‹œë„...")
            
            try:
                # Attrition ë¼ë²¨ì´ ìˆëŠ” ë°ì´í„° í™•ì¸
                import pandas as pd
                df = pd.DataFrame(employees)
                
                if 'Attrition' in df.columns:
                    labeled_count = df['Attrition'].notna().sum()
                    attrition_yes = (df['Attrition'] == 'Yes').sum()
                    attrition_no = (df['Attrition'] == 'No').sum()
                    
                    logger.info(f"ğŸ“Š ë¼ë²¨ ë°ì´í„° ë°œê²¬: {labeled_count}ê°œ (Yes: {attrition_yes}, No: {attrition_no})")
                    print(f"[DEBUG] ğŸ“Š ë¼ë²¨ ë°ì´í„° ë°œê²¬: {labeled_count}ê°œ (Yes: {attrition_yes}, No: {attrition_no})")
                    
                    if labeled_count >= 10:  # ìµœì†Œ í•™ìŠµ ë°ì´í„° í™•ë³´
                        # Structura ì—ì´ì „íŠ¸ë¡œ í•™ìŠµ ìˆ˜í–‰
                        if 'structura' in worker_mgr.workers and worker_mgr.workers['structura']['agent']:
                            structura_agent = worker_mgr.workers['structura']['agent']
                            training_success = worker_mgr._train_structura_from_batch_data(structura_agent, employees)
                            
                            if training_success:
                                logger.info("âœ… ë°°ì¹˜ ë°ì´í„° í•™ìŠµ ì™„ë£Œ! í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì§„í–‰")
                                print(f"[DEBUG] âœ… ë°°ì¹˜ ë°ì´í„° í•™ìŠµ ì™„ë£Œ! í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì§„í–‰")
                            else:
                                logger.warning("âš ï¸ ë°°ì¹˜ ë°ì´í„° í•™ìŠµ ì‹¤íŒ¨. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                                print(f"[DEBUG] âš ï¸ ë°°ì¹˜ ë°ì´í„° í•™ìŠµ ì‹¤íŒ¨. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                        else:
                            logger.warning("Structura ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    else:
                        logger.info(f"ë¼ë²¨ ë°ì´í„° ë¶€ì¡± ({labeled_count}ê°œ). íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                        print(f"[DEBUG] ë¼ë²¨ ë°ì´í„° ë¶€ì¡± ({labeled_count}ê°œ). íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                else:
                    logger.info("Attrition ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                    print(f"[DEBUG] Attrition ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                
                # ğŸ•’ Chronosë¥¼ ìœ„í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
                logger.info("ğŸ•’ Chronosë¥¼ ìœ„í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì¤‘...")
                print(f"[DEBUG] ğŸ•’ Chronosë¥¼ ìœ„í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì¤‘...")
                
                timeseries_data = worker_mgr._generate_timeseries_from_batch_data(employees)
                if timeseries_data:
                    logger.info(f"âœ… ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(timeseries_data)}ê°œ ë ˆì½”ë“œ")
                    print(f"[DEBUG] âœ… ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(timeseries_data)}ê°œ ë ˆì½”ë“œ")
                    
                    # Chronos ì—ì´ì „íŠ¸ë¡œ í•™ìŠµ ìˆ˜í–‰
                    if 'chronos' in worker_mgr.workers and worker_mgr.workers['chronos']['agent']:
                        chronos_agent = worker_mgr.workers['chronos']['agent']
                        chronos_training_success = worker_mgr._train_chronos_from_batch_data(chronos_agent, timeseries_data)
                        
                        if chronos_training_success:
                            logger.info("âœ… Chronos ì‹œê³„ì—´ í•™ìŠµ ì™„ë£Œ!")
                            print(f"[DEBUG] âœ… Chronos ì‹œê³„ì—´ í•™ìŠµ ì™„ë£Œ!")
                        else:
                            logger.warning("âš ï¸ Chronos ì‹œê³„ì—´ í•™ìŠµ ì‹¤íŒ¨")
                            print(f"[DEBUG] âš ï¸ Chronos ì‹œê³„ì—´ í•™ìŠµ ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.warning(f"ë°°ì¹˜ í•™ìŠµ ì¤€ë¹„ ì‹¤íŒ¨: {str(e)}")
                print(f"[DEBUG] ë°°ì¹˜ í•™ìŠµ ì¤€ë¹„ ì‹¤íŒ¨: {str(e)}")
            
            # ğŸš€ ì—ì´ì „íŠ¸ë³„ ë°°ì¹˜ ë¶„ì„ (ì „ì²´ ì§ì›ì„ ì—ì´ì „íŠ¸ë³„ë¡œ ì²˜ë¦¬)
            logger.info("ğŸš€ ì—ì´ì „íŠ¸ë³„ ë°°ì¹˜ ë¶„ì„ ì‹œì‘")
            print(f"[DEBUG] ğŸš€ ì—ì´ì „íŠ¸ë³„ ë°°ì¹˜ ë¶„ì„ ì‹œì‘")
            
            # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ (ì§ì›ë³„ë¡œ ê° ì—ì´ì „íŠ¸ ê²°ê³¼ ì €ì¥)
            employee_results = {}
            for idx, employee in enumerate(employees):
                employee_number = employee.get('EmployeeNumber', str(idx))
                employee_results[employee_number] = {
                    'employee_data': employee,
                    'structura_result': None,
                    'cognita_result': None,
                    'chronos_result': None,
                    'sentio_result': None,
                    'agora_result': None,
                    'progress': 0
                }
            
            # ì—ì´ì „íŠ¸ë³„ ìˆœì°¨ ì‹¤í–‰
            active_agents = []
            if agent_config.get('use_structura'): active_agents.append('structura')
            if agent_config.get('use_cognita'): active_agents.append('cognita')
            if agent_config.get('use_chronos'): active_agents.append('chronos')
            if agent_config.get('use_sentio'): active_agents.append('sentio')
            if agent_config.get('use_agora'): active_agents.append('agora')
            
            for agent_idx, agent_name in enumerate(active_agents):
                # í˜„ì¬ ì—ì´ì „íŠ¸ ì„¤ì •
                batch_progress_tracker['current_agent'] = agent_name
                
                logger.info(f"ğŸ“Š {agent_idx + 1}/{len(active_agents)}ë‹¨ê³„: {agent_name} ì—ì´ì „íŠ¸ - ì „ì²´ {total_employees}ëª… ì²˜ë¦¬ ì¤‘...")
                print(f"[DEBUG] ğŸ“Š {agent_idx + 1}/{len(active_agents)}ë‹¨ê³„: {agent_name} ì—ì´ì „íŠ¸ - ì „ì²´ {total_employees}ëª… ì²˜ë¦¬ ì¤‘...")
                
                successful_count = 0
                failed_count = 0
                
                for emp_idx, (employee_number, emp_data) in enumerate(employee_results.items()):
                    try:
                        # ê°œë³„ ì—ì´ì „íŠ¸ ì‹¤í–‰
                        task_id = f"batch_{agent_name}_{employee_number}_{int(time.time() * 1000)}"
                        task = AgenticTask(
                            task_id=task_id,
                            task_type='individual_analysis',
                            employee_data=emp_data['employee_data'],
                            **agent_config
                        )
                        
                        # ì—ì´ì „íŠ¸ë³„ ì‹¤í–‰
                        if agent_name == 'structura':
                            result = worker_mgr._execute_structura_task(task)
                            emp_data['structura_result'] = result
                        elif agent_name == 'cognita':
                            result = worker_mgr._execute_cognita_task(task)
                            emp_data['cognita_result'] = result
                        elif agent_name == 'chronos':
                            result = worker_mgr._execute_chronos_task(task)
                            emp_data['chronos_result'] = result
                        elif agent_name == 'sentio':
                            result = worker_mgr._execute_sentio_task(task)
                            emp_data['sentio_result'] = result
                        elif agent_name == 'agora':
                            result = worker_mgr._execute_agora_task(task)
                            emp_data['agora_result'] = result
                        
                        successful_count += 1
                        
                        # ì‹¤ì œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                        batch_progress_tracker['agent_progress'][agent_name]['completed'] = emp_idx + 1
                        
                        # ì „ì²´ ì™„ë£Œëœ ì§ì› ìˆ˜ ì—…ë°ì´íŠ¸ (ë§ˆì§€ë§‰ ì—ì´ì „íŠ¸ì¼ ë•Œë§Œ)
                        if agent_idx == len(active_agents) - 1:
                            batch_progress_tracker['completed_employees'] = emp_idx + 1
                        
                        # ì£¼ê¸°ì  ë¡œê¹… (10ëª…ë§ˆë‹¤)
                        if (emp_idx + 1) % 10 == 0:
                            logger.info(f"  {agent_name}: {emp_idx + 1}/{total_employees}ëª… ì™„ë£Œ")
                            print(f"[DEBUG]   {agent_name}: {emp_idx + 1}/{total_employees}ëª… ì™„ë£Œ")
                        
                    except Exception as e:
                        logger.warning(f"{agent_name} - ì§ì› {employee_number} ì‹¤íŒ¨: {str(e)}")
                        failed_count += 1
                
                # ì—ì´ì „íŠ¸ ì™„ë£Œ ì‹œ ì§„í–‰ë¥  100%ë¡œ ì„¤ì •
                batch_progress_tracker['agent_progress'][agent_name]['completed'] = batch_progress_tracker['agent_progress'][agent_name]['total']
                
                logger.info(f"âœ… {agent_name} ì™„ë£Œ: ì„±ê³µ {successful_count}ëª…, ì‹¤íŒ¨ {failed_count}ëª…")
                print(f"[DEBUG] âœ… {agent_name} ì™„ë£Œ: ì„±ê³µ {successful_count}ëª…, ì‹¤íŒ¨ {failed_count}ëª…")
            
            # ìµœì¢… ê²°ê³¼ ìƒì„±
            for employee_number, emp_data in employee_results.items():
                # í†µí•© ë¶„ì„ ê²°ê³¼ ìƒì„±
                combined_analysis = worker_mgr._create_combined_analysis(
                    emp_data['structura_result'],
                    emp_data['cognita_result'],
                    emp_data['chronos_result'],
                    emp_data['sentio_result'],
                    emp_data['agora_result']
                )
                
                batch_results.append({
                    'employee_number': employee_number,
                    'analysis_result': {
                        'structura_result': emp_data['structura_result'],
                        'cognita_result': emp_data['cognita_result'],
                        'chronos_result': emp_data['chronos_result'],
                        'sentio_result': emp_data['sentio_result'],
                        'agora_result': emp_data['agora_result'],
                        'combined_analysis': combined_analysis,
                        'status': 'success',
                        'execution_time': 0.1,  # í‰ê·  ì‹¤í–‰ ì‹œê°„
                        'timestamp': datetime.now().isoformat()
                    },
                    'progress': 100
                })
            
            # ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
            batch_progress_tracker['status'] = 'completed'
            batch_progress_tracker['completed_employees'] = total_employees
            batch_progress_tracker['current_agent'] = 'completed'
            
            logger.info(f"ğŸ‰ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {total_employees}ëª… ì¤‘ {len(batch_results)}ëª… ì²˜ë¦¬ ì™„ë£Œ")
            print(f"[DEBUG] ğŸ‰ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {total_employees}ëª… ì¤‘ {len(batch_results)}ëª… ì²˜ë¦¬ ì™„ë£Œ")
            
            return jsonify({
                'batch_id': batch_progress_tracker['current_batch_id'],
                'total_employees': total_employees,
                'completed_employees': len(batch_results),
                'results': batch_results,
                'summary': {
                    'high_risk_count': len([r for r in batch_results if r and isinstance(r, dict) and r.get('analysis_result', {}) and r.get('analysis_result', {}).get('combined_analysis', {}) and r.get('analysis_result', {}).get('combined_analysis', {}).get('overall_risk_level') == 'HIGH']),
                    'medium_risk_count': len([r for r in batch_results if r and isinstance(r, dict) and r.get('analysis_result', {}) and r.get('analysis_result', {}).get('combined_analysis', {}) and r.get('analysis_result', {}).get('combined_analysis', {}).get('overall_risk_level') == 'MEDIUM']),
                    'low_risk_count': len([r for r in batch_results if r and isinstance(r, dict) and r.get('analysis_result', {}) and r.get('analysis_result', {}).get('combined_analysis', {}) and r.get('analysis_result', {}).get('combined_analysis', {}).get('overall_risk_level') == 'LOW'])
                }
            })
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            logger.error(f"ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {error_details}")
            return jsonify({
                "error": f"ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "details": error_details
            }), 500

    @app.route('/api/integration/report', methods=['POST'])
    def generate_integration_report():
        """Integration ë¶„ì„ - LLM ê¸°ë°˜ ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        try:
            # ìš”ì²­ ë°ì´í„° íŒŒì‹±
            data = request.get_json()
            logger.info(f"Integration ë³´ê³ ì„œ ìƒì„± ìš”ì²­: {data}")
            
            if not data:
                return jsonify({"error": "ìš”ì²­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}), 400
            
            # ë¶„ì„ ê²°ê³¼ ë°ì´í„° ê²€ì¦
            analysis_results = data.get('analysis_results', [])
            if not analysis_results:
                return jsonify({"error": "ë¶„ì„ ê²°ê³¼ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
            
            # ë³´ê³ ì„œ ìƒì„± ì˜µì…˜
            report_options = data.get('report_options', {})
            include_recommendations = report_options.get('include_recommendations', True)
            include_risk_analysis = report_options.get('include_risk_analysis', True)
            
            # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            report = _generate_comprehensive_report(
                analysis_results, 
                include_recommendations, 
                include_risk_analysis
            )
            
            return jsonify({
                'report_id': f"report_{int(time.time() * 1000)}",
                'generated_at': datetime.now().isoformat(),
                'total_employees': len(analysis_results),
                'report': report,
                'metadata': {
                    'report_type': 'comprehensive_integration',
                    'options': report_options,
                    'data_sources': ['structura', 'cognita', 'chronos', 'sentio', 'agora']
                }
            })
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            logger.error(f"Integration ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {error_details}")
            return jsonify({
                "error": f"Integration ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                "details": error_details
            }), 500

    def _generate_comprehensive_report(analysis_results, include_recommendations=True, include_risk_analysis=True):
        """ì¢…í•©ì ì¸ Integration ë³´ê³ ì„œ ìƒì„±"""
        
        # ì „ì²´ í†µê³„ ë¶„ì„
        total_employees = len(analysis_results)
        high_risk_count = 0
        medium_risk_count = 0
        low_risk_count = 0
        
        # ê° ì§ì›ë³„ ê²°ê³¼ ë¶„ì„
        for result in analysis_results:
            if not result or not isinstance(result, dict):
                continue
                
            analysis = result.get('analysis_result', {})
            if not analysis:
                continue
            
            # ì „ì²´ ìœ„í—˜ë„ ë¶„ë¥˜ (ê°„ë‹¨í•œ ë¡œì§)
            structura_risk = 0
            cognita_risk = 0
            
            structura = analysis.get('structura_result')
            if structura:
                structura_risk = structura.get('attrition_probability', 0)
            
            cognita = analysis.get('cognita_result') 
            if cognita:
                cognita_risk = cognita.get('overall_risk_score', 0)
            
            # í‰ê·  ìœ„í—˜ë„ ê³„ì‚°
            avg_risk = (structura_risk + cognita_risk) / 2 if (structura_risk > 0 or cognita_risk > 0) else 0
            
            if avg_risk > 0.7:
                high_risk_count += 1
            elif avg_risk > 0.4:
                medium_risk_count += 1
            else:
                low_risk_count += 1
        
        # ë³´ê³ ì„œ êµ¬ì¡° ìƒì„±
        report = {
            'executive_summary': {
                'overview': f"ì´ {total_employees}ëª…ì˜ ì§ì›ì„ ëŒ€ìƒìœ¼ë¡œ 5ê°œ ì—ì´ì „íŠ¸(Structura, Cognita, Chronos, Sentio, Agora)ë¥¼ í†µí•œ ì¢…í•© ë¶„ì„ì„ ì‹¤ì‹œí–ˆìŠµë‹ˆë‹¤.",
                'key_metrics': f"ê³ ìœ„í—˜êµ° {high_risk_count}ëª…, ì¤‘ìœ„í—˜êµ° {medium_risk_count}ëª…, ì €ìœ„í—˜êµ° {low_risk_count}ëª…ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
                'urgency_assessment': f"ì „ì²´ ì§ì› ì¤‘ {(high_risk_count/total_employees*100):.1f}%ê°€ ê³ ìœ„í—˜êµ°ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ {'ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•œ' if high_risk_count/total_employees > 0.2 else 'ì£¼ì˜ ê¹Šì€ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•œ'} ìƒí™©ì…ë‹ˆë‹¤.",
                'next_steps': "ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œë³„ ì§ì›ë³„ ë§ì¶¤í˜• ê´€ë¦¬ ë°©ì•ˆì„ ìˆ˜ë¦½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            },
            'overall_statistics': {
                'total_employees_analyzed': total_employees,
                'high_risk_count': high_risk_count,
                'medium_risk_count': medium_risk_count,
                'low_risk_count': low_risk_count,
                'risk_distribution': {
                    'high_risk_percentage': (high_risk_count / total_employees * 100) if total_employees > 0 else 0,
                    'medium_risk_percentage': (medium_risk_count / total_employees * 100) if total_employees > 0 else 0,
                    'low_risk_percentage': (low_risk_count / total_employees * 100) if total_employees > 0 else 0
                }
            },
            'agent_analysis': {
                'structura_insights': "XGBoost ê¸°ë°˜ ì´ì§ ì˜ˆì¸¡ ëª¨ë¸ì„ í†µí•œ ì •í˜• ë°ì´í„° ë¶„ì„ ê²°ê³¼",
                'cognita_insights': "Neo4j ê¸°ë°˜ ê´€ê³„í˜• ë°ì´í„° ë¶„ì„ì„ í†µí•œ ë„¤íŠ¸ì›Œí¬ ìœ„í—˜ë„ í‰ê°€",
                'chronos_insights': "GRU+CNN+Attention í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì„ í†µí•œ ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„",
                'sentio_insights': "NLP ê¸°ë°˜ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ì„ í†µí•œ ì‹¬ë¦¬ì  ìƒíƒœ í‰ê°€",
                'agora_insights': "ì™¸ë¶€ ì‹œì¥ ë¶„ì„ì„ í†µí•œ ê²½ìŸë ¥ ë° ì‹œì¥ ì••ë ¥ í‰ê°€"
            },
            'key_findings': [
                f"ì´ {total_employees}ëª… ì¤‘ {high_risk_count}ëª…ì´ ê³ ìœ„í—˜êµ°ìœ¼ë¡œ ë¶„ë¥˜ë¨",
                "ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•œ ë‹¤ë©´ì  ë¶„ì„ ì™„ë£Œ",
                "Supervisor íŒ¨í„´ì„ í†µí•œ ì—ì´ì „íŠ¸ ê°„ ë°ì´í„° ì „ë‹¬ ì„±ê³µ"
            ]
        }
        
        # ì„ íƒì  ì„¹ì…˜ ì¶”ê°€
        if include_recommendations:
            report['recommendations'] = {
                'immediate_actions': [
                    f"ê³ ìœ„í—˜êµ° {high_risk_count}ëª…ì— ëŒ€í•œ ê°œë³„ ë©´ë‹´ ë° í˜„í™© íŒŒì•…",
                    "ë‹¤ë©´ì  ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë§ì¶¤í˜• ê´€ë¦¬ ë°©ì•ˆ ìˆ˜ë¦½"
                ],
                'short_term_strategies': [
                    "AI ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸ì„ í™œìš©í•œ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•",
                    "ì—ì´ì „íŠ¸ë³„ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•œ ì¢…í•©ì  HR ëŒ€ì‹œë³´ë“œ ê°œë°œ"
                ],
                'long_term_initiatives': [
                    "ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œì˜ ì •í™•ë„ ì§€ì† ê°œì„ ",
                    "5ê°œ ì—ì´ì „íŠ¸ í†µí•© ë¶„ì„ì„ í†µí•œ ì¡°ì§ ë¬¸í™” í˜ì‹  í”„ë¡œê·¸ë¨ ê°œë°œ"
                ]
            }
        
        if include_risk_analysis:
            report['detailed_risk_analysis'] = {
                'high_risk_analysis': {
                    'count': high_risk_count,
                    'percentage': f"{(high_risk_count/total_employees*100):.1f}%" if total_employees > 0 else "0%",
                    'priority_interventions': [
                        "1:1 ê°œë³„ ìƒë‹´ì„ í†µí•œ êµ¬ì²´ì ì¸ ë¬¸ì œì  íŒŒì•…",
                        "ì—…ë¬´ í™˜ê²½ ê°œì„  ë° ì—­í•  ì¬ì¡°ì • ê²€í† ",
                        "ê²½ë ¥ ê°œë°œ ê¸°íšŒ ì œê³µ ë° ì„±ì¥ ê²½ë¡œ ëª…í™•í™”"
                    ]
                },
                'workflow_effectiveness': {
                    'sequential_execution': "Supervisor íŒ¨í„´ì„ í†µí•œ ìˆœì°¨ì  ì—ì´ì „íŠ¸ ì‹¤í–‰ ì„±ê³µ",
                    'data_integration': "ê° ë‹¨ê³„ë³„ ê²°ê³¼ê°€ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì„±ê³µì ìœ¼ë¡œ ì „ë‹¬ë¨",
                    'comprehensive_coverage': "5ê°œ ì—ì´ì „íŠ¸ë¥¼ í†µí•œ ë‹¤ë©´ì  ë¶„ì„ìœ¼ë¡œ í¬ê´„ì  ìœ„í—˜ë„ í‰ê°€ ì™„ë£Œ"
                }
            }
        
        return report
    
    @app.route('/api/task/<task_id>/result')
    def get_task_result(task_id):
        """ì‘ì—… ê²°ê³¼ ì¡°íšŒ"""
        
        worker_mgr = get_worker_manager()
        if not worker_mgr:
            return jsonify({"error": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 503
        
        if task_id in worker_mgr.result_cache:
            result = worker_mgr.result_cache[task_id]
            return jsonify(asdict(result))
        else:
            return jsonify({"error": f"ì‘ì—… ID '{task_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 404
    
    @app.route('/api/results/employee/<employee_id>')
    def get_employee_results(employee_id):
        """ì§ì› ê²°ê³¼ ì¡°íšŒ"""
        try:
            results = result_manager.get_employee_results(employee_id)
            
            if "error" in results:
                return jsonify(results), 404
            
            return jsonify(results)
            
        except Exception as e:
            logger.error(f"ì§ì› ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return jsonify({"error": f"ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}), 500
    
    @app.route('/api/results/employee/<employee_id>/visualizations')
    def get_employee_visualizations(employee_id):
        """ì§ì› ì‹œê°í™” íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
        try:
            viz_files = result_manager.list_available_visualizations(employee_id)
            
            return jsonify({
                "employee_id": employee_id,
                "visualizations": viz_files,
                "count": len(viz_files)
            })
            
        except Exception as e:
            logger.error(f"ì‹œê°í™” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return jsonify({"error": f"ì‹œê°í™” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}), 500
    
    @app.route('/api/results/department/<department>/report')
    def get_department_report(department):
        """ë¶€ì„œë³„ ì¢…í•© ë³´ê³ ì„œ ì¡°íšŒ"""
        try:
            report = result_manager.generate_department_report(department)
            
            if "error" in report:
                return jsonify(report), 404
            
            return jsonify(report)
            
        except Exception as e:
            logger.error(f"ë¶€ì„œ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return jsonify({"error": f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}"}), 500
    
    @app.route('/api/results')
    def get_results():
        """ì‹œìŠ¤í…œ ì „ì²´ ê²°ê³¼ ì¡°íšŒ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±)"""
        try:
            worker_mgr = get_worker_manager()
            if not worker_mgr:
                return jsonify({"error": "ì›Œì»¤ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 503
            
            # ê¸°ë³¸ ì‹œìŠ¤í…œ í†µê³„
            system_stats = {
                "total_workers": 5,
                "active_workers": sum([
                    1 if STRUCTURA_AVAILABLE else 0,
                    1 if COGNITA_AVAILABLE else 0,
                    1 if CHRONOS_AVAILABLE else 0,
                    1 if SENTIO_AVAILABLE else 0,
                    1 if AGORA_AVAILABLE else 0
                ]),
                "total_tasks": len(worker_mgr.result_cache),
                "completed_tasks": len([r for r in worker_mgr.result_cache.values() if r.status == "completed"]),
                "timestamp": datetime.now().isoformat()
            }
            
            # ìµœê·¼ ê²°ê³¼ë“¤
            recent_results = []
            for task_id, result in list(worker_mgr.result_cache.items())[-10:]:  # ìµœê·¼ 10ê°œ
                recent_results.append({
                    "task_id": task_id,
                    "status": result.status,
                    "timestamp": result.timestamp,
                    "worker_type": result.worker_results.keys() if hasattr(result, 'worker_results') else []
                })
            
            return jsonify({
                "status": "success",
                "results": system_stats,
                "recent_results": recent_results,
                "timestamp": datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return jsonify({"error": f"ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}), 500
    
    @app.route('/upload_file', methods=['POST'])
    def upload_file():
        """íŒŒì¼ ì—…ë¡œë“œ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±)"""
        try:
            # íŒŒì¼ í™•ì¸
            if 'file' not in request.files:
                return jsonify({
                    "success": False,
                    "error": "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({
                    "success": False,
                    "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }), 400
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            if not file.filename.lower().endswith('.csv'):
                return jsonify({
                    "success": False,
                    "error": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                }), 400
            
            # íŒŒì¼ ì €ì¥
            filename = secure_filename(file.filename)
            upload_dir = os.path.join(os.path.dirname(__file__), 'uploads', 'master')
            os.makedirs(upload_dir, exist_ok=True)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = os.path.splitext(filename)[0]
            new_filename = f"{base_name}_{timestamp}.csv"
            file_path = os.path.join(upload_dir, new_filename)
            
            file.save(file_path)
            
            return jsonify({
                "success": True,
                "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "file_info": {
                    "original_filename": filename,
                    "saved_filename": new_filename,
                    "file_path": file_path,
                    "upload_time": datetime.now().isoformat()
                }
            })
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
            }), 500
    
    @app.route('/load_data', methods=['POST'])
    def load_data():
        """ë°ì´í„° ë¡œë“œ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±)"""
        try:
            data = request.get_json()
            file_path = data.get('filePath') if data else None
            
            if not file_path:
                # ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ì‚¬ìš©
                file_path = 'Total_score.csv'
            
            # ë°ì´í„° ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ì°¾ê¸°
            data_dir = os.path.join(os.path.dirname(__file__), '..', 'data')
            full_path = os.path.join(data_dir, file_path)
            
            if not os.path.exists(full_path):
                return jsonify({
                    "success": False,
                    "error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}"
                }), 404
            
            # CSV íŒŒì¼ ì½ê¸° ë° ê¸°ë³¸ ì •ë³´ ì œê³µ
            import pandas as pd
            df = pd.read_csv(full_path)
            
            return jsonify({
                "success": True,
                "message": "ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "data_info": {
                    "file_path": file_path,
                    "rows": len(df),
                    "columns": len(df.columns),
                    "column_names": list(df.columns),
                    "load_time": datetime.now().isoformat()
                }
            })
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return jsonify({
                "success": False,
                "error": f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
            }), 500
    
    return app

# ------------------------------------------------------
# ì„œë²„ ì‹¤í–‰ í•¨ìˆ˜
# ------------------------------------------------------

def run_server(host='0.0.0.0', port=8000, debug=True):
    """Agentic AI Master Server ì‹¤í–‰"""
    app = create_app()
    
    print("=" * 70)
    print("ğŸ¤– Agentic AI Master Server ì‹œì‘")
    print("=" * 70)
    print(f"ğŸ“¡ ì„œë²„ ì£¼ì†Œ: http://{host}:{port}")
    print(f"ğŸ”— React ì—°ë™: http://localhost:3000ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥")
    print(f"ğŸ”„ ë””ë²„ê·¸ ëª¨ë“œ: {'í™œì„±í™”' if debug else 'ë¹„í™œì„±í™”'}")
    print()
    print("ğŸ—ï¸ ì•„í‚¤í…ì²˜:")
    print("  ğŸ“Š ì›Œì»¤ ì—ì´ì „íŠ¸ 1: ì •í˜• ë°ì´í„° ë¶„ì„ (Structura)")
    print("  ğŸ•¸ï¸  ì›Œì»¤ ì—ì´ì „íŠ¸ 2: ê´€ê³„í˜• ë°ì´í„° ë¶„ì„ (Cognita)")
    print("  â° ì›Œì»¤ ì—ì´ì „íŠ¸ 3: ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ (Chronos)")
    print("  ğŸ“ ì›Œì»¤ ì—ì´ì „íŠ¸ 4: ìì—°ì–´ ë°ì´í„° ë¶„ì„ (Sentio)")
    print("  ğŸŒ ì›Œì»¤ ì—ì´ì „íŠ¸ 5: ì™¸ë¶€ ì‹œì¥ ë¶„ì„ (Agora)")
    print("  ğŸ¤– Supervisor ì—ì´ì „íŠ¸: âœ… êµ¬í˜„ë¨ (LangGraph ì›Œí¬í”Œë¡œìš°)")
    print("  ğŸ”— Integration ì—ì´ì „íŠ¸: âœ… êµ¬í˜„ë¨ (ê²°ê³¼ í†µí•© ë° ìµœì í™”)")
    print()
    print("ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸:")
    print(f"  â€¢ í—¬ìŠ¤ì²´í¬: http://{host}:{port}/api/health")
    print(f"  â€¢ ì›Œì»¤ ìƒíƒœ: http://{host}:{port}/api/workers/status")
    print(f"  â€¢ ê°œë³„ ë¶„ì„: http://{host}:{port}/api/analyze/individual")
    print(f"  â€¢ ë¶€ì„œ ë¶„ì„: http://{host}:{port}/api/analyze/department")
    print()
    print("ì›Œì»¤ ì—ì´ì „íŠ¸ ìƒíƒœ:")
    print(f"  â€¢ Structura: {'âœ…' if STRUCTURA_AVAILABLE else 'âŒ'}")
    print(f"  â€¢ Cognita: {'âœ…' if COGNITA_AVAILABLE else 'âŒ'}")
    print(f"  â€¢ Chronos: {'âœ…' if CHRONOS_AVAILABLE else 'âŒ'}")
    print(f"  â€¢ Sentio: {'âœ…' if SENTIO_AVAILABLE else 'âŒ'}")
    print(f"  â€¢ Agora: {'âœ…' if AGORA_AVAILABLE else 'âŒ'}")
    print()
    print("ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    print("=" * 70)
    
    app.run(host=host, port=port, debug=debug)

if __name__ == '__main__':
    run_server()
