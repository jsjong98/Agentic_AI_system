# ============================================================================
# ê°œì„ ëœ Chronos ë°ì´í„° ì²˜ë¦¬ ëª¨ë“ˆ (Chronos_analysis_fixed.pyì—ì„œ ì¶”ì¶œ)
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import torch
from torch.utils.data import Dataset, DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import joblib
import io
import base64
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class ProperTimeSeriesProcessor:
    def __init__(self, sequence_length=6, prediction_horizon=4, aggregation_unit='week'):
        """
        ì˜¬ë°”ë¥¸ ì‹œê³„ì—´ ì˜ˆì¸¡ì„ ìœ„í•œ í”„ë¡œì„¸ì„œ
        
        Args:
            sequence_length (int): ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ì‹œí€€ìŠ¤ ê¸¸ì´
            prediction_horizon (int): ì˜ˆì¸¡ ì‹œì  (Nì£¼ í›„ í‡´ì‚¬ ì—¬ë¶€ ì˜ˆì¸¡)
            aggregation_unit (str): ì§‘ê³„ ë‹¨ìœ„ ('day', 'week', 'month')
        """
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
        self.aggregation_unit = aggregation_unit
        self.scaler = StandardScaler()
        self.excluded_ratio_columns = [
            'work_focused_ratio', 'meeting_collaboration_ratio', 
            'social_dining_ratio', 'break_relaxation_ratio', 'shared_work_ratio'
        ]
        self.feature_columns = []
        
        print(f"ğŸ”§ ì˜¬ë°”ë¥¸ ì‹œê³„ì—´ ì„¤ì •:")
        print(f"   ì‹œí€€ìŠ¤ ê¸¸ì´: {sequence_length}{aggregation_unit[0]}")
        print(f"   ì˜ˆì¸¡ ì‹œì : {prediction_horizon}{aggregation_unit[0]} í›„")
        print(f"   ì§‘ê³„ ë‹¨ìœ„: {aggregation_unit}")
        
    def load_data(self, timeseries_path, personas_path):
        """ë°ì´í„° ë¡œë”©"""
        print("=" * 50)
        print("ë°ì´í„° ë¡œë”© ì¤‘...")
        print("=" * 50)
        
        # ì‹œê³„ì—´ ë°ì´í„° ë¡œë“œ
        self.ts_data = pd.read_csv(timeseries_path)
        print(f"âœ… ì‹œê³„ì—´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.ts_data.shape}")
        
        # ì§ì› ì†ì„± ë°ì´í„° ë¡œë“œ
        self.personas_data = pd.read_csv(personas_path)
        print(f"âœ… ì§ì› ì†ì„± ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.personas_data.shape}")
        
        return self.ts_data.head(), self.personas_data.head()

    def detect_columns(self):
        """ì»¬ëŸ¼ ìë™ ê°ì§€ ë° ë§¤ì¹­"""
        print("=" * 50)
        print("ì»¬ëŸ¼ ìë™ ê°ì§€ ì¤‘...")
        print("=" * 50)
        
        # ë‚ ì§œ ì»¬ëŸ¼ ìë™ ê°ì§€
        date_columns = [col for col in self.ts_data.columns 
                       if any(keyword in col.lower() for keyword in ['date', 'time', 'timestamp'])]
        
        if date_columns:
            self.date_column = date_columns[0]
            print(f"ğŸ—“ï¸  ê°ì§€ëœ ë‚ ì§œ ì»¬ëŸ¼: {self.date_column}")
        else:
            raise ValueError("âŒ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        # ì§ì› ID ì»¬ëŸ¼ ìë™ ê°ì§€
        employee_id_candidates = [col for col in self.ts_data.columns 
                                 if any(keyword in col.lower() for keyword in ['employee', 'id', 'number'])]
        
        if employee_id_candidates:
            self.employee_id_col = employee_id_candidates[0]
            print(f"ğŸ‘¤ ê°ì§€ëœ ì‹œê³„ì—´ ì§ì› ID ì»¬ëŸ¼: {self.employee_id_col}")
        else:
            raise ValueError("âŒ ì§ì› ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        # ì§ì› ì†ì„± ë°ì´í„°ì—ì„œ ë§¤ì¹­ë˜ëŠ” ID ì»¬ëŸ¼ ì°¾ê¸°
        personas_id_candidates = [col for col in self.personas_data.columns 
                                 if any(keyword in col.lower() for keyword in ['employee', 'id', 'number'])]
        
        max_overlap = 0
        best_match_col = None
        
        for col in personas_id_candidates:
            try:
                overlap = len(set(self.ts_data[self.employee_id_col]).intersection(
                             set(self.personas_data[col])))
                if overlap > max_overlap:
                    max_overlap = overlap
                    best_match_col = col
            except:
                continue
                
        if best_match_col:
            self.personas_id_col = best_match_col
            print(f"âœ… ìµœì  ë§¤ì¹­ ì»¬ëŸ¼: {self.personas_id_col} ({max_overlap}ëª… ê²¹ì¹¨)")
        else:
            raise ValueError("âŒ ì§ì› ì†ì„± ë°ì´í„°ì—ì„œ ë§¤ì¹­ë˜ëŠ” ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # Attrition ì»¬ëŸ¼ ì°¾ê¸°
        attrition_cols = [col for col in self.personas_data.columns 
                         if 'attrition' in col.lower()]
        
        if attrition_cols:
            self.attrition_col = attrition_cols[0]
            print(f"ğŸ¯ ê°ì§€ëœ Attrition ì»¬ëŸ¼: {self.attrition_col}")
        else:
            raise ValueError("âŒ Attrition ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def preprocess_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œê°„ ë²”ìœ„ ë¶„ì„"""
        print("=" * 50)
        print("ì˜¬ë°”ë¥¸ ì‹œê³„ì—´ ì „ì²˜ë¦¬ ì¤‘...")
        print("=" * 50)
        
        # ë‚ ì§œ ë³€í™˜
        self.ts_data[self.date_column] = pd.to_datetime(self.ts_data[self.date_column])
        
        # 2023-2024ë…„ ë°ì´í„°ë§Œ í•„í„°ë§
        start_date = datetime(2023, 1, 1)
        end_date = datetime(2024, 12, 31)
        
        original_shape = self.ts_data.shape
        self.ts_data = self.ts_data[
            (self.ts_data[self.date_column] >= start_date) & 
            (self.ts_data[self.date_column] <= end_date)
        ].copy()
        
        print(f"ğŸ“… 2023-2024ë…„ í•„í„°ë§: {original_shape} â†’ {self.ts_data.shape}")
        
        # Attrition ë¼ë²¨ì„ 0/1ë¡œ ë³€í™˜
        def convert_attrition(value):
            if pd.isna(value):
                return 0
            value_str = str(value).lower().strip()
            if value_str in ['yes', 'y', 'true', '1', '1.0']:
                return 1
            else:
                return 0
                
        self.personas_data['attrition_binary'] = self.personas_data[self.attrition_col].apply(convert_attrition)
        
        attrition_dist = self.personas_data['attrition_binary'].value_counts()
        print(f"\nğŸ¯ Attrition ë¶„í¬:")
        print(f"   ì¬ì§(0): {attrition_dist.get(0, 0)}ëª…")
        print(f"   í‡´ì‚¬(1): {attrition_dist.get(1, 0)}ëª…")
        print(f"   í‡´ì‚¬ìœ¨: {attrition_dist.get(1, 0) / len(self.personas_data) * 100:.1f}%")

    def identify_features(self):
        """í”¼ì²˜ ì‹ë³„"""
        print("=" * 50)
        print("í”¼ì²˜ ì‹ë³„ ì¤‘...")
        print("=" * 50)
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì‹ë³„
        numeric_columns = self.ts_data.select_dtypes(include=[np.number]).columns.tolist()
        
        # ì œì™¸í•  ì»¬ëŸ¼ë“¤ ì œê±°
        exclude_columns = [self.employee_id_col] + self.excluded_ratio_columns
        exclude_columns = [col for col in exclude_columns if col in numeric_columns]
        
        self.feature_columns = [col for col in numeric_columns if col not in exclude_columns]
        
        print(f"ğŸ” ì „ì²´ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: {len(numeric_columns)}ê°œ")
        print(f"âŒ ì œì™¸ëœ ì»¬ëŸ¼: {exclude_columns}")
        print(f"âœ… ì‚¬ìš©í•  í”¼ì²˜: {len(self.feature_columns)}ê°œ")

    def create_proper_sequences(self):
        """ì˜¬ë°”ë¥¸ ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± - ì‹œê°„ ìˆœì„œ ê³ ë ¤"""
        print("=" * 50)
        print("ì˜¬ë°”ë¥¸ ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        print("=" * 50)
        
        # ì‹œê°„ë³„ ì§‘ê³„
        if self.aggregation_unit == 'week':
            self.ts_data['year'] = self.ts_data[self.date_column].dt.year
            self.ts_data['week'] = self.ts_data[self.date_column].dt.isocalendar().week
            self.ts_data['time_period'] = self.ts_data['year'].astype(str) + '-W' + self.ts_data['week'].astype(str).str.zfill(2)
        
        # ì‹œê°„ë³„ ì§‘ê³„
        agg_data = self.ts_data.groupby([self.employee_id_col, 'time_period'])[self.feature_columns].mean().reset_index()
        
        # ì§ì› ì†ì„± ë°ì´í„°ì™€ ë³‘í•©
        merged_data = pd.merge(
            agg_data,
            self.personas_data[[self.personas_id_col, 'attrition_binary']],
            left_on=self.employee_id_col,
            right_on=self.personas_id_col,
            how='inner'
        )
        
        # ì‹œê°„ ìˆœì„œ ì •ë ¬
        merged_data = merged_data.sort_values(['employee_id', 'time_period'])
        
        sequences = []
        labels = []
        employee_ids = []
        time_points = []
        
        print("ğŸ”„ ì§ì›ë³„ ì˜¬ë°”ë¥¸ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        
        for employee_id in tqdm(merged_data[self.employee_id_col].unique(), desc="ì§ì›ë³„ ì²˜ë¦¬"):
            employee_data = merged_data[
                merged_data[self.employee_id_col] == employee_id
            ].sort_values('time_period').reset_index(drop=True)
            
            attrition_label = employee_data['attrition_binary'].iloc[0]
            
            # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
            min_required_length = self.sequence_length + self.prediction_horizon
            if len(employee_data) >= min_required_length:
                
                # ì „ì²´ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ê³ ì • ê¸¸ì´ë¡œ ë§ì¶¤ (íŒ¨ë”© ë˜ëŠ” ìƒ˜í”Œë§)
                if len(employee_data) >= self.sequence_length:
                    if len(employee_data) > self.sequence_length:
                        # ë°ì´í„°ê°€ ë” ê¸¸ë©´ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
                        indices = np.linspace(0, len(employee_data)-1, self.sequence_length, dtype=int)
                        sequence_data = employee_data.iloc[indices][self.feature_columns].values
                    else:
                        # ë°ì´í„°ê°€ ì •í™•íˆ ë§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        sequence_data = employee_data[self.feature_columns].values
                    
                    # ê° ì§ì›ë‹¹ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë§Œ ìƒì„±
                    sequences.append(sequence_data)
                    labels.append(attrition_label)
                    employee_ids.append(employee_id)
                    time_points.append(employee_data.iloc[0]['time_period'])  # ì‹œì‘ ì‹œì 
        
        self.X = np.array(sequences, dtype=np.float32)
        self.y = np.array(labels, dtype=np.int64)
        self.employee_ids_seq = np.array(employee_ids)
        self.time_points = np.array(time_points)
        
        print(f"âœ… ì˜¬ë°”ë¥¸ ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ:")
        print(f"   ì´ ì‹œí€€ìŠ¤: {len(self.X)}ê°œ")
        print(f"   ì‹œí€€ìŠ¤ í˜•íƒœ: {self.X.shape}")
        print(f"   í‡´ì‚¬ ë¼ë²¨ ë¹„ìœ¨: {np.mean(self.y) * 100:.1f}%")
        
        return self.X, self.y, self.employee_ids_seq

def employee_based_train_test_split(X, y, employee_ids, test_ratio=0.2):
    """ì§ì› ê¸°ë°˜ train/test ë¶„í•  (ì‹œê°„ ìˆœì„œ ê³ ë ¤í•˜ë©´ì„œ í´ë˜ìŠ¤ ê· í˜• ìœ ì§€)"""
    
    # ì§ì›ë³„ ë¼ë²¨ í™•ì¸
    unique_employees = np.unique(employee_ids)
    employee_labels = []
    
    for emp_id in unique_employees:
        emp_sequences = y[employee_ids == emp_id]
        # í•´ë‹¹ ì§ì›ì˜ ì‹œí€€ìŠ¤ ì¤‘ í•˜ë‚˜ë¼ë„ positiveë©´ í‡´ì‚¬ ì§ì›ìœ¼ë¡œ ë¶„ë¥˜
        emp_label = 1 if np.any(emp_sequences == 1) else 0
        employee_labels.append(emp_label)
    
    employee_labels = np.array(employee_labels)
    
    print(f"ğŸ“Š ì§ì›ë³„ ë¼ë²¨ ë¶„í¬:")
    print(f"   ì´ ì§ì› ìˆ˜: {len(unique_employees)}ëª…")
    print(f"   í‡´ì‚¬ ì§ì›: {np.sum(employee_labels)}ëª…")
    print(f"   ì¬ì§ ì§ì›: {np.sum(employee_labels == 0)}ëª…")
    
    # ì§ì› ë ˆë²¨ì—ì„œ stratified split
    try:
        train_employees, test_employees = train_test_split(
            unique_employees, test_size=test_ratio, random_state=42, 
            stratify=employee_labels
        )
    except ValueError:
        # stratifyê°€ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ì¼ë°˜ ë¶„í• 
        train_employees, test_employees = train_test_split(
            unique_employees, test_size=test_ratio, random_state=42
        )
    
    # ì§ì› ê¸°ë°˜ìœ¼ë¡œ ì‹œí€€ìŠ¤ ë¶„í• 
    train_mask = np.isin(employee_ids, train_employees)
    test_mask = np.isin(employee_ids, test_employees)
    
    X_train = X[train_mask]
    X_test = X[test_mask]
    y_train = y[train_mask]
    y_test = y[test_mask]
    
    print(f"ğŸ‘¥ ì§ì› ê¸°ë°˜ ë¶„í•  ì™„ë£Œ:")
    print(f"   í›ˆë ¨ ì§ì›: {len(train_employees)}ëª…")
    print(f"   í…ŒìŠ¤íŠ¸ ì§ì›: {len(test_employees)}ëª…")
    print(f"   í›ˆë ¨ ì‹œí€€ìŠ¤: {len(X_train)}ê°œ (í‡´ì‚¬ìœ¨: {np.mean(y_train)*100:.1f}%)")
    print(f"   í…ŒìŠ¤íŠ¸ ì‹œí€€ìŠ¤: {len(X_test)}ê°œ (í‡´ì‚¬ìœ¨: {np.mean(y_test)*100:.1f}%)")
    
    return X_train, X_test, y_train, y_test

# ì‹œê°í™” í´ë˜ìŠ¤ëŠ” ê¸°ì¡´ chronos_processor.pyì—ì„œ ê°€ì ¸ì˜´
class ChronosVisualizer:
    """
    Chronos ì‹œê°í™” í´ë˜ìŠ¤
    """
    def __init__(self):
        plt.style.use('default')
        sns.set_palette("husl")
    
    def plot_feature_importance(self, feature_importance: np.ndarray, feature_names: List[str], 
                              title: str = "Feature Importance") -> str:
        """
        Feature importance ì‹œê°í™”
        """
        # Plotlyë¥¼ ì‚¬ìš©í•œ ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸
        fig = go.Figure(data=[
            go.Bar(
                x=feature_importance,
                y=feature_names,
                orientation='h',
                marker=dict(
                    color=feature_importance,
                    colorscale='Viridis',
                    showscale=True
                )
            )
        ])
        
        fig.update_layout(
            title=title,
            xaxis_title="Importance Score",
            yaxis_title="Features",
            height=max(400, len(feature_names) * 25),
            template="plotly_white"
        )
        
        return fig.to_html(include_plotlyjs='cdn')
    
    def plot_temporal_attention(self, attention_weights: np.ndarray, 
                              sequence_length: int, title: str = "Temporal Attention") -> str:
        """
        ì‹œê³„ì—´ attention ì‹œê°í™”
        """
        # í‰ê·  attention weights ê³„ì‚°
        avg_attention = np.mean(attention_weights, axis=0) if attention_weights.ndim > 1 else attention_weights
        
        time_steps = [f"Week -{sequence_length-i}" for i in range(sequence_length)]
        
        fig = go.Figure(data=[
            go.Scatter(
                x=time_steps,
                y=avg_attention,
                mode='lines+markers',
                line=dict(width=3, color='#1f77b4'),
                marker=dict(size=8, color='#ff7f0e')
            )
        ])
        
        fig.update_layout(
            title=title,
            xaxis_title="Time Steps",
            yaxis_title="Attention Weight",
            template="plotly_white",
            height=400
        )
        
        return fig.to_html(include_plotlyjs='cdn')
    
    def plot_prediction_analysis(self, predictions: np.ndarray, probabilities: np.ndarray, 
                               labels: np.ndarray) -> str:
        """
        ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ì‹œê°í™”
        """
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('Confusion Matrix', 'ROC Curve', 
                          'Prediction Distribution', 'Probability Distribution'),
            specs=[[{"type": "heatmap"}, {"type": "scatter"}],
                   [{"type": "histogram"}, {"type": "histogram"}]]
        )
        
        # 1. Confusion Matrix
        cm = confusion_matrix(labels, predictions)
        fig.add_trace(
            go.Heatmap(z=cm, colorscale='Blues', showscale=False),
            row=1, col=1
        )
        
        # 2. ROC Curve
        if len(np.unique(labels)) > 1:
            fpr, tpr, _ = roc_curve(labels, probabilities[:, 1])
            auc_score = roc_auc_score(labels, probabilities[:, 1])
            
            fig.add_trace(
                go.Scatter(x=fpr, y=tpr, mode='lines', 
                          name=f'ROC (AUC = {auc_score:.3f})'),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(x=[0, 1], y=[0, 1], mode='lines', 
                          line=dict(dash='dash'), name='Random'),
                row=1, col=2
            )
        
        # 3. Prediction Distribution
        fig.add_trace(
            go.Histogram(x=predictions, name='Predictions', nbinsx=10),
            row=2, col=1
        )
        
        # 4. Probability Distribution
        fig.add_trace(
            go.Histogram(x=probabilities[:, 1], name='Attrition Probability', nbinsx=20),
            row=2, col=2
        )
        
        fig.update_layout(
            title="Prediction Analysis Dashboard",
            height=800,
            template="plotly_white",
            showlegend=False
        )
        
        return fig.to_html(include_plotlyjs='cdn')
    
    def create_employee_timeline(self, employee_data: pd.DataFrame, 
                               attention_weights: np.ndarray = None) -> str:
        """
        ê°œë³„ ì§ì›ì˜ ì‹œê³„ì—´ ë°ì´í„° ì‹œê°í™”
        """
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('Feature Timeline', 'Attention Weights'),
            vertical_spacing=0.1
        )
        
        # Feature timeline
        for i, col in enumerate(employee_data.columns[2:]):  # Skip employee_id and period
            fig.add_trace(
                go.Scatter(
                    x=employee_data['period'],
                    y=employee_data[col],
                    mode='lines+markers',
                    name=col,
                    line=dict(width=2)
                ),
                row=1, col=1
            )
        
        # Attention weights
        if attention_weights is not None:
            fig.add_trace(
                go.Bar(
                    x=employee_data['period'][-len(attention_weights):],
                    y=attention_weights,
                    name='Attention',
                    marker_color='red',
                    opacity=0.7
                ),
                row=2, col=1
            )
        
        fig.update_layout(
            title="Employee Timeline Analysis",
            height=600,
            template="plotly_white"
        )
        
        return fig.to_html(include_plotlyjs='cdn')