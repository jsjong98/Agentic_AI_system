import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

# ì‹œë“œ ì„¤ì • (ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼)
np.random.seed(42)

# ì‹œê°í™” ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['figure.figsize'] = (12, 6)
sns.set_style("whitegrid")

print("=== Chronos ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì‹œìŠ¤í…œ ===")
print(f"NumPy version: {np.__version__}")
print(f"Pandas version: {pd.__version__}")
print("ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")

class BusinessCalendar:
    def __init__(self, start_date='2023-01-02', end_date='2024-12-30'):
        self.start_date = pd.to_datetime(start_date)
        self.end_date = pd.to_datetime(end_date)
        
        # ì˜ì—…ì¼ ìƒì„± (ì£¼ë§ ì œì™¸)
        self.business_days = pd.bdate_range(
            start=self.start_date,
            end=self.end_date
        )
        
        # í•œêµ­ ê³µíœ´ì¼ (2023-2024ë…„ ì£¼ìš” ê³µíœ´ì¼)
        korean_holidays = [
            # 2023ë…„
            '2023-01-01', '2023-01-22', '2023-01-23', '2023-01-24',  # ì‹ ì •, ì„¤ë‚ 
            '2023-03-01', '2023-05-05', '2023-05-27', '2023-06-06',  # ì‚¼ì¼ì ˆ, ì–´ë¦°ì´ë‚ , ë¶€ì²˜ë‹˜ì˜¤ì‹ ë‚ , í˜„ì¶©ì¼
            '2023-08-15', '2023-09-28', '2023-09-29', '2023-09-30', # ê´‘ë³µì ˆ, ì¶”ì„
            '2023-10-03', '2023-10-09', '2023-12-25',               # ê°œì²œì ˆ, í•œê¸€ë‚ , ì„±íƒ„ì ˆ
            
            # 2024ë…„  
            '2024-01-01', '2024-02-09', '2024-02-10', '2024-02-12', # ì‹ ì •, ì„¤ë‚ 
            '2024-03-01', '2024-05-05', '2024-05-15', '2024-06-06', # ì‚¼ì¼ì ˆ, ì–´ë¦°ì´ë‚ , ë¶€ì²˜ë‹˜ì˜¤ì‹ ë‚ , í˜„ì¶©ì¼
            '2024-08-15', '2024-09-16', '2024-09-17', '2024-09-18', # ê´‘ë³µì ˆ, ì¶”ì„
            '2024-10-03', '2024-10-09', '2024-12-25'                # ê°œì²œì ˆ, í•œê¸€ë‚ , ì„±íƒ„ì ˆ
        ]
        
        holiday_dates = pd.to_datetime(korean_holidays)
        self.business_days = self.business_days.difference(holiday_dates)
        
        print(f"ì´ ì˜ì—…ì¼ ìˆ˜: {len(self.business_days)}ì¼")
        print(f"ì‹œì‘ì¼: {self.business_days[0].strftime('%Y-%m-%d')}")
        print(f"ì¢…ë£Œì¼: {self.business_days[-1].strftime('%Y-%m-%d')}")
        
    def get_day_characteristics(self, date):
        """ìš”ì¼ë³„ íŠ¹ì„± ë°˜í™˜"""
        day_of_week = date.weekday()
        
        characteristics = {
            0: {'name': 'Monday', 'energy': 0.85, 'stress': 1.1, 'social': 0.9},
            1: {'name': 'Tuesday', 'energy': 1.0, 'stress': 1.0, 'social': 1.0},
            2: {'name': 'Wednesday', 'energy': 1.05, 'stress': 0.95, 'social': 1.05},
            3: {'name': 'Thursday', 'energy': 1.0, 'stress': 1.0, 'social': 1.0},
            4: {'name': 'Friday', 'energy': 0.9, 'stress': 0.8, 'social': 1.15}
        }
        
        return characteristics.get(day_of_week, characteristics[1])

# ìº˜ë¦°ë” ìƒì„±
calendar = BusinessCalendar()

class IndividualCharacteristics:
    def __init__(self, employee_id, persona_code, attrition_status=None):
        self.employee_id = employee_id
        self.persona_code = persona_code
        self.attrition_status = attrition_status
        
        # ì§ì› ID ê¸°ë°˜ ì‹œë“œ ì„¤ì • (ì¬í˜„ ê°€ëŠ¥í•˜ì§€ë§Œ ê°œì¸ë³„ ê³ ìœ )
        individual_seed = int(str(employee_id)[-4:]) + hash(persona_code) % 1000
        self.rng = np.random.RandomState(individual_seed)  # ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
        
        self.individual_traits = self._generate_individual_traits()
        
        # ğŸ”¥ ì‹œë“œ ë³µì› ì œê±°! ê°œì¸ë³„ ì°¨ì´ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´
        # np.random.seed(42)  # ì´ ì¤„ì´ ë¬¸ì œì˜€ìŒ!
    
    def _generate_individual_traits(self):
        """ê°œì¸ë³„ ê³ ìœ  íŠ¹ì„± ìƒì„±"""
        
        # í‡´ì‚¬ì ì—¬ë¶€ì— ë”°ë¥¸ ê¸°ë³¸ í¸í–¥ ì„¤ì •
        attrition_bias = self._get_attrition_bias()
        
        traits = {
            # ê¸°ë³¸ ì„±í–¥ í¸í–¥ (í‡´ì‚¬ìëŠ” ë” ê·¹ë‹¨ì ) - ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
            'work_intensity_bias': self.rng.uniform(-0.4, 0.4) + attrition_bias.get('work_intensity', 0),
            'social_tendency_bias': self.rng.uniform(-0.4, 0.4) + attrition_bias.get('social_tendency', 0),
            'stress_sensitivity_bias': self.rng.uniform(-0.4, 0.4) + attrition_bias.get('stress_sensitivity', 0),
            'routine_preference_bias': self.rng.uniform(-0.3, 0.3),
            
            # ë³€ë™ì„± ê°œì¸ì°¨ (í‡´ì‚¬ìëŠ” ë” ë¶ˆì•ˆì •) - ë²”ìœ„ í™•ëŒ€
            'volatility_multiplier': self.rng.uniform(0.5, 1.8) * attrition_bias.get('volatility_mult', 1.0),
            
            # ë°˜ì‘ ì†ë„ ì°¨ì´ (í˜ë¥´ì†Œë‚˜ ë³€í™”ê°€ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬/ëŠ¦ê²Œ ë‚˜íƒ€ë‚˜ëŠ”ê°€)
            'change_rate_multiplier': self.rng.uniform(0.6, 1.6),
            
            # íŠ¹ì • ë³€ìˆ˜ì— ëŒ€í•œ ê°œì¸ì  ë¯¼ê°ë„ (í‡´ì‚¬ì íŠ¹ì„± ë°˜ì˜) - ë²”ìœ„ í™•ëŒ€
            'login_hours_sensitivity': self.rng.uniform(0.6, 1.5) * attrition_bias.get('login_sensitivity', 1.0),
            'communication_sensitivity': self.rng.uniform(0.6, 1.5) * attrition_bias.get('comm_sensitivity', 1.0),
            'social_eating_sensitivity': self.rng.uniform(0.6, 1.5),
            'stress_eating_tendency': self.rng.uniform(0.5, 2.0) * attrition_bias.get('stress_eating_mult', 1.0),
            
            # í‡´ì‚¬ì íŠ¹ë³„ ì§€í‘œë“¤
            'attrition_indicators': attrition_bias.get('indicators', {}),
            
            # í˜ë¥´ì†Œë‚˜ë³„ íŠ¹í™” ê°œì¸ì°¨
            'persona_specific_traits': self._get_persona_specific_traits()
        }
        
        return traits
    
    def _get_attrition_bias(self):
        """í‡´ì‚¬ ì—¬ë¶€ì— ë”°ë¥¸ í–‰ë™ í¸í–¥ ì„¤ì •"""
        
        if self.attrition_status == 'Yes':
            # í‡´ì‚¬ì: 2025ë…„ í‡´ì§ ì˜ˆì •ìë“¤ì˜ í–‰ë™ íŒ¨í„´
            return {
                'work_intensity': -0.15,        # ì—…ë¬´ ê°•ë„ ê°ì†Œ
                'social_tendency': -0.1,        # ì‚¬íšŒì  í™œë™ ê°ì†Œ  
                'stress_sensitivity': 0.2,      # ìŠ¤íŠ¸ë ˆìŠ¤ ë¯¼ê°ë„ ì¦ê°€
                'volatility_mult': 1.4,         # í–‰ë™ ë³€ë™ì„± ì¦ê°€
                'login_sensitivity': 0.85,      # ë¡œê·¸ì¸ ì‹œê°„ ë¶ˆê·œì¹™
                'comm_sensitivity': 0.75,       # ì†Œí†µëŸ‰ ê°ì†Œ ê²½í–¥
                'stress_eating_mult': 1.3,      # ìŠ¤íŠ¸ë ˆìŠ¤ ì‹ìŠµê´€ ì¦ê°€
                'indicators': {
                    'disengagement_trend': 0.002,    # ì ì§„ì  ì´íƒˆ ê²½í–¥
                    'routine_disruption': 1.2,       # ë£¨í‹´ íŒŒê´´ ê²½í–¥
                    'social_withdrawal': 1.15        # ì‚¬íšŒì  ìœ„ì¶•
                }
            }
        else:
            # ì¬ì§ì: ì•ˆì •ì ì¸ íŒ¨í„´ ìœ ì§€
            return {
                'work_intensity': 0.05,         # ì•½ê°„ì˜ ê¸ì •ì  í¸í–¥
                'social_tendency': 0.0,         # ì¤‘ë¦½ì 
                'stress_sensitivity': -0.05,    # ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ì–‘í˜¸
                'volatility_mult': 0.9,         # ì•ˆì •ì  í–‰ë™
                'login_sensitivity': 1.0,       # ê·œì¹™ì  ë¡œê·¸ì¸
                'comm_sensitivity': 1.05,       # í™œë°œí•œ ì†Œí†µ
                'stress_eating_mult': 0.9,      # ê±´ê°•í•œ ì‹ìŠµê´€
                'indicators': {
                    'engagement_stability': 1.0,     # ì•ˆì •ì  ëª°ì…
                    'routine_consistency': 1.0,      # ì¼ê´€ëœ ë£¨í‹´
                    'social_integration': 1.0        # ì‚¬íšŒì  í†µí•©
                }
            }
    
    def _get_persona_specific_traits(self):
        """í˜ë¥´ì†Œë‚˜ë³„ íŠ¹í™”ëœ ê°œì¸ íŠ¹ì„±"""
        
        if self.persona_code == 'P01_burnout':
            return {
                'burnout_trigger_threshold': np.random.uniform(0.6, 0.9),  # ë²ˆì•„ì›ƒ ì´‰ë°œ ì„ê³„ì 
                'recovery_difficulty': np.random.uniform(0.7, 1.0),        # íšŒë³µ ì–´ë ¤ì›€ ì •ë„
                'isolation_preference': np.random.uniform(0.5, 1.0),       # ê³ ë¦½ ì„ í˜¸ë„
                'workaholic_tendency': np.random.uniform(0.6, 1.0)         # ì›Œì»¤í™€ë¦­ ì„±í–¥
            }
        elif self.persona_code == 'S02_rising_star':
            return {
                'ambition_level': np.random.uniform(0.8, 1.0),             # ì•¼ë§ ìˆ˜ì¤€
                'networking_skill': np.random.uniform(0.7, 1.0),          # ë„¤íŠ¸ì›Œí‚¹ ëŠ¥ë ¥
                'innovation_drive': np.random.uniform(0.8, 1.0),          # í˜ì‹  ì¶”ì§„ë ¥
                'leadership_emergence_rate': np.random.uniform(0.8, 1.2)   # ë¦¬ë”ì‹­ ë°œí˜„ ì†ë„
            }
        elif self.persona_code == 'S01_anchor':
            return {
                'consistency_strength': np.random.uniform(0.9, 1.0),       # ì¼ê´€ì„± ê°•ë„
                'reliability_factor': np.random.uniform(0.95, 1.0),       # ì‹ ë¢°ì„± íŒ©í„°
                'change_resistance': np.random.uniform(0.8, 1.0),         # ë³€í™” ì €í•­ì„±
                'team_loyalty': np.random.uniform(0.9, 1.0)               # íŒ€ ì¶©ì„±ë„
            }
        else:
            return {'adaptability': np.random.uniform(0.7, 1.0)}

# ì‚¬ìš© ì˜ˆì‹œ
individual_char = IndividualCharacteristics(1001, 'P01_burnout')
print("ê°œì¸ë³„ íŠ¹ì„± ìƒì„± ì‹œìŠ¤í…œ ì™„ë£Œ")
print(f"ì§ì› 1001ì˜ íŠ¹ì„± ìƒ˜í”Œ:")
for key, value in list(individual_char.individual_traits.items())[:5]:
    print(f"  {key}: {value:.3f}")
    
# ê¸°ì¡´ ComprehensivePersonaPatterns í´ë˜ìŠ¤ëŠ” ì œê±°ë¨ - RealisticPersonaPatterns ì‚¬ìš©
    
class RealisticNoiseGenerator:
    def __init__(self):
        self.noise_cache = {}
    
    def gaussian_noise(self, base_value, intensity=0.1):
        """ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ"""
        return base_value * (1 + np.random.normal(0, intensity))
    
    def behavioral_noise(self, base_value, persona_code, volatility=0.1):
        """í˜ë¥´ì†Œë‚˜ë³„ í–‰ë™ íŒ¨í„´ ë…¸ì´ì¦ˆ"""
        behavioral_factors = {
            'P01_burnout': {'mood_swings': 0.3, 'inconsistency': 0.4},
            'P02_onboarding_failure': {'confusion': 0.35, 'anxiety': 0.25},
            'S01_anchor': {'stability': 0.05, 'consistency': 0.95},
            'S02_rising_star': {'enthusiasm': 0.15, 'innovation': 0.1}
        }
        
        factors = behavioral_factors.get(persona_code, {'default': 0.1})
        
        noise_multiplier = 1.0
        for factor_name, intensity in factors.items():
            if np.random.random() < intensity:
                if factor_name in ['mood_swings', 'confusion', 'anxiety']:
                    noise_multiplier *= np.random.uniform(0.7, 1.3)
                elif factor_name in ['enthusiasm', 'innovation']:
                    noise_multiplier *= np.random.uniform(1.0, 1.2)
        
        result = base_value * noise_multiplier * (1 + np.random.normal(0, volatility))
        return max(0.01, min(0.98, result))  # ë²”ìœ„ ì œí•œ
    
    def environmental_noise(self, base_value, date):
        """í™˜ê²½ì  ìš”ì¸ ë…¸ì´ì¦ˆ"""
        multiplier = 1.0
        
        # ê³„ì ˆì  ìš”ì¸
        month = date.month
        if month in [12, 1, 2]:  # ê²¨ìš¸
            multiplier *= 0.95
        elif month in [6, 7, 8]:  # ì—¬ë¦„
            multiplier *= 0.92
        
        # ìš”ì¼ íš¨ê³¼
        if date.weekday() == 0:  # ì›”ìš”ì¼
            multiplier *= 0.88
        elif date.weekday() == 4:  # ê¸ˆìš”ì¼
            multiplier *= 0.93
        
        # ì›”ë§ íš¨ê³¼
        if date.day >= 25:
            multiplier *= 1.08
        
        return base_value * multiplier

# ë…¸ì´ì¦ˆ ìƒì„±ê¸° ì´ˆê¸°í™”
noise_generator = RealisticNoiseGenerator()
print("ë…¸ì´ì¦ˆ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

# ì´ í•¨ìˆ˜ëŠ” generate_realistic_variables_consistentë¡œ ëŒ€ì²´ë¨

# ì´ í•¨ìˆ˜ëŠ” generate_communication_food_variablesë¡œ ëŒ€ì²´ë¨

print("ì¶”ê°€ ë³€ìˆ˜ ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ")

# Cell 5: ì¼ê´€ì„± ìˆëŠ” í˜„ì‹¤ì  ë³€ìˆ˜ ìƒì„± ì‹œìŠ¤í…œ

# 1. í˜ë¥´ì†Œë‚˜ íŒ¨í„´ ê°ì²´ ìƒì„± (í˜„ì‹¤ì  ë³€ìˆ˜ë§Œ í¬í•¨)
class RealisticPersonaPatterns:
    def __init__(self):
        self.patterns = {
            # ê³ ìœ„í—˜êµ°
            'P01_burnout': {
                'description': 'ë²ˆì•„ì›ƒì— ì§ë©´í•œ ì§ì›',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0) - ë” ê·¹ë‹¨ì  ë³€í™”
                'work_focused_ratio': {'stage1': 0.75, 'stage2': 0.50, 'stage3': 0.30, 'volatility': 0.20},
                'meeting_collaboration_ratio': {'stage1': 0.15, 'stage2': 0.08, 'stage3': 0.05, 'volatility': 0.10},
                'social_dining_ratio': {'stage1': 0.06, 'stage2': 0.03, 'stage3': 0.02, 'volatility': 0.04},
                'break_relaxation_ratio': {'stage1': 0.03, 'stage2': 0.25, 'stage3': 0.45, 'volatility': 0.15},
                'shared_work_ratio': {'stage1': 0.01, 'stage2': 0.14, 'stage3': 0.18, 'volatility': 0.08},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤ - ë” ëª…í™•í•œ ì°¨ì´
                'system_login_hours': {'stage1': 10.5, 'stage2': 12.8, 'stage3': 5.2, 'volatility': 2.0},
                'internal_comm_volume': {'stage1': 35, 'stage2': 12, 'stage3': 3, 'volatility': 10},
                'cafeteria_usage': {'stage1': 1.4, 'stage2': 0.6, 'stage3': 0.2, 'volatility': 0.5},
                'convenience_food_usage': {'stage1': 1.2, 'stage2': 4.5, 'stage3': 7.8, 'volatility': 1.5}
            },
            
            'P02_onboarding_failure': {
                'description': 'ì˜¨ë³´ë”©ì— ì‹¤íŒ¨í•œ ì§ì›',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0)
                'work_focused_ratio': {'base': 0.35, 'volatility': 0.20},
                'meeting_collaboration_ratio': {'base': 0.15, 'volatility': 0.08},
                'social_dining_ratio': {'base': 0.04, 'volatility': 0.02},
                'break_relaxation_ratio': {'base': 0.25, 'volatility': 0.15},
                'shared_work_ratio': {'base': 0.21, 'volatility': 0.12},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
                'system_login_hours': {'base': 6.8, 'volatility': 1.8},
                'internal_comm_volume': {'base': 12, 'volatility': 6, 'help_seeking_bursts': True},
                'cafeteria_usage': {'base': 0.4, 'volatility': 0.2},
                'convenience_food_usage': {'base': 2.8, 'volatility': 1.0}
            },
            
            'P03_career_stagnation': {
                'description': 'ì„±ì¥ì´ ì •ì²´ëœ ì§ì›',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0)
                'work_focused_ratio': {'base': 0.62, 'volatility': 0.05},
                'meeting_collaboration_ratio': {'base': 0.12, 'volatility': 0.03},
                'social_dining_ratio': {'base': 0.08, 'volatility': 0.02},
                'break_relaxation_ratio': {'base': 0.12, 'volatility': 0.04},
                'shared_work_ratio': {'base': 0.06, 'volatility': 0.02},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
                'system_login_hours': {'base': 8.3, 'volatility': 0.4},
                'internal_comm_volume': {'base': 18, 'trend': -0.002, 'volatility': 4},
                'cafeteria_usage': {'base': 0.9, 'volatility': 0.1},
                'convenience_food_usage': {'base': 1.1, 'volatility': 0.3}
            },
            
            'P04_under_compensated': {
                'description': 'ì €í‰ê°€ëœ ì§ì›',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0)
                'work_focused_ratio': {'base': 0.68, 'volatility': 0.06},
                'meeting_collaboration_ratio': {'base': 0.16, 'volatility': 0.04},
                'social_dining_ratio': {'base': 0.09, 'volatility': 0.02},
                'break_relaxation_ratio': {'base': 0.05, 'volatility': 0.02},
                'shared_work_ratio': {'base': 0.02, 'volatility': 0.01},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
                'system_login_hours': {'base': 8.5, 'volatility': 0.3},
                'internal_comm_volume': {'base': 22, 'volatility': 4},
                'cafeteria_usage': {'base': 1.0, 'volatility': 0.2},
                'convenience_food_usage': {'base': 1.3, 'volatility': 0.4}
            },
            
            # ì•ˆì • ë° ëª°ì…êµ°
            'S01_anchor': {
                'description': 'ì•ˆì •ì ì¸ í•µì‹¬ì¸ì¬',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0) - ë§¤ìš° ì•ˆì •ì 
                'work_focused_ratio': {'base': 0.68, 'volatility': 0.02},
                'meeting_collaboration_ratio': {'base': 0.20, 'volatility': 0.01},
                'social_dining_ratio': {'base': 0.08, 'volatility': 0.01},
                'break_relaxation_ratio': {'base': 0.03, 'volatility': 0.01},
                'shared_work_ratio': {'base': 0.01, 'volatility': 0.005},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤ - ë†’ê³  ì•ˆì •ì 
                'system_login_hours': {'base': 8.7, 'volatility': 0.2},
                'internal_comm_volume': {'base': 28, 'volatility': 2},
                'cafeteria_usage': {'base': 1.2, 'volatility': 0.08},
                'convenience_food_usage': {'base': 0.5, 'volatility': 0.1}
            },
            
            'S02_rising_star': {
                'description': 'ë¼ì´ì§• ìŠ¤íƒ€',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0)
                'work_focused_ratio': {'base': 0.58, 'volatility': 0.06},
                'meeting_collaboration_ratio': {'base': 0.25, 'trend': 0.0002, 'volatility': 0.04},
                'social_dining_ratio': {'base': 0.10, 'volatility': 0.02},
                'break_relaxation_ratio': {'base': 0.03, 'volatility': 0.01},
                'shared_work_ratio': {'base': 0.04, 'trend': 0.0001, 'volatility': 0.03},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
                'system_login_hours': {'base': 9.2, 'volatility': 0.6},
                'internal_comm_volume': {'base': 35, 'trend': 0.01, 'volatility': 5},
                'cafeteria_usage': {'base': 1.3, 'volatility': 0.3},
                'convenience_food_usage': {'base': 1.2, 'volatility': 0.3}
            },
            
            'S03_intrinsically_motivated': {
                'description': 'ë‚´ì¬ì  ë™ê¸°ê°€ ë†’ì€ ì§ì›',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0)
                'work_focused_ratio': {'base': 0.70, 'volatility': 0.04},
                'meeting_collaboration_ratio': {'base': 0.15, 'volatility': 0.03},
                'social_dining_ratio': {'base': 0.08, 'volatility': 0.02},
                'break_relaxation_ratio': {'base': 0.05, 'volatility': 0.02},
                'shared_work_ratio': {'base': 0.02, 'volatility': 0.01},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
                'system_login_hours': {'base': 8.8, 'volatility': 0.4},
                'internal_comm_volume': {'base': 18, 'volatility': 3},
                'cafeteria_usage': {'base': 0.9, 'volatility': 0.15},
                'convenience_food_usage': {'base': 0.9, 'volatility': 0.25}
            },
            
            # ì¤‘ë¦½ ë° ê´€ë§êµ°
            'N01_coaster': {
                'description': 'í˜„ìƒë§Œ ìœ ì§€í•˜ëŠ” ì§ì›',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0)
                'work_focused_ratio': {'base': 0.60, 'volatility': 0.02},
                'meeting_collaboration_ratio': {'base': 0.15, 'volatility': 0.02},
                'social_dining_ratio': {'base': 0.10, 'volatility': 0.01},
                'break_relaxation_ratio': {'base': 0.12, 'volatility': 0.02},
                'shared_work_ratio': {'base': 0.03, 'volatility': 0.01},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
                'system_login_hours': {'base': 8.0, 'volatility': 0.2},
                'internal_comm_volume': {'base': 15, 'volatility': 2},
                'cafeteria_usage': {'base': 0.9, 'volatility': 0.1},
                'convenience_food_usage': {'base': 1.2, 'volatility': 0.3}
            },
            
            'N02_competent_malcontent': {
                'description': 'ìœ ëŠ¥í•˜ì§€ë§Œ ë¶ˆë§Œì´ ë§ì€ ì§ì›',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0)
                'work_focused_ratio': {'base': 0.68, 'volatility': 0.08},
                'meeting_collaboration_ratio': {'base': 0.10, 'volatility': 0.05},
                'social_dining_ratio': {'base': 0.06, 'volatility': 0.03},
                'break_relaxation_ratio': {'base': 0.08, 'volatility': 0.04},
                'shared_work_ratio': {'base': 0.08, 'volatility': 0.05},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
                'system_login_hours': {'base': 8.2, 'volatility': 0.5},
                'internal_comm_volume': {'base': 12, 'volatility': 6},
                'cafeteria_usage': {'base': 0.7, 'volatility': 0.2},
                'convenience_food_usage': {'base': 1.4, 'volatility': 0.5}
            },
            
            'N03_new_parent': {
                'description': 'ì‹ ê·œ ë¶€ëª¨',
                # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ (í•©ê³„ = 1.0)
                'work_focused_ratio': {'base': 0.62, 'volatility': 0.06},
                'meeting_collaboration_ratio': {'base': 0.18, 'volatility': 0.04},
                'social_dining_ratio': {'base': 0.08, 'volatility': 0.02},
                'break_relaxation_ratio': {'base': 0.08, 'volatility': 0.03},
                'shared_work_ratio': {'base': 0.04, 'volatility': 0.02},
                
                # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
                'system_login_hours': {'base': 7.5, 'volatility': 0.8},
                'internal_comm_volume': {'base': 20, 'volatility': 4},
                'cafeteria_usage': {'base': 0.8, 'volatility': 0.2},
                'convenience_food_usage': {'base': 1.1, 'volatility': 0.3}
            }
        }
    
    def get_pattern(self, persona_code):
        return self.patterns.get(persona_code, self.patterns['S01_anchor'])

# í˜ë¥´ì†Œë‚˜ íŒ¨í„´ ê°ì²´ ìƒì„±
persona_patterns = RealisticPersonaPatterns()
print("í˜„ì‹¤ì  í˜ë¥´ì†Œë‚˜ íŒ¨í„´ ê°ì²´ ìƒì„± ì™„ë£Œ")

def generate_realistic_variables_consistent(employee_id, persona_code, day_index, date, attrition_status=None):
    """ì¼ê´€ì„± ìˆëŠ” í˜„ì‹¤ì  ë³€ìˆ˜ë§Œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    
    # ê°œì¸ íŠ¹ì„± ë¡œë“œ (í‡´ì‚¬ ì •ë³´ í¬í•¨)
    individual = IndividualCharacteristics(employee_id, persona_code, attrition_status)
    traits = individual.individual_traits
    
    # ê¸°ë³¸ íŒ¨í„´ ë¡œë“œ
    pattern = persona_patterns.get_pattern(persona_code)
    all_vars = {}
    
    # 1. ê³µê°„ë³„ ë¹„ìœ¨ ìƒì„± (í•©ê³„ = 1.0)
    space_ratios = generate_space_ratios_consistent(
        employee_id, persona_code, day_index, date, pattern, traits
    )
    all_vars.update(space_ratios)
    
    # 2. ì‹œìŠ¤í…œ ë¡œê·¸ì¸ ì‹œê°„ ìƒì„±
    login_hours = generate_login_hours_consistent(
        employee_id, persona_code, day_index, date, pattern, traits
    )
    all_vars.update(login_hours)
    
    # 3. ê³µê°„ë³„ ì‹œê°„ ê³„ì‚° (ë¹„ìœ¨ Ã— ë¡œê·¸ì¸ ì‹œê°„)
    total_hours = all_vars['system_login_hours']
    space_hour_vars = {}
    for space in ['work_focused', 'meeting_collaboration', 'social_dining', 'break_relaxation', 'shared_work']:
        ratio_key = f"{space}_ratio"
        hour_key = f"{space}_hours"
        if ratio_key in all_vars:
            space_hour_vars[hour_key] = all_vars[ratio_key] * total_hours
    all_vars.update(space_hour_vars)
    
    # 4. ì†Œí†µ ë° ì‹ìƒí™œ ë³€ìˆ˜ ìƒì„±
    comm_food_vars = generate_communication_food_variables(
        employee_id, persona_code, day_index, date, pattern, traits
    )
    all_vars.update(comm_food_vars)
    
    # 5. í‡´ì‚¬ì íŠ¹ë³„ ì²˜ë¦¬ (ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ì´íƒˆ íŒ¨í„´)
    if attrition_status == 'Yes':
        all_vars = apply_attrition_patterns(all_vars, day_index, traits)
    
    return all_vars

def apply_attrition_patterns(variables, day_index, traits):
    """í‡´ì‚¬ìì˜ ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ì´íƒˆ íŒ¨í„´ ì ìš©"""
    
    # ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ì´íƒˆ ê°•ë„ (0 -> 1ë¡œ ì ì§„ì  ì¦ê°€)
    total_days = 105  # ì „ì²´ ê¸°ê°„
    disengagement_progress = min(day_index / total_days, 1.0)
    
    # í‡´ì‚¬ì íŠ¹ë³„ ì§€í‘œë“¤
    attrition_indicators = traits.get('attrition_indicators', {})
    
    # ì ì§„ì  ì´íƒˆ ê²½í–¥ ì ìš©
    disengagement_trend = attrition_indicators.get('disengagement_trend', 0)
    routine_disruption = attrition_indicators.get('routine_disruption', 1.0)
    social_withdrawal = attrition_indicators.get('social_withdrawal', 1.0)
    
    # ì—…ë¬´ ì§‘ì¤‘ë„ ì ì§„ì  ê°ì†Œ
    if 'work_focused_ratio' in variables:
        decline_factor = 1.0 - (disengagement_progress * disengagement_trend * 50)
        variables['work_focused_ratio'] *= max(0.3, decline_factor)
    
    # íœ´ì‹ ì‹œê°„ ì ì§„ì  ì¦ê°€
    if 'break_relaxation_ratio' in variables:
        increase_factor = 1.0 + (disengagement_progress * routine_disruption * 0.5)
        variables['break_relaxation_ratio'] *= increase_factor
    
    # ì†Œí†µëŸ‰ ê°ì†Œ
    if 'internal_comm_volume' in variables:
        comm_decline = 1.0 - (disengagement_progress * social_withdrawal * 0.4)
        variables['internal_comm_volume'] = int(variables['internal_comm_volume'] * max(0.2, comm_decline))
    
    # ì¹´í˜í…Œë¦¬ì•„ ì‚¬ìš© ê°ì†Œ (ì‚¬íšŒì  ìœ„ì¶•)
    if 'cafeteria_usage' in variables:
        social_decline = 1.0 - (disengagement_progress * social_withdrawal * 0.3)
        variables['cafeteria_usage'] *= max(0.1, social_decline)
    
    # í¸ì˜ì  ìŒì‹ ì¦ê°€ (ìŠ¤íŠ¸ë ˆìŠ¤ ì‹ìŠµê´€)
    if 'convenience_food_usage' in variables:
        stress_increase = 1.0 + (disengagement_progress * routine_disruption * 0.6)
        variables['convenience_food_usage'] *= stress_increase
    
    # ë¡œê·¸ì¸ ì‹œê°„ ë¶ˆê·œì¹™ì„± ì¦ê°€ - ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
    if 'system_login_hours' in variables:
        # employee_id ì •ë³´ë¥¼ traitsì—ì„œ ì¶”ì¶œ (ì„ì‹œ ë°©ë²•)
        emp_id = hash(str(traits)) % 10000  # traits ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ  ID ìƒì„±
        rng_irreg = np.random.RandomState(emp_id + day_index + 5000)
        irregularity = 1.0 + (disengagement_progress * routine_disruption * 0.3 * rng_irreg.uniform(-1, 1))
        variables['system_login_hours'] *= max(0.5, irregularity)
    
    # ë¹„ìœ¨ ì¬ì •ê·œí™” (ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ë“¤)
    ratio_keys = [k for k in variables.keys() if k.endswith('_ratio')]
    if ratio_keys:
        total_ratio = sum(variables[k] for k in ratio_keys)
        for k in ratio_keys:
            variables[k] = variables[k] / total_ratio
    
    # ì‹œê°„ ì¬ê³„ì‚°
    if 'system_login_hours' in variables:
        total_hours = variables['system_login_hours']
        for space in ['work_focused', 'meeting_collaboration', 'social_dining', 'break_relaxation', 'shared_work']:
            ratio_key = f"{space}_ratio"
            hour_key = f"{space}_hours"
            if ratio_key in variables:
                variables[hour_key] = variables[ratio_key] * total_hours
    
    return variables

def generate_space_ratios_consistent(employee_id, persona_code, day_index, date, pattern, traits):
    """ì¼ê´€ì„± ìˆëŠ” ê³µê°„ë³„ ë¹„ìœ¨ ìƒì„± (í•©ê³„ = 1.0)"""
    
    day_chars = calendar.get_day_characteristics(date)
    space_vars = {}
    
    # 5ê°œ ê³µê°„ ë¹„ìœ¨ ìƒì„±
    space_names = ['work_focused_ratio', 'meeting_collaboration_ratio', 
                   'social_dining_ratio', 'break_relaxation_ratio', 'shared_work_ratio']
    
    for space in space_names:
        space_config = pattern.get(space, {'base': 0.2, 'volatility': 0.05})
        
        # ë‹¨ê³„ì  íŒ¨í„´ (P01 burnout) ë˜ëŠ” ê¸°ë³¸ íŒ¨í„´
        if 'stage1' in space_config:
            progress = min(day_index / 300, 1.0)
            if progress < 0.33:
                base_ratio = space_config['stage1']
            elif progress < 0.66:
                base_ratio = space_config['stage2']
            else:
                base_ratio = space_config['stage3']
        else:
            base_ratio = space_config['base']
            if 'trend' in space_config:
                base_ratio += space_config['trend'] * day_index
        
        # ê°œì¸ë³„ íŠ¹ì„± ì ìš©
        if space == 'work_focused_ratio':
            base_ratio *= (1 + traits.get('work_intensity_bias', 0))
        elif space == 'social_dining_ratio':
            base_ratio *= (1 + traits.get('social_tendency_bias', 0))
            base_ratio *= traits.get('social_eating_sensitivity', 1.0)
        elif space == 'break_relaxation_ratio':
            base_ratio *= (1 + traits.get('stress_sensitivity_bias', 0))
        
        # ìš”ì¼ íš¨ê³¼ ì ìš©
        if space == 'social_dining_ratio' and date.weekday() == 4:  # ê¸ˆìš”ì¼
            base_ratio *= 1.3
        
        # ë…¸ì´ì¦ˆ ì ìš© - ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
        volatility = space_config.get('volatility', 0.05) * traits.get('volatility_multiplier', 1.0)
        # ì „ì—­ np.random ëŒ€ì‹  ê°œì¸ë³„ ì‹œë“œ ì‚¬ìš©
        noise = np.random.RandomState(employee_id + day_index).normal(0, volatility)
        base_ratio *= (1 + noise)
        
        space_vars[space] = max(0.01, base_ratio)
    
    # ì •ê·œí™” (í•©ê³„ = 1.0)
    total_ratio = sum(space_vars.values())
    for space in space_names:
        space_vars[space] = space_vars[space] / total_ratio
    
    return space_vars

def generate_login_hours_consistent(employee_id, persona_code, day_index, date, pattern, traits):
    """ì¼ê´€ì„± ìˆëŠ” ì‹œìŠ¤í…œ ë¡œê·¸ì¸ ì‹œê°„ ìƒì„±"""
    
    hours_config = pattern.get('system_login_hours', {'base': 8.5, 'volatility': 0.5})
    day_chars = calendar.get_day_characteristics(date)
    
    # ë‹¨ê³„ì  íŒ¨í„´ ë˜ëŠ” ê¸°ë³¸ íŒ¨í„´
    if 'stage1' in hours_config:
        progress = min(day_index / 300, 1.0)
        if progress < 0.33:
            base_hours = hours_config['stage1']
        elif progress < 0.66:
            base_hours = hours_config['stage2']
        else:
            base_hours = hours_config['stage3']
    else:
        base_hours = hours_config['base']
    
    # ê°œì¸ë³„ íŠ¹ì„± ë° ìš”ì¼ íš¨ê³¼ ì ìš©
    base_hours *= traits.get('login_hours_sensitivity', 1.0)
    base_hours *= day_chars['energy']
    
    # ë…¸ì´ì¦ˆ ì ìš© - ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
    volatility = hours_config.get('volatility', 0.5)
    noise = np.random.RandomState(employee_id + day_index + 1000).normal(0, volatility)
    base_hours += noise
    base_hours = max(4.0, min(16.0, base_hours))
    
    return {'system_login_hours': base_hours}

def generate_communication_food_variables(employee_id, persona_code, day_index, date, pattern, traits):
    """ì†Œí†µ ë° ì‹ìƒí™œ ê´€ë ¨ ë³€ìˆ˜ ìƒì„±"""
    
    comm_food_vars = {}
    day_chars = calendar.get_day_characteristics(date)
    
    # Internal Communication Volume
    comm_config = pattern.get('internal_comm_volume', {'base': 20, 'volatility': 5})
    
    if 'stage1' in comm_config:
        progress = min(day_index / 300, 1.0)
        if progress < 0.33:
            base_comm = comm_config['stage1']
        elif progress < 0.66:
            base_comm = comm_config['stage2']
        else:
            base_comm = comm_config['stage3']
    else:
        base_comm = comm_config['base']
        if 'trend' in comm_config:
            base_comm += comm_config['trend'] * day_index
    
    # ìš”ì¼ íš¨ê³¼ ë° ê°œì¸ íŠ¹ì„± ì ìš©
    base_comm *= day_chars['social']
    base_comm *= traits.get('communication_sensitivity', 1.0)
    
    # íŠ¹ìˆ˜ íŒ¨í„´ (ë„ì›€ ìš”ì²­ í­ì¦) - ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
    if comm_config.get('help_seeking_bursts', False):
        rng_burst = np.random.RandomState(employee_id + day_index + 1500)
        if rng_burst.random() < 0.15:
            base_comm *= rng_burst.uniform(2.0, 3.5)
    
    volatility = comm_config.get('volatility', 5)
    # ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
    rng = np.random.RandomState(employee_id + day_index + 2000)
    noise_factor = 1 + rng.normal(0, volatility/max(base_comm, 1))
    comm_food_vars['internal_comm_volume'] = max(0, int(base_comm * noise_factor))
    
    # Cafeteria Usage
    cafe_config = pattern.get('cafeteria_usage', {'base': 1.0, 'volatility': 0.2})
    
    if 'stage1' in cafe_config:
        progress = min(day_index / 300, 1.0)
        if progress < 0.33:
            base_cafe = cafe_config['stage1']
        elif progress < 0.66:
            base_cafe = cafe_config['stage2']
        else:
            base_cafe = cafe_config['stage3']
    else:
        base_cafe = cafe_config['base']
    
    # ê¸ˆìš”ì¼ ì‚¬íšŒì  ì‹ì‚¬ ì¦ê°€
    if date.weekday() == 4:
        base_cafe *= 1.2
    
    # ê°œì¸ë³„ íŠ¹ì„± ì ìš©
    base_cafe *= traits.get('social_eating_sensitivity', 1.0)
    
    # ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
    rng_cafe = np.random.RandomState(employee_id + day_index + 3000)
    cafe_noise = 1 + rng_cafe.normal(0, cafe_config.get('volatility', 0.2))
    comm_food_vars['cafeteria_usage'] = max(0, min(3, base_cafe * cafe_noise))
    
    # Convenience Food Usage
    conv_config = pattern.get('convenience_food_usage', {'base': 1.5, 'volatility': 0.5})
    
    if 'stage1' in conv_config:
        progress = min(day_index / 300, 1.0)
        if progress < 0.33:
            base_conv = conv_config['stage1']
        elif progress < 0.66:
            base_conv = conv_config['stage2']
        else:
            base_conv = conv_config['stage3']
    else:
        base_conv = conv_config['base']
    
    # ìŠ¤íŠ¸ë ˆìŠ¤ì™€ ìƒê´€ê´€ê³„
    base_conv *= traits.get('stress_eating_tendency', 1.0)
    
    # ê°œë³„ ëœë¤ ìƒì„±ê¸° ì‚¬ìš©
    rng_conv = np.random.RandomState(employee_id + day_index + 4000)
    conv_noise = 1 + rng_conv.normal(0, conv_config.get('volatility', 0.5))
    comm_food_vars['convenience_food_usage'] = max(0, min(8, base_conv * conv_noise))
    
    return comm_food_vars

def generate_realistic_behavioral_variables(persona_code, day_index, date, pattern, traits):
    """í˜„ì‹¤ì ìœ¼ë¡œ ì¸¡ì • ê°€ëŠ¥í•œ í–‰ë™ ì§€í‘œ ìƒì„±"""
    
    realistic_vars = {}
    day_chars = calendar.get_day_characteristics(date)
    
    # 1. Meeting Participation (ìº˜ë¦°ë” ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ì¸¡ì • ê°€ëŠ¥)
    meeting_config = pattern.get('meeting_participation', {'base': 0.7, 'volatility': 0.1})
    
    if 'stage1' in meeting_config:  # ë‹¨ê³„ì  íŒ¨í„´ (P01 burnout)
        progress = min(day_index / 300, 1.0)
        if progress < 0.33:
            base_meeting = meeting_config['stage1']
        elif progress < 0.66:
            base_meeting = meeting_config['stage2']
        else:
            base_meeting = meeting_config['stage3']
    else:
        base_meeting = meeting_config['base']
        if 'trend' in meeting_config:
            base_meeting += meeting_config['trend'] * day_index
    
    # ê°œì¸ë³„ íŠ¹ì„± ì ìš©
    if traits:
        base_meeting *= (1 + traits.get('social_tendency_bias', 0) * 0.2)
    
    # íŠ¹ìˆ˜ íŒ¨í„´
    if meeting_config.get('passive_attendance', False):  # P02
        base_meeting *= 0.8  # ìˆ˜ë™ì  ì°¸ì„
    elif meeting_config.get('reliable_participant', False):  # S01
        volatility = 0.05  # ë§¤ìš° ì•ˆì •ì 
    else:
        volatility = meeting_config.get('volatility', 0.1)
    
    realistic_vars['meeting_participation'] = max(0.0, min(1.0,
        noise_generator.behavioral_noise(base_meeting, persona_code, volatility)
    ))
    
    # 2. Internal Communication Volume (ì‹¤ì œ ì¸¡ì • ê°€ëŠ¥)
    comm_config = pattern.get('internal_comm_volume', {'base': 20, 'volatility': 5})
    
    if 'stage1' in comm_config:
        progress = min(day_index / 300, 1.0)
        if progress < 0.33:
            base_comm = comm_config['stage1']
        elif progress < 0.66:
            base_comm = comm_config['stage2']
        else:
            base_comm = comm_config['stage3']
    else:
        base_comm = comm_config['base']
        if 'trend' in comm_config:
            base_comm += comm_config['trend'] * day_index
    
    # ìš”ì¼ íš¨ê³¼ ì ìš©
    base_comm *= day_chars['social']
    
    # ê°œì¸ë³„ íŠ¹ì„± ì ìš©
    if traits:
        base_comm *= traits.get('communication_sensitivity', 1.0)
    
    # íŠ¹ìˆ˜ íŒ¨í„´
    if comm_config.get('help_seeking_bursts', False):
        if np.random.random() < 0.15:  # 15% í™•ë¥ ë¡œ ë„ì›€ ìš”ì²­ í­ì¦
            base_comm *= np.random.uniform(2.0, 3.5)
    
    volatility = comm_config.get('volatility', 5)
    realistic_vars['internal_comm_volume'] = max(0, int(
        noise_generator.gaussian_noise(base_comm, volatility/max(base_comm, 1))
    ))
    
    return realistic_vars

# ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ - generate_space_ratios_consistent ì‚¬ìš©

def generate_work_engagement_personalized(persona_code, day_index, date, pattern, traits):
    """ê°œì¸í™”ëœ ì—…ë¬´ ëª°ì…ë„ ë³€ìˆ˜ ìƒì„±"""
    
    work_vars = {}
    
    # Digital Work Engagement
    engagement_config = pattern.get('digital_work_engagement', {'base': 0.7})
    
    if 'stage1' in engagement_config:
        adjusted_day_index = day_index * traits.get('change_rate_multiplier', 1.0)
        progress = min(adjusted_day_index / 300, 1.0)
        
        if progress < 0.33:
            base_engagement = engagement_config['stage1']
        elif progress < 0.66:
            base_engagement = engagement_config['stage2']
        else:
            base_engagement = engagement_config['stage3']
    else:
        base_engagement = engagement_config['base']
        if 'trend' in engagement_config:
            base_engagement += engagement_config['trend'] * day_index
    
    # ê°œì¸ë³„ íŠ¹ì„± ì ìš©
    base_engagement *= (1 + traits.get('work_intensity_bias', 0) * 0.4)
    
    # í™˜ê²½ì  ìš”ì¸ ì ìš©
    day_chars = calendar.get_day_characteristics(date)
    base_engagement *= day_chars['energy']
    
    volatility = engagement_config.get('volatility', 0.1) * traits.get('volatility_multiplier', 1.0)
    work_vars['digital_work_engagement'] = max(0.1, min(1.0,
        noise_generator.gaussian_noise(base_engagement, volatility)
    ))
    
    # System Login Hours
    hours_config = pattern.get('system_login_hours', {'base': 8.5, 'volatility': 0.5})
    
    if 'stage1' in hours_config:
        progress = min(day_index / 300, 1.0)
        if progress < 0.33:
            base_hours = hours_config['stage1']
        elif progress < 0.66:
            base_hours = hours_config['stage2']
        else:
            base_hours = hours_config['stage3']
    else:
        base_hours = hours_config['base']
    
    # ê°œì¸ë³„ íŠ¹ì„± ë° ìš”ì¼ íš¨ê³¼
    base_hours *= traits.get('login_hours_sensitivity', 1.0)
    base_hours *= day_chars['energy']
    
    volatility = hours_config.get('volatility', 0.5)
    work_vars['system_login_hours'] = max(4.0, min(16.0,
        noise_generator.gaussian_noise(base_hours, volatility)
    ))
    
    return work_vars

# ì´ í•¨ìˆ˜ëŠ” generate_communication_food_variablesë¡œ í†µí•©ë¨

print("Cell 5 - í˜„ì‹¤ì  ê°œì¸í™” ë³€ìˆ˜ ìƒì„± í•¨ìˆ˜ ì™„ë£Œ")

# Cell 6: ì…€ 5ì— ë§ì¶˜ ì•ˆì „í•œ ì‹œê³„ì—´ ìƒì„± í•¨ìˆ˜ (ì˜ì¡´ì„± ì²´í¬ í¬í•¨)

# 1. ì˜ì¡´ì„± ì²´í¬ ë° ë³µêµ¬
try:
    # persona_patterns ê°ì²´ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    test_pattern = persona_patterns.get_pattern('P01_burnout')
    print("ê¸°ì¡´ persona_patterns ê°ì²´ ì‚¬ìš©")
except NameError:
    # ì—†ìœ¼ë©´ ë‹¤ì‹œ ìƒì„±
    print("persona_patterns ê°ì²´ê°€ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
    
    class ComprehensivePersonaPatterns:
        def __init__(self):
            self.patterns = {
                # ê³ ìœ„í—˜êµ°
                'P01_burnout': {
                    'description': 'ë²ˆì•„ì›ƒì— ì§ë©´í•œ ì§ì›',
                    'work_focused_ratio': {'stage1': 0.70, 'stage2': 0.58, 'stage3': 0.42, 'volatility': 0.15},
                    'meeting_collaboration_ratio': {'stage1': 0.18, 'stage2': 0.12, 'stage3': 0.08, 'volatility': 0.08},
                    'social_dining_ratio': {'stage1': 0.08, 'stage2': 0.05, 'stage3': 0.03, 'volatility': 0.03},
                    'break_relaxation_ratio': {'stage1': 0.03, 'stage2': 0.18, 'stage3': 0.37, 'volatility': 0.12},
                    'shared_work_ratio': {'stage1': 0.01, 'stage2': 0.07, 'stage3': 0.10, 'volatility': 0.05},
                    
                    'digital_work_engagement': {'stage1': 0.75, 'stage2': 0.55, 'stage3': 0.35, 'volatility': 0.20},
                    'system_login_hours': {'stage1': 9.5, 'stage2': 11.2, 'stage3': 7.8, 'volatility': 1.5},
                    'internal_comm_volume': {'stage1': 25, 'stage2': 15, 'stage3': 8, 'volatility': 8},
                    'cafeteria_usage': {'stage1': 1.2, 'stage2': 0.8, 'stage3': 0.3, 'volatility': 0.4},
                    'convenience_food_usage': {'stage1': 1.5, 'stage2': 3.2, 'stage3': 4.8, 'volatility': 1.2},
                    'meeting_participation': {'stage1': 0.8, 'stage2': 0.6, 'stage3': 0.3, 'volatility': 0.15}
                },
                
                'P02_onboarding_failure': {
                    'description': 'ì˜¨ë³´ë”©ì— ì‹¤íŒ¨í•œ ì§ì›',
                    'work_focused_ratio': {'base': 0.35, 'volatility': 0.20},
                    'meeting_collaboration_ratio': {'base': 0.15, 'volatility': 0.08},
                    'social_dining_ratio': {'base': 0.04, 'volatility': 0.02},
                    'break_relaxation_ratio': {'base': 0.25, 'volatility': 0.15},
                    'shared_work_ratio': {'base': 0.21, 'volatility': 0.12},
                    
                    'digital_work_engagement': {'base': 0.35, 'volatility': 0.25},
                    'system_login_hours': {'base': 6.8, 'volatility': 1.8},
                    'internal_comm_volume': {'base': 12, 'volatility': 6, 'help_seeking_bursts': True},
                    'cafeteria_usage': {'base': 0.4, 'volatility': 0.2},
                    'convenience_food_usage': {'base': 2.8, 'volatility': 1.0},
                    'meeting_participation': {'base': 0.4, 'volatility': 0.2, 'passive_attendance': True}
                },
                
                'P03_career_stagnation': {
                    'description': 'ì„±ì¥ì´ ì •ì²´ëœ ì§ì›',
                    'work_focused_ratio': {'base': 0.62, 'volatility': 0.05},
                    'meeting_collaboration_ratio': {'base': 0.12, 'volatility': 0.03},
                    'social_dining_ratio': {'base': 0.08, 'volatility': 0.02},
                    'break_relaxation_ratio': {'base': 0.12, 'volatility': 0.04},
                    'shared_work_ratio': {'base': 0.06, 'volatility': 0.02},
                    
                    'digital_work_engagement': {'base': 0.58, 'volatility': 0.08},
                    'system_login_hours': {'base': 8.3, 'volatility': 0.4},
                    'internal_comm_volume': {'base': 18, 'trend': -0.002, 'volatility': 4},
                    'cafeteria_usage': {'base': 0.9, 'volatility': 0.1},
                    'convenience_food_usage': {'base': 1.1, 'volatility': 0.3},
                    'meeting_participation': {'base': 0.6, 'volatility': 0.05}
                },
                
                'P04_under_compensated': {
                    'description': 'ì €í‰ê°€ëœ ì§ì›',
                    'work_focused_ratio': {'base': 0.68, 'volatility': 0.06},
                    'meeting_collaboration_ratio': {'base': 0.16, 'volatility': 0.04},
                    'social_dining_ratio': {'base': 0.09, 'volatility': 0.02},
                    'break_relaxation_ratio': {'base': 0.05, 'volatility': 0.02},
                    'shared_work_ratio': {'base': 0.02, 'volatility': 0.01},
                    
                    'digital_work_engagement': {'base': 0.72, 'volatility': 0.12},
                    'system_login_hours': {'base': 8.5, 'volatility': 0.3},
                    'internal_comm_volume': {'base': 22, 'volatility': 4},
                    'cafeteria_usage': {'base': 1.0, 'volatility': 0.2},
                    'convenience_food_usage': {'base': 1.3, 'volatility': 0.4},
                    'meeting_participation': {'base': 0.7, 'volatility': 0.05}
                },
                
                # ì•ˆì • ë° ëª°ì…êµ°
                'S01_anchor': {
                    'description': 'ì•ˆì •ì ì¸ í•µì‹¬ì¸ì¬',
                    'work_focused_ratio': {'base': 0.65, 'volatility': 0.03},
                    'meeting_collaboration_ratio': {'base': 0.18, 'volatility': 0.02},
                    'social_dining_ratio': {'base': 0.12, 'volatility': 0.01},
                    'break_relaxation_ratio': {'base': 0.04, 'volatility': 0.01},
                    'shared_work_ratio': {'base': 0.01, 'volatility': 0.01},
                    
                    'digital_work_engagement': {'base': 0.82, 'volatility': 0.05},
                    'system_login_hours': {'base': 8.5, 'volatility': 0.3},
                    'internal_comm_volume': {'base': 22, 'volatility': 3},
                    'cafeteria_usage': {'base': 1.0, 'volatility': 0.1},
                    'convenience_food_usage': {'base': 0.8, 'volatility': 0.2},
                    'meeting_participation': {'base': 0.85, 'volatility': 0.05, 'reliable_participant': True}
                },
                
                'S02_rising_star': {
                    'description': 'ë¼ì´ì§• ìŠ¤íƒ€',
                    'work_focused_ratio': {'base': 0.58, 'volatility': 0.06},
                    'meeting_collaboration_ratio': {'base': 0.25, 'trend': 0.0002, 'volatility': 0.04},
                    'social_dining_ratio': {'base': 0.10, 'volatility': 0.02},
                    'break_relaxation_ratio': {'base': 0.03, 'volatility': 0.01},
                    'shared_work_ratio': {'base': 0.04, 'trend': 0.0001, 'volatility': 0.03},
                    
                    'digital_work_engagement': {'base': 0.88, 'trend': 0.0001, 'volatility': 0.08},
                    'system_login_hours': {'base': 9.2, 'volatility': 0.6},
                    'internal_comm_volume': {'base': 35, 'trend': 0.01, 'volatility': 5},
                    'cafeteria_usage': {'base': 1.3, 'volatility': 0.3},
                    'convenience_food_usage': {'base': 1.2, 'volatility': 0.3},
                    'meeting_participation': {'base': 0.90, 'trend': 0.001, 'volatility': 0.08}
                },
                
                'S03_intrinsically_motivated': {
                    'description': 'ë‚´ì¬ì  ë™ê¸°ê°€ ë†’ì€ ì§ì›',
                    'work_focused_ratio': {'base': 0.70, 'volatility': 0.04},
                    'meeting_collaboration_ratio': {'base': 0.15, 'volatility': 0.03},
                    'social_dining_ratio': {'base': 0.08, 'volatility': 0.02},
                    'break_relaxation_ratio': {'base': 0.05, 'volatility': 0.02},
                    'shared_work_ratio': {'base': 0.02, 'volatility': 0.01},
                    
                    'digital_work_engagement': {'base': 0.88, 'volatility': 0.05},
                    'system_login_hours': {'base': 8.8, 'volatility': 0.4},
                    'internal_comm_volume': {'base': 18, 'volatility': 3},
                    'cafeteria_usage': {'base': 0.9, 'volatility': 0.15},
                    'convenience_food_usage': {'base': 0.9, 'volatility': 0.25},
                    'meeting_participation': {'base': 0.70, 'volatility': 0.06}
                },
                
                # ì¤‘ë¦½ ë° ê´€ë§êµ°
                'N01_coaster': {
                    'description': 'í˜„ìƒë§Œ ìœ ì§€í•˜ëŠ” ì§ì›',
                    'work_focused_ratio': {'base': 0.60, 'volatility': 0.02},
                    'meeting_collaboration_ratio': {'base': 0.15, 'volatility': 0.02},
                    'social_dining_ratio': {'base': 0.10, 'volatility': 0.01},
                    'break_relaxation_ratio': {'base': 0.12, 'volatility': 0.02},
                    'shared_work_ratio': {'base': 0.03, 'volatility': 0.01},
                    
                    'digital_work_engagement': {'base': 0.55, 'volatility': 0.08},
                    'system_login_hours': {'base': 8.0, 'volatility': 0.2},
                    'internal_comm_volume': {'base': 15, 'volatility': 2},
                    'cafeteria_usage': {'base': 0.9, 'volatility': 0.1},
                    'convenience_food_usage': {'base': 1.2, 'volatility': 0.3},
                    'meeting_participation': {'base': 0.60, 'volatility': 0.03}
                },
                
                'N02_competent_malcontent': {
                    'description': 'ìœ ëŠ¥í•˜ì§€ë§Œ ë¶ˆë§Œì´ ë§ì€ ì§ì›',
                    'work_focused_ratio': {'base': 0.68, 'volatility': 0.08},
                    'meeting_collaboration_ratio': {'base': 0.10, 'volatility': 0.05},
                    'social_dining_ratio': {'base': 0.06, 'volatility': 0.03},
                    'break_relaxation_ratio': {'base': 0.08, 'volatility': 0.04},
                    'shared_work_ratio': {'base': 0.08, 'volatility': 0.05},
                    
                    'digital_work_engagement': {'base': 0.75, 'volatility': 0.12},
                    'system_login_hours': {'base': 8.2, 'volatility': 0.5},
                    'internal_comm_volume': {'base': 12, 'volatility': 6},
                    'cafeteria_usage': {'base': 0.7, 'volatility': 0.2},
                    'convenience_food_usage': {'base': 1.4, 'volatility': 0.5},
                    'meeting_participation': {'base': 0.55, 'volatility': 0.15}
                },
                
                'N03_new_parent': {
                    'description': 'ì‹ ê·œ ë¶€ëª¨',
                    'work_focused_ratio': {'base': 0.62, 'volatility': 0.06},
                    'meeting_collaboration_ratio': {'base': 0.18, 'volatility': 0.04},
                    'social_dining_ratio': {'base': 0.08, 'volatility': 0.02},
                    'break_relaxation_ratio': {'base': 0.08, 'volatility': 0.03},
                    'shared_work_ratio': {'base': 0.04, 'volatility': 0.02},
                    
                    'digital_work_engagement': {'base': 0.70, 'volatility': 0.15},
                    'system_login_hours': {'base': 7.5, 'volatility': 0.8},
                    'internal_comm_volume': {'base': 20, 'volatility': 4},
                    'cafeteria_usage': {'base': 0.8, 'volatility': 0.2},
                    'convenience_food_usage': {'base': 1.1, 'volatility': 0.3},
                    'meeting_participation': {'base': 0.75, 'volatility': 0.10}
                }
            }
        
        def get_pattern(self, persona_code):
            return self.patterns.get(persona_code, self.patterns['S01_anchor'])
    
    persona_patterns = ComprehensivePersonaPatterns()
    print("persona_patterns ê°ì²´ ì¬ìƒì„± ì™„ë£Œ")

def generate_employee_timeseries_realistic(employee_id, persona_code, business_days):
    """ì…€ 5ì˜ í˜„ì‹¤ì  ë³€ìˆ˜ ìƒì„± í•¨ìˆ˜ì— ë§ì¶˜ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±"""
    
    timeseries_data = []
    
    print(f"ì§ì› {employee_id} ({persona_code}) í˜„ì‹¤ì  ê°œì¸í™” ë°ì´í„° ìƒì„± ì¤‘...")
    
    for day_idx, date in enumerate(business_days):
        daily_data = {
            'employee_id': employee_id,
            'date': date,
            'day_of_week': date.weekday(),
            'day_index': day_idx,
            'persona_code': persona_code
        }
        
        # ì…€ 5ì˜ í˜„ì‹¤ì  ë³€ìˆ˜ ìƒì„± í•¨ìˆ˜ ì‚¬ìš©
        try:
            # ì…€ 5ì—ì„œ ì •ì˜ëœ í•¨ìˆ˜ëª… ì‚¬ìš©
            realistic_variables = generate_realistic_variables_consistent(
                employee_id, persona_code, day_idx, date
            )
            daily_data.update(realistic_variables)
            
        except NameError:
            print(f"generate_realistic_variables_consistent í•¨ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
            realistic_variables = {
                'work_focused_ratio': 0.6,
                'meeting_collaboration_ratio': 0.15,
                'social_dining_ratio': 0.1,
                'break_relaxation_ratio': 0.1,
                'shared_work_ratio': 0.05,
                'system_login_hours': 8.0,
                'internal_comm_volume': 20,
                'cafeteria_usage': 1.0,
                'convenience_food_usage': 1.5
            }
            daily_data.update(realistic_variables)
            
        except Exception as e:
            print(f"Day {day_idx} ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
            realistic_variables = {
                'work_focused_ratio': 0.6,
                'meeting_collaboration_ratio': 0.15,
                'social_dining_ratio': 0.1,
                'break_relaxation_ratio': 0.1,
                'shared_work_ratio': 0.05,
                'digital_work_engagement': 0.7,
                'system_login_hours': 8.0,
                'internal_comm_volume': 20,
                'cafeteria_usage': 1.0,
                'convenience_food_usage': 1.5,
                'meeting_participation': 0.7
            }
            daily_data.update(realistic_variables)
        
        # ì¶”ê°€ ê³„ì‚°ëœ ì§€í‘œë“¤ (í˜„ì‹¤ì ìœ¼ë¡œ ë„ì¶œ ê°€ëŠ¥í•œ ê²ƒë“¤ë§Œ)
        total_hours = daily_data.get('system_login_hours', 8.0)
        space_ratios = ['work_focused_ratio', 'meeting_collaboration_ratio', 
                       'social_dining_ratio', 'break_relaxation_ratio', 'shared_work_ratio']
        
        # ê³µê°„ë³„ ì‹œê°„ ê³„ì‚° (í˜„ì‹¤ì  ì§€í‘œ)
        for space in space_ratios:
            if space in daily_data:
                daily_data[f"{space.replace('_ratio', '_hours')}"] = daily_data[space] * total_hours
        
        # í˜„ì‹¤ì ìœ¼ë¡œ ì¸¡ì • ê°€ëŠ¥í•œ ì¢…í•© ì§€í‘œë“¤
        daily_data['productivity_efficiency'] = (
            daily_data.get('digital_work_engagement', 0.7) * daily_data.get('work_focused_ratio', 0.6)
        )
        
        daily_data['collaboration_intensity'] = (
            daily_data.get('meeting_collaboration_ratio', 0.15) * 
            daily_data.get('meeting_participation', 0.7)
        )
        
        # ì†Œí†µ í™œì„±ë„ (ì‹¤ì œ ì¸¡ì • ê°€ëŠ¥)
        daily_data['communication_activity'] = daily_data.get('internal_comm_volume', 20) / 20.0
        
        # ì‹ìƒí™œ íŒ¨í„´ ì§€í‘œ (í˜„ì‹¤ì ìœ¼ë¡œ ì¸¡ì • ê°€ëŠ¥)
        daily_data['healthy_eating_score'] = max(0, min(1, 
            daily_data.get('cafeteria_usage', 1.0) / (
                daily_data.get('cafeteria_usage', 1.0) + daily_data.get('convenience_food_usage', 1.5)
            )
        ))
        
        timeseries_data.append(daily_data)
    
    return pd.DataFrame(timeseries_data)

# ë°±ì—… í•¨ìˆ˜ëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŒ - generate_realistic_variables_consistent ì‚¬ìš©

# í•„ìš”í•œ IndividualCharacteristics í´ë˜ìŠ¤ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ë²„ì „
try:
    test_individual = IndividualCharacteristics(1001, 'P01_burnout')
    print("ê¸°ì¡´ IndividualCharacteristics í´ë˜ìŠ¤ ì‚¬ìš©")
except NameError:
    print("IndividualCharacteristics í´ë˜ìŠ¤ê°€ ì—†ì–´ì„œ ê°„ë‹¨í•œ ë²„ì „ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    
    class IndividualCharacteristics:
        def __init__(self, employee_id, persona_code):
            self.employee_id = employee_id
            self.persona_code = persona_code
            
            # ê°œì¸ë³„ íŠ¹ì„± (ì‹œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ì„± ìœ ì§€)
            np.random.seed(employee_id)
            
            self.individual_traits = {
                'work_intensity_bias': np.random.normal(0, 0.1),
                'social_tendency_bias': np.random.normal(0, 0.15),
                'stress_sensitivity_bias': np.random.normal(0, 0.1),
                'routine_preference_bias': np.random.normal(0, 0.08),
                'communication_sensitivity': np.random.uniform(0.8, 1.2),
                'social_eating_sensitivity': np.random.uniform(0.7, 1.3),
                'stress_eating_tendency': np.random.uniform(0.8, 1.4),
                'login_hours_sensitivity': np.random.uniform(0.9, 1.1),
                'volatility_multiplier': np.random.uniform(0.7, 1.3),
                'change_rate_multiplier': np.random.uniform(0.8, 1.2)
            }
            
            # ì‹œë“œ ë³µì›
            np.random.seed()

# í…ŒìŠ¤íŠ¸: í˜„ì‹¤ì  ë³€ìˆ˜ë“¤ë§Œìœ¼ë¡œ ê°œì¸ì°¨ í™•ì¸
print("\n=== í˜„ì‹¤ì  ë³€ìˆ˜ ê°œì¸ì°¨ í…ŒìŠ¤íŠ¸ ===")
test_employees = [1001, 1002, 1003]  # ëª¨ë‘ P01_burnout

for emp_id in test_employees:
    try:
        sample_data = generate_employee_timeseries_realistic(
            emp_id, 'P01_burnout', calendar.business_days[:7]  # 7ì¼ë§Œ í…ŒìŠ¤íŠ¸
        )
        
        avg_engagement = sample_data['digital_work_engagement'].mean()
        avg_hours = sample_data['system_login_hours'].mean() 
        avg_comm = sample_data.get('internal_comm_volume', pd.Series([0])).mean()
        avg_meeting = sample_data.get('meeting_participation', pd.Series([0])).mean()
        avg_cafe = sample_data.get('cafeteria_usage', pd.Series([0])).mean()
        avg_productivity = sample_data.get('productivity_efficiency', pd.Series([0])).mean()
        
        print(f"ì§ì› {emp_id}:")
        print(f"  ëª°ì…ë„={avg_engagement:.3f}, ê·¼ë¬´ì‹œê°„={avg_hours:.1f}h, ì†Œí†µëŸ‰={avg_comm:.1f}")
        print(f"  ë¯¸íŒ…ì°¸ì—¬={avg_meeting:.3f}, ì¹´í˜í…Œë¦¬ì•„={avg_cafe:.1f}, ìƒì‚°ì„±={avg_productivity:.3f}")
        print()
        
    except Exception as e:
        print(f"ì§ì› {emp_id} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

print("Cell 6 - ì…€ 5ì— ë§ì¶˜ í˜„ì‹¤ì  ì‹œê³„ì—´ ìƒì„± í•¨ìˆ˜ ì™„ë£Œ")

# Cell 7: 10ê°œ í˜ë¥´ì†Œë‚˜ ì „ì²´ ë°ì´í„°ì…‹ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©)

# 10ê°œ í˜ë¥´ì†Œë‚˜ ë¶„í¬ ì„¤ì •
np.random.seed(42)
sample_size = 1470  

# í˜„ì‹¤ì ì¸ í˜ë¥´ì†Œë‚˜ ë¶„í¬ ì„¤ì •
persona_distribution = {
    # ê³ ìœ„í—˜êµ° (30%)
    'P01_burnout': 0.08,           # 8% - ë²ˆì•„ì›ƒ ì§ì›
    'P02_onboarding_failure': 0.05, # 5% - ì˜¨ë³´ë”© ì‹¤íŒ¨
    'P03_career_stagnation': 0.12,  # 12% - ì„±ì¥ ì •ì²´
    'P04_under_compensated': 0.05,  # 5% - ì €í‰ê°€ëœ ì§ì›
    
    # ì•ˆì • ë° ëª°ì…êµ° (40%)
    'S01_anchor': 0.20,            # 20% - í•µì‹¬ ì¸ì¬ (ê°€ì¥ ë§ìŒ)
    'S02_rising_star': 0.10,       # 10% - ë¼ì´ì§• ìŠ¤íƒ€
    'S03_intrinsically_motivated': 0.10, # 10% - ë‚´ì¬ ë™ê¸°
    
    # ì¤‘ë¦½ ë° ê´€ë§êµ° (30%)
    'N01_coaster': 0.15,           # 15% - í˜„ìƒ ìœ ì§€
    'N02_competent_malcontent': 0.08, # 8% - ìœ ëŠ¥í•œ ë¶ˆë§Œì
    'N03_new_parent': 0.07         # 7% - ì‹ ê·œ ë¶€ëª¨
}

# ë¶„í¬ ê²€ì¦
total_prob = sum(persona_distribution.values())
print(f"í˜ë¥´ì†Œë‚˜ ë¶„í¬ í•©ê³„: {total_prob:.3f}")
assert abs(total_prob - 1.0) < 0.001, "í˜ë¥´ì†Œë‚˜ ë¶„í¬ í•©ê³„ê°€ 1.0ì´ ì•„ë‹™ë‹ˆë‹¤!"

# ìƒ˜í”Œ ì§ì› ë°ì´í„° ìƒì„± (10ê°œ í˜ë¥´ì†Œë‚˜ í¬í•¨)
sample_employees = pd.DataFrame({
    'EmployeeNumber': range(1001, 1001 + sample_size),
    'softmax_Persona_Code': np.random.choice(
        list(persona_distribution.keys()), 
        size=sample_size, 
        p=list(persona_distribution.values())
    )
})

print(f"ì „ì²´ ì§ì› ìˆ˜: {len(sample_employees)}")
print("\n=== 10ê°œ í˜ë¥´ì†Œë‚˜ ë¶„í¬ í˜„í™© ===")
persona_counts = sample_employees['softmax_Persona_Code'].value_counts()
for persona, count in persona_counts.items():
    percentage = (count / len(sample_employees)) * 100
    risk_tier = "ê³ ìœ„í—˜" if persona.startswith('P') else "ì•ˆì •/ëª°ì…" if persona.startswith('S') else "ì¤‘ë¦½/ê´€ë§"
    print(f"{persona:25} {count:4d}ëª… ({percentage:5.1f}%) - {risk_tier}")

def generate_complete_chronos_dataset_fixed(employees_df, business_days, max_employees=None):
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ í˜¸í™˜ë˜ëŠ” ì™„ì „í•œ Chronos ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„±"""
    
    all_timeseries = []
    
    if max_employees:
        employees_df = employees_df.head(max_employees)
    
    total_employees = len(employees_df)
    print(f"\n=== Chronos ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì‹œì‘ ===")
    print(f"ëŒ€ìƒ ì§ì› ìˆ˜: {total_employees}ëª…")
    print(f"ê¸°ê°„: {len(business_days)}ì¼ ({business_days[0].strftime('%Y-%m-%d')} ~ {business_days[-1].strftime('%Y-%m-%d')})")
    
    import time
    start_time = time.time()
    
    for idx, (_, employee) in enumerate(employees_df.iterrows()):
        if idx % 10 == 0 and idx > 0:
            elapsed = time.time() - start_time
            estimated_total = (elapsed / idx) * total_employees
            print(f"ì§„í–‰ë¥ : {idx:4d}/{total_employees} ({idx/total_employees*100:5.1f}%) - ì˜ˆìƒ ì†Œìš”ì‹œê°„: {estimated_total/60:.1f}ë¶„")
        elif idx == 0:
            print(f"ì§„í–‰ë¥ : {idx:4d}/{total_employees} ({idx/total_employees*100:5.1f}%) - ì˜ˆìƒ ì†Œìš”ì‹œê°„: ê³„ì‚°ì¤‘...")
        
        emp_id = employee['EmployeeNumber']
        persona = employee['softmax_Persona_Code']
        
        # ê¸°ì¡´ì— ì •ì˜ëœ í•¨ìˆ˜ ì‚¬ìš©
        try:
            employee_timeseries = generate_employee_timeseries_consistent(
                emp_id, persona, business_days
            )
            all_timeseries.append(employee_timeseries)
            
        except Exception as e:
            print(f"ì§ì› {emp_id} ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ë°ì´í„° ìƒì„±
            try:
                basic_data = create_basic_employee_data(emp_id, persona, business_days)
                all_timeseries.append(basic_data)
            except:
                print(f"ì§ì› {emp_id} ê¸°ë³¸ ë°ì´í„° ìƒì„±ë„ ì‹¤íŒ¨")
                continue
    
    if not all_timeseries:
        print("ERROR: ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return pd.DataFrame()
    
    # ì „ì²´ ë°ì´í„° í†µí•©
    final_dataset = pd.concat(all_timeseries, ignore_index=True)
    
    total_time = time.time() - start_time
    print(f"\n=== Chronos ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ ===")
    print(f"ìµœì¢… Shape: {final_dataset.shape}")
    print(f"ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„")
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {final_dataset.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    
    # ìƒì„±ëœ ë³€ìˆ˜ í™•ì¸ (í˜„ì‹¤ì  ë³€ìˆ˜ë§Œ)
    realistic_columns = [
        'work_focused_ratio', 'meeting_collaboration_ratio', 'social_dining_ratio',
        'break_relaxation_ratio', 'shared_work_ratio', 'system_login_hours', 
        'internal_comm_volume', 'cafeteria_usage', 'convenience_food_usage'
    ]
    
    print(f"\n=== ìƒì„±ëœ í˜„ì‹¤ì  í–‰ë™ ì§€í‘œ ===")
    available_columns = [col for col in realistic_columns if col in final_dataset.columns]
    for col in available_columns:
        stats = final_dataset[col].describe()
        print(f"{col:25} - ë²”ìœ„: [{stats['min']:.3f}, {stats['max']:.3f}], í‰ê· : {stats['mean']:.3f}")
    
    print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ í˜„ì‹¤ì  ë³€ìˆ˜: {len(available_columns)}/{len(realistic_columns)}ê°œ")
    
    return final_dataset

def create_basic_employee_data(employee_id, persona_code, business_days):
    """ê¸°ë³¸ ë°±ì—… ë°ì´í„° ìƒì„± í•¨ìˆ˜"""
    
    basic_data = []
    
    for day_idx, date in enumerate(business_days):
        # í˜ë¥´ì†Œë‚˜ë³„ ê¸°ë³¸ íŒ¨í„´
        if persona_code.startswith('P01'):  # ë²ˆì•„ì›ƒ
            base_engagement = max(0.2, 0.7 - (day_idx / 500) * 0.4)  # ì ì§„ì  ê°ì†Œ
            base_job_search = min(0.8, (day_idx / 500) * 0.8)  # ì ì§„ì  ì¦ê°€
        elif persona_code.startswith('S'):  # ì•ˆì •/ëª°ì…
            base_engagement = 0.85 + np.random.normal(0, 0.05)
            base_job_search = 0.02 + np.random.normal(0, 0.01)
        else:  # ì¤‘ë¦½/ê´€ë§
            base_engagement = 0.65 + np.random.normal(0, 0.1)
            base_job_search = 0.1 + np.random.normal(0, 0.05)
        
        daily_data = {
            'employee_id': employee_id,
            'date': date,
            'day_of_week': date.weekday(),
            'day_index': day_idx,
            'persona_code': persona_code,
            
            # ê¸°ë³¸ ë³€ìˆ˜ë“¤
            'work_focused_ratio': max(0.01, min(0.99, 0.6 + np.random.normal(0, 0.1))),
            'meeting_collaboration_ratio': max(0.01, min(0.99, 0.15 + np.random.normal(0, 0.05))),
            'social_dining_ratio': max(0.01, min(0.99, 0.1 + np.random.normal(0, 0.03))),
            'break_relaxation_ratio': max(0.01, min(0.99, 0.1 + np.random.normal(0, 0.03))),
            'shared_work_ratio': max(0.01, min(0.99, 0.05 + np.random.normal(0, 0.02))),
            
            'system_login_hours': max(4.0, min(16.0, 8.0 + np.random.normal(0, 1))),
            
            # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤ë§Œ
            'internal_comm_volume': max(0, int(20 + np.random.normal(0, 5))),
            'cafeteria_usage': max(0, min(3, 1.0 + np.random.normal(0, 0.3))),
            'convenience_food_usage': max(0, min(8, 1.5 + np.random.normal(0, 0.5)))
        }
        
        # ë¹„ìœ¨ ì •ê·œí™”
        ratio_cols = ['work_focused_ratio', 'meeting_collaboration_ratio', 'social_dining_ratio', 
                     'break_relaxation_ratio', 'shared_work_ratio']
        ratio_sum = sum(daily_data[col] for col in ratio_cols)
        for col in ratio_cols:
            daily_data[col] = daily_data[col] / ratio_sum
        
        # ì‹œê°„ ê³„ì‚°
        total_hours = daily_data['system_login_hours']
        for col in ratio_cols:
            daily_data[col.replace('_ratio', '_hours')] = daily_data[col] * total_hours
        
        basic_data.append(daily_data)
    
    return pd.DataFrame(basic_data)

# ì „ì²´ ë°ì´í„°ì…‹ ìƒì„± (í…ŒìŠ¤íŠ¸ìš© 10ëª…)
print("í…ŒìŠ¤íŠ¸ìš© ì†Œê·œëª¨ ë°ì´í„°ì…‹ ìƒì„±...")
test_dataset = generate_complete_chronos_dataset_fixed(
    sample_employees, calendar.business_days, max_employees=10
)

if len(test_dataset) > 0:
    print("\n=== ìƒì„±ëœ ë°ì´í„°ì…‹ ìƒ˜í”Œ ===")
    print(f"ë°ì´í„°ì…‹ í¬ê¸°: {test_dataset.shape}")
    print(f"í˜ë¥´ì†Œë‚˜ ë¶„í¬:")
    print(test_dataset['persona_code'].value_counts())
    
    print(f"\nì£¼ìš” ë³€ìˆ˜ ìš”ì•½:")
    key_vars = ['work_focused_ratio', 'system_login_hours', 'internal_comm_volume', 'cafeteria_usage']
    for var in key_vars:
        if var in test_dataset.columns:
            print(f"{var:25}: í‰ê·  {test_dataset[var].mean():.3f}, ë²”ìœ„ [{test_dataset[var].min():.3f}, {test_dataset[var].max():.3f}]")
else:
    print("ERROR: ë°ì´í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
plt.rcParams['font.family'] = 'Malgun Gothic'

# Cell 8: í™•ì¥ëœ ë°ì´í„° ê²€ì¦
def validate_chronos_dataset(df):
    """10ê°œ í˜ë¥´ì†Œë‚˜ Chronos ë°ì´í„°ì…‹ ê²€ì¦"""
    print("=== Chronos ë°ì´í„°ì…‹ ê²€ì¦ ===")
    
    # 1. ê¸°ë³¸ ì •ë³´
    print(f"ì´ ë ˆì½”ë“œ ìˆ˜: {len(df):,}")
    print(f"ì§ì› ìˆ˜: {df['employee_id'].nunique()}")
    print(f"ì¼ ìˆ˜: {df['date'].nunique()}")
    
    # 2. 10ê°œ í˜ë¥´ì†Œë‚˜ ë¶„í¬ í™•ì¸
    print(f"\n=== í˜ë¥´ì†Œë‚˜ ë¶„í¬ ê²€ì¦ ===")
    persona_dist = df['persona_code'].value_counts()
    for persona, count in persona_dist.items():
        records_per_persona = count
        employees_per_persona = df[df['persona_code'] == persona]['employee_id'].nunique()
        avg_days = records_per_persona / employees_per_persona if employees_per_persona > 0 else 0
        risk_tier = "ê³ ìœ„í—˜" if persona.startswith('P') else "ì•ˆì •/ëª°ì…" if persona.startswith('S') else "ì¤‘ë¦½/ê´€ë§"
        print(f"{persona:25} {employees_per_persona:3d}ëª… ({records_per_persona:5d} ë ˆì½”ë“œ, í‰ê·  {avg_days:.1f}ì¼) - {risk_tier}")
    
    # 3. Chronos í•µì‹¬ ì§€í‘œ ê²€ì¦
    realistic_indicators = [
        'work_focused_ratio', 'system_login_hours', 'internal_comm_volume', 
        'cafeteria_usage', 'convenience_food_usage'
    ]
    
    print(f"\n=== í˜„ì‹¤ì  í–‰ë™ ì§€í‘œ í†µê³„ ===")
    for indicator in realistic_indicators:
        if indicator in df.columns:
            stats = df[indicator].describe()
            print(f"{indicator:25} | í‰ê· : {stats['mean']:6.3f} | í‘œì¤€í¸ì°¨: {stats['std']:6.3f} | ë²”ìœ„: [{stats['min']:6.3f}, {stats['max']:6.3f}]")
    
    # 4. ê³µê°„ ë¹„ìœ¨ í•©ê³„ ê²€ì¦
    space_columns = [col for col in df.columns if col.endswith('_ratio') and not col.startswith('after_hours')]
    if space_columns:
        df['ratio_sum'] = df[space_columns].sum(axis=1)
        ratio_check = df['ratio_sum']
        print(f"\n=== ê³µê°„ ë¹„ìœ¨ í•©ê³„ ê²€ì¦ ===")
        print(f"ë¹„ìœ¨ í•©ê³„ í‰ê· : {ratio_check.mean():.6f}")
        print(f"ë¹„ìœ¨ í•©ê³„ í‘œì¤€í¸ì°¨: {ratio_check.std():.6f}")
        invalid_ratios = ((ratio_check < 0.99) | (ratio_check > 1.01)).sum()
        print(f"ìœ íš¨ ë²”ìœ„(0.99-1.01) ë°– ì¼€ì´ìŠ¤: {invalid_ratios} ({invalid_ratios/len(df)*100:.2f}%)")
    
    # 5. ëˆ„ë½ê°’ í™•ì¸
    print(f"\n=== ëˆ„ë½ê°’ ê²€ì¦ ===")
    missing_data = df.isnull().sum()
    if missing_data.sum() == 0:
        print("ëˆ„ë½ê°’ ì—†ìŒ âœ“")
    else:
        print("ëˆ„ë½ê°’ ë°œê²¬:")
        for col, missing in missing_data[missing_data > 0].items():
            print(f"  {col}: {missing} ({missing/len(df)*100:.2f}%)")
    
    # 6. í˜ë¥´ì†Œë‚˜ë³„ í–‰ë™ íŒ¨í„´ ì°¨ì´ ê²€ì¦
    print(f"\n=== í˜ë¥´ì†Œë‚˜ë³„ ì£¼ìš” ì§€í‘œ í‰ê·  ë¹„êµ ===")
    key_indicators = ['work_focused_ratio', 'system_login_hours', 'internal_comm_volume']
    
    for indicator in key_indicators:
        if indicator in df.columns:
            print(f"\n{indicator}:")
            persona_means = df.groupby('persona_code')[indicator].mean().sort_values(ascending=False)
            for persona, mean_val in persona_means.items():
                risk_tier = "ê³ ìœ„í—˜" if persona.startswith('P') else "ì•ˆì •/ëª°ì…" if persona.startswith('S') else "ì¤‘ë¦½/ê´€ë§"
                print(f"  {persona:20} {mean_val:8.3f} ({risk_tier})")
    
    return df

# Cell 9: í™•ì¥ëœ ì‹œê°í™”
def visualize_chronos_patterns(df, personas_to_plot=None):
    """10ê°œ í˜ë¥´ì†Œë‚˜ Chronos íŒ¨í„´ ì‹œê°í™”"""
    
    if personas_to_plot is None:
        # 10ê°œ í˜ë¥´ì†Œë‚˜ ëª¨ë‘ í‘œì‹œ
        personas_to_plot = [
            'P01_burnout', 'P02_onboarding_failure', 'P03_career_stagnation', 'P04_under_compensated',
            'S01_anchor', 'S02_rising_star', 'S03_intrinsically_motivated', 
            'N01_coaster', 'N02_competent_malcontent', 'N03_new_parent'
        ]
    
    # 1. ì‹œê³„ì—´ íŒ¨í„´ ë¹„êµ
    realistic_indicators = ['work_focused_ratio', 'system_login_hours', 'internal_comm_volume', 'cafeteria_usage']
    
    fig, axes = plt.subplots(2, 2, figsize=(24, 16))
    axes = axes.ravel()
    
    # 10ê°œ í˜ë¥´ì†Œë‚˜ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì‚¬ìš©
    colors = plt.cm.tab10(np.linspace(0, 1, len(personas_to_plot)))
    
    for i, indicator in enumerate(realistic_indicators):
        if indicator in df.columns:
            for j, persona in enumerate(personas_to_plot):
                persona_data = df[df['persona_code'] == persona]
                if len(persona_data) > 0:
                    # 7ì¼ ì´ë™í‰ê· ìœ¼ë¡œ ìŠ¤ë¬´ë”©
                    daily_avg = persona_data.groupby('day_index')[indicator].mean()
                    smoothed = daily_avg.rolling(window=7, center=True).mean()
                    
                    risk_label = ""
                    if persona.startswith('P'):
                        risk_label = " (ê³ ìœ„í—˜)"
                    elif persona.startswith('S'):
                        risk_label = " (ì•ˆì •/ëª°ì…)"
                    else:
                        risk_label = " (ì¤‘ë¦½/ê´€ë§)"
                    
                    axes[i].plot(smoothed.index, smoothed.values, 
                               label=persona.replace('_', ' ') + risk_label, 
                               color=colors[j], linewidth=2, alpha=0.8)
        
        axes[i].set_title(f'{indicator.replace("_", " ").title()} - ì‹œê°„ë³„ ë³€í™” íŒ¨í„´', fontsize=14)
        axes[i].set_xlabel('Day Index')
        axes[i].set_ylabel(indicator.replace('_', ' ').title())
        # 10ê°œ í˜ë¥´ì†Œë‚˜ë¥¼ ìœ„í•œ ë²”ë¡€ ì¡°ì •
        axes[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8, ncol=1)
        axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # 2. í˜ë¥´ì†Œë‚˜ë³„ í–‰ë™ íŒ¨í„´ íˆíŠ¸ë§µ
    behavior_indicators = ['work_focused_ratio', 'system_login_hours', 'internal_comm_volume']
    
    fig, ax = plt.subplots(figsize=(10, 12))  # 10ê°œ í˜ë¥´ì†Œë‚˜ì— ë§ê²Œ ì„¸ë¡œë¡œ ê¸¸ê²Œ
    
    # í˜ë¥´ì†Œë‚˜ë³„ í–‰ë™ íŒ¨í„´ í‰ê·  ê³„ì‚°
    behavior_matrix = []
    persona_labels = []
    
    all_personas = df['persona_code'].unique()
    for persona in sorted(all_personas):
        persona_data = df[df['persona_code'] == persona]
        behavior_values = []
        
        for indicator in behavior_indicators:
            if indicator in df.columns:
                behavior_values.append(persona_data[indicator].mean())
            else:
                behavior_values.append(0)
        
        behavior_matrix.append(behavior_values)
        # í˜ë¥´ì†Œë‚˜ ë¼ë²¨ì„ ë” ì½ê¸° ì‰½ê²Œ ë³€ê²½
        risk_tier = "ê³ ìœ„í—˜" if persona.startswith('P') else "ì•ˆì •/ëª°ì…" if persona.startswith('S') else "ì¤‘ë¦½/ê´€ë§"
        persona_labels.append(f"{persona.replace('_', ' ')}\n({risk_tier})")
    
    # íˆíŠ¸ë§µ ìƒì„±
    im = ax.imshow(behavior_matrix, cmap='Blues', aspect='auto')
    
    # ì¶• ë ˆì´ë¸” ì„¤ì •
    ax.set_xticks(range(len(behavior_indicators)))
    ax.set_xticklabels([ind.replace('_', '\n') for ind in behavior_indicators], fontsize=10)
    ax.set_yticks(range(len(persona_labels)))
    ax.set_yticklabels(persona_labels, fontsize=9)
    
    # ê°’ í‘œì‹œ
    for i in range(len(persona_labels)):
        for j in range(len(behavior_indicators)):
            text = ax.text(j, i, f'{behavior_matrix[i][j]:.2f}',
                         ha="center", va="center", fontsize=8,
                         color="white" if behavior_matrix[i][j] > 0.5 else "black")
    
    ax.set_title('í˜ë¥´ì†Œë‚˜ë³„ í–‰ë™ íŒ¨í„´ íˆíŠ¸ë§µ', fontsize=14, pad=20)
    
    # ì»¬ëŸ¬ë°”
    cbar = plt.colorbar(im)
    cbar.set_label('í–‰ë™ ê°•ë„', rotation=270, labelpad=20)
    
    plt.tight_layout()
    plt.show()
    
    # 3. í˜ë¥´ì†Œë‚˜ë³„ ë¶„í¬ í†µê³„
    print("\n=== í˜ë¥´ì†Œë‚˜ë³„ í•µì‹¬ ì§€í‘œ í†µê³„ ìš”ì•½ ===")
    summary_stats = df.groupby('persona_code')[realistic_indicators].agg(['mean', 'std']).round(3)
    
    for persona in sorted(df['persona_code'].unique()):
        risk_tier = "ê³ ìœ„í—˜" if persona.startswith('P') else "ì•ˆì •/ëª°ì…" if persona.startswith('S') else "ì¤‘ë¦½/ê´€ë§"
        print(f"\n{persona} ({risk_tier}):")
        for indicator in ['work_focused_ratio', 'system_login_hours', 'internal_comm_volume']:
            if indicator in summary_stats.columns.levels[0]:
                mean_val = summary_stats.loc[persona, (indicator, 'mean')]
                std_val = summary_stats.loc[persona, (indicator, 'std')]
                print(f"  {indicator:20}: {mean_val:6.3f} Â± {std_val:6.3f}")

# ê²€ì¦ ë° ì‹œê°í™” ì‹¤í–‰
validated_dataset = validate_chronos_dataset(test_dataset)
visualize_chronos_patterns(test_dataset)

print("=== Chronos ë°ì´í„° ê²€ì¦ ë° ì‹œê°í™” ì™„ë£Œ ===")

# Cell: ìˆ˜ì •ëœ ìµœì¢… Chronos ì‹œê³„ì—´ CSV íŒŒì¼ ìƒì„±

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import os

# í•„ìš”í•œ ì˜ì¡´ì„±ë“¤ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ ì„¤ì •
try:
    # business_daysê°€ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    test_days = calendar.business_days[:5]
    print("ê¸°ì¡´ calendar.business_days ì‚¬ìš©")
except NameError:
    print("business_daysë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
    # 2023ë…„ 1ì›”ë¶€í„° 2024ë…„ 12ì›”ê¹Œì§€ì˜ ì˜ì—…ì¼ ìƒì„±
    start_date = '2023-01-02'
    end_date = '2024-12-30'
    business_days = pd.bdate_range(start=start_date, end=end_date).tolist()
    print(f"ì˜ì—…ì¼ {len(business_days)}ì¼ ìƒì„± ì™„ë£Œ")

# ì§ì› ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
def create_sample_employees(num_employees=1470):
    """ìƒ˜í”Œ ì§ì› ë°ì´í„° ìƒì„±"""
    
    personas = ['P01_burnout', 'P02_onboarding_failure', 'P03_career_stagnation', 
               'P04_under_compensated', 'S01_anchor', 'S02_rising_star', 
               'S03_intrinsically_motivated', 'N01_coaster', 'N02_competent_malcontent', 
               'N03_new_parent']
    
    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´
    
    employees_data = []
    for i in range(num_employees):
        employee_id = 1001 + i
        persona = np.random.choice(personas)
        
        employees_data.append({
            'EmployeeNumber': employee_id,
            'softmax_Persona_Code': persona
        })
    
    return pd.DataFrame(employees_data)

def generate_attrition_aware_chronos_dataset(ibm_hr_path="data/IBM_HR_personas_assigned.csv", num_employees=50, save_path=None):
    """í‡´ì‚¬ ì •ë³´ë¥¼ í™œìš©í•œ Chronos ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„±"""
    
    # IBM HR ë°ì´í„° ë¡œë“œ
    try:
        ibm_df = pd.read_csv(ibm_hr_path)
        print(f"IBM HR ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(ibm_df)}ëª…")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['EmployeeNumber', 'Attrition', 'softmax_Persona_Code']
        missing_cols = [col for col in required_cols if col not in ibm_df.columns]
        if missing_cols:
            print(f"ê²½ê³ : ëˆ„ë½ëœ ì»¬ëŸ¼ë“¤: {missing_cols}")
            return pd.DataFrame()
            
        # ìƒ˜í”Œ ì„ íƒ
        sample_df = ibm_df.head(num_employees)[['EmployeeNumber', 'Attrition', 'softmax_Persona_Code']].copy()
        
        # í‡´ì‚¬ì/ì¬ì§ì ë¶„í¬ í™•ì¸
        attrition_dist = sample_df['Attrition'].value_counts()
        print(f"í‡´ì‚¬ì ë¶„í¬: {dict(attrition_dist)}")
        
    except Exception as e:
        print(f"IBM HR ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()
    
    # business_days ì¤€ë¹„
    try:
        bdays = calendar.business_days
    except NameError:
        bdays = business_days
    
    all_timeseries = []
    
    total_employees = len(sample_df)
    print(f"\n=== í‡´ì‚¬ ì¸ì‹ Chronos ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì‹œì‘ ===")
    print(f"ëŒ€ìƒ ì§ì› ìˆ˜: {total_employees}ëª…")
    print(f"ê¸°ê°„: {len(bdays)}ì¼")
    
    start_time = time.time()
    
    for idx, (_, employee) in enumerate(sample_df.iterrows()):
        if idx % 10 == 0 and idx > 0:
            elapsed = time.time() - start_time
            estimated_total = (elapsed / idx) * total_employees
            print(f"ì§„í–‰ë¥ : {idx:4d}/{total_employees} ({idx/total_employees*100:5.1f}%) - ì˜ˆìƒ ì†Œìš”ì‹œê°„: {estimated_total/60:.1f}ë¶„")
        
        emp_id = employee['EmployeeNumber']
        persona = employee['softmax_Persona_Code']
        attrition = employee['Attrition']
        
        try:
            employee_timeseries = generate_employee_timeseries_with_attrition(
                emp_id, persona, attrition, bdays
            )
            all_timeseries.append(employee_timeseries)
            
        except Exception as e:
            print(f"ì§ì› {emp_id} ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            continue
    
    if not all_timeseries:
        print("ERROR: ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return pd.DataFrame()
    
    # ì „ì²´ ë°ì´í„° í†µí•©
    final_dataset = pd.concat(all_timeseries, ignore_index=True)
    
    # CSV ì €ì¥
    if save_path:
        final_dataset.to_csv(save_path, index=False)
        print(f"ë°ì´í„°ì…‹ì´ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    total_time = time.time() - start_time
    print(f"\n=== í‡´ì‚¬ ì¸ì‹ Chronos ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ ===")
    print(f"ìµœì¢… Shape: {final_dataset.shape}")
    print(f"ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„")
    
    # í‡´ì‚¬ì/ì¬ì§ìë³„ í†µê³„
    print(f"\n=== í‡´ì‚¬ì/ì¬ì§ìë³„ ì£¼ìš” ì§€í‘œ ë¹„êµ ===")
    for attrition_status in ['Yes', 'No']:
        subset = final_dataset[final_dataset['attrition_status'] == attrition_status]
        if len(subset) > 0:
            status_name = "í‡´ì‚¬ì" if attrition_status == 'Yes' else "ì¬ì§ì"
            print(f"\n{status_name} ({len(subset):,}ê°œ ë ˆì½”ë“œ):")
            
            key_metrics = ['work_focused_ratio', 'system_login_hours', 'internal_comm_volume', 'convenience_food_usage']
            for metric in key_metrics:
                if metric in subset.columns:
                    avg_val = subset[metric].mean()
                    print(f"  {metric:25}: {avg_val:8.3f}")
    
    return final_dataset

def generate_employee_timeseries_with_attrition(employee_id, persona_code, attrition_status, business_days):
    """í‡´ì‚¬ ì •ë³´ë¥¼ í¬í•¨í•œ ì§ì›ë³„ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±"""
    
    timeseries_data = []
    
    print(f"ì§ì› {employee_id} ({persona_code}, í‡´ì‚¬:{attrition_status}) ë°ì´í„° ìƒì„± ì¤‘...")
    
    for day_idx, date in enumerate(business_days):
        daily_data = {
            'employee_id': employee_id,
            'date': date,
            'day_of_week': date.weekday(),
            'day_index': day_idx,
            'persona_code': persona_code,
            'attrition_status': attrition_status
        }
        
        # í‡´ì‚¬ ì •ë³´ë¥¼ í¬í•¨í•œ í˜„ì‹¤ì  ë³€ìˆ˜ ìƒì„±
        try:
            realistic_variables = generate_realistic_variables_consistent(
                employee_id, persona_code, day_idx, date, attrition_status
            )
            daily_data.update(realistic_variables)
            
        except Exception as e:
            print(f"Day {day_idx} ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
            daily_data.update({
                'work_focused_ratio': 0.6,
                'meeting_collaboration_ratio': 0.15,
                'social_dining_ratio': 0.1,
                'break_relaxation_ratio': 0.1,
                'shared_work_ratio': 0.05,
                'system_login_hours': 8.0,
                'work_focused_hours': 4.8,
                'meeting_collaboration_hours': 1.2,
                'social_dining_hours': 0.8,
                'break_relaxation_hours': 0.8,
                'shared_work_hours': 0.4,
                'internal_comm_volume': 20,
                'cafeteria_usage': 1.0,
                'convenience_food_usage': 1.5
            })
        
        timeseries_data.append(daily_data)
    
    return pd.DataFrame(timeseries_data)

def generate_consistent_chronos_dataset(num_employees=50, save_path=None, use_existing_employees=None):
    """ì¼ê´€ì„± ìˆëŠ” í˜„ì‹¤ì  ë³€ìˆ˜ë§Œ í¬í•¨í•œ Chronos ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„±"""
    
    # ì§ì› ë°ì´í„° ì¤€ë¹„
    if use_existing_employees is not None:
        employees_df = use_existing_employees.head(num_employees)
        print(f"ê¸°ì¡´ ì§ì› ë°ì´í„° ì‚¬ìš©: {len(employees_df)}ëª…")
    else:
        employees_df = create_sample_employees(num_employees)
        print(f"ìƒ˜í”Œ ì§ì› ë°ì´í„° ìƒì„±: {len(employees_df)}ëª…")
    
    # business_days ì¤€ë¹„
    try:
        bdays = calendar.business_days
    except NameError:
        bdays = business_days
    
    all_timeseries = []
    
    total_employees = len(employees_df)
    print(f"\n=== ì¼ê´€ì„± ìˆëŠ” Chronos ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì‹œì‘ ===")
    print(f"ëŒ€ìƒ ì§ì› ìˆ˜: {total_employees}ëª…")
    print(f"ê¸°ê°„: {len(bdays)}ì¼")
    
    start_time = time.time()
    
    for idx, (_, employee) in enumerate(employees_df.iterrows()):
        if idx % 10 == 0 and idx > 0:
            elapsed = time.time() - start_time
            estimated_total = (elapsed / idx) * total_employees
            print(f"ì§„í–‰ë¥ : {idx:4d}/{total_employees} ({idx/total_employees*100:5.1f}%) - ì˜ˆìƒ ì†Œìš”ì‹œê°„: {estimated_total/60:.1f}ë¶„")
        
        emp_id = employee['EmployeeNumber']
        persona = employee['softmax_Persona_Code']
        
        try:
            employee_timeseries = generate_employee_timeseries_consistent(
                    emp_id, persona, bdays
                )
            all_timeseries.append(employee_timeseries)
            
        except Exception as e:
            print(f"ì§ì› {emp_id} ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            continue
    
    if not all_timeseries:
        print("ERROR: ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return pd.DataFrame()
    
    # ì „ì²´ ë°ì´í„° í†µí•©
    final_dataset = pd.concat(all_timeseries, ignore_index=True)
    
    # ì¼ê´€ì„± ìˆëŠ” í˜„ì‹¤ì  ë³€ìˆ˜ë§Œ ìœ ì§€
    consistent_columns = [
        'employee_id', 'date', 'day_of_week', 'day_index', 'persona_code',
        # ê³µê°„ë³„ ë¹„ìœ¨ (í•©ê³„ = 1.0)
        'work_focused_ratio', 'meeting_collaboration_ratio', 
        'social_dining_ratio', 'break_relaxation_ratio', 'shared_work_ratio',
        # ê³µê°„ë³„ ì‹œê°„ (ë¹„ìœ¨ Ã— ë¡œê·¸ì¸ ì‹œê°„)
        'work_focused_hours', 'meeting_collaboration_hours', 
        'social_dining_hours', 'break_relaxation_hours', 'shared_work_hours',
        # í˜„ì‹¤ì  ì¸¡ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
        'system_login_hours', 'internal_comm_volume', 
        'cafeteria_usage', 'convenience_food_usage'
    ]
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_columns = [col for col in consistent_columns if col in final_dataset.columns]
    final_dataset = final_dataset[available_columns].copy()
    
    # CSV ì €ì¥
    if save_path:
        final_dataset.to_csv(save_path, index=False)
        print(f"ë°ì´í„°ì…‹ì´ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    total_time = time.time() - start_time
    print(f"\n=== ì¼ê´€ì„± ìˆëŠ” Chronos ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ ===")
    print(f"ìµœì¢… Shape: {final_dataset.shape}")
    print(f"í¬í•¨ëœ ë³€ìˆ˜: {len(available_columns)}ê°œ")
    print(f"ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„")
    
    # ìƒì„±ëœ ë³€ìˆ˜ í™•ì¸
    print(f"\n=== ìƒì„±ëœ ì¼ê´€ì„± ìˆëŠ” ë³€ìˆ˜ ëª©ë¡ ===")
    for i, col in enumerate(available_columns, 1):
        variable_type = ""
        if 'ratio' in col:
            variable_type = "(ë¹„ìœ¨, í•©ê³„=1.0)"
        elif 'hours' in col:
            variable_type = "(ì‹œê°„)"
        elif col in ['internal_comm_volume']:
            variable_type = "(ê°œìˆ˜)"
        elif col in ['cafeteria_usage', 'convenience_food_usage']:
            variable_type = "(íšŸìˆ˜)"
        print(f"{i:2d}. {col:30} {variable_type}")
    
    return final_dataset

def generate_employee_timeseries_consistent(employee_id, persona_code, business_days):
    """ì¼ê´€ì„± ìˆëŠ” ì§ì›ë³„ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±"""
    
    timeseries_data = []
    
    print(f"ì§ì› {employee_id} ({persona_code}) ì¼ê´€ì„± ìˆëŠ” ë°ì´í„° ìƒì„± ì¤‘...")
    
    for day_idx, date in enumerate(business_days):
        daily_data = {
            'employee_id': employee_id,
            'date': date,
            'day_of_week': date.weekday(),
            'day_index': day_idx,
            'persona_code': persona_code
        }
        
        # ì¼ê´€ì„± ìˆëŠ” í˜„ì‹¤ì  ë³€ìˆ˜ ìƒì„±
        try:
            realistic_variables = generate_realistic_variables_consistent(
                employee_id, persona_code, day_idx, date
            )
            daily_data.update(realistic_variables)
            
        except Exception as e:
            print(f"Day {day_idx} ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
            daily_data.update({
                'work_focused_ratio': 0.6,
                'meeting_collaboration_ratio': 0.15,
                'social_dining_ratio': 0.1,
                'break_relaxation_ratio': 0.1,
                'shared_work_ratio': 0.05,
                'system_login_hours': 8.0,
                'work_focused_hours': 4.8,
                'meeting_collaboration_hours': 1.2,
                'social_dining_hours': 0.8,
                'break_relaxation_hours': 0.8,
                'shared_work_hours': 0.4,
                'internal_comm_volume': 20,
                'cafeteria_usage': 1.0,
                'convenience_food_usage': 1.5
            })
        
        timeseries_data.append(daily_data)
    
    return pd.DataFrame(timeseries_data)

def generate_employee_timeseries_backup(employee_id, persona_code, business_days):
    """ë°±ì—…ìš© ì‹œê³„ì—´ ìƒì„± í•¨ìˆ˜"""
    
    timeseries_data = []
    
    # ê°œì¸ë³„ íŠ¹ì„± ìƒì„±
    np.random.seed(employee_id)
    individual_traits = {
        'work_intensity': np.random.uniform(0.8, 1.2),
        'social_tendency': np.random.uniform(0.7, 1.3),
        'routine_preference': np.random.uniform(0.9, 1.1),
        'volatility_multiplier': np.random.uniform(0.8, 1.2)
    }
    np.random.seed()  # ì‹œë“œ ë³µì›
    
    # í˜ë¥´ì†Œë‚˜ë³„ ê¸°ë³¸ íŒ¨í„´
    base_patterns = get_persona_base_pattern(persona_code)
    
    for day_idx, date in enumerate(business_days):
        daily_data = generate_daily_data(
            employee_id, date, day_idx, persona_code, base_patterns, individual_traits
        )
        
        # ì¢…í•© ì§€í‘œ ê³„ì‚°
        daily_data['productivity_efficiency'] = (
            daily_data['digital_work_engagement'] * 
            (daily_data['work_focused_hours'] / daily_data['system_login_hours'])
        )
        
        daily_data['collaboration_intensity'] = (
            (daily_data['meeting_collaboration_hours'] / daily_data['system_login_hours']) * 
            daily_data['meeting_participation']
        )
        
        timeseries_data.append(daily_data)
    
    return pd.DataFrame(timeseries_data)

def get_persona_base_pattern(persona):
    """í˜ë¥´ì†Œë‚˜ë³„ ê¸°ë³¸ íŒ¨í„´ ë°˜í™˜"""
    patterns = {
        'P01_burnout': {
            'base_hours': 9.5, 'work_ratio': 0.65, 'social_ratio': 0.06,
            'engagement_start': 0.7, 'engagement_end': 0.3, 'comm_volume': 20
        },
        'P02_onboarding_failure': {
            'base_hours': 7.2, 'work_ratio': 0.45, 'social_ratio': 0.04,
            'engagement_start': 0.4, 'engagement_end': 0.25, 'comm_volume': 12
        },
        'P03_career_stagnation': {
            'base_hours': 8.3, 'work_ratio': 0.62, 'social_ratio': 0.08,
            'engagement_start': 0.6, 'engagement_end': 0.55, 'comm_volume': 18
        },
        'P04_under_compensated': {
            'base_hours': 8.5, 'work_ratio': 0.68, 'social_ratio': 0.09,
            'engagement_start': 0.72, 'engagement_end': 0.65, 'comm_volume': 22
        },
        'S01_anchor': {
            'base_hours': 8.5, 'work_ratio': 0.68, 'social_ratio': 0.12,
            'engagement_start': 0.85, 'engagement_end': 0.87, 'comm_volume': 25
        },
        'S02_rising_star': {
            'base_hours': 9.8, 'work_ratio': 0.63, 'social_ratio': 0.11,
            'engagement_start': 0.85, 'engagement_end': 0.92, 'comm_volume': 35
        },
        'S03_intrinsically_motivated': {
            'base_hours': 8.8, 'work_ratio': 0.72, 'social_ratio': 0.08,
            'engagement_start': 0.88, 'engagement_end': 0.90, 'comm_volume': 20
        },
        'N01_coaster': {
            'base_hours': 8.0, 'work_ratio': 0.60, 'social_ratio': 0.10,
            'engagement_start': 0.55, 'engagement_end': 0.53, 'comm_volume': 15
        },
        'N02_competent_malcontent': {
            'base_hours': 8.2, 'work_ratio': 0.70, 'social_ratio': 0.06,
            'engagement_start': 0.75, 'engagement_end': 0.65, 'comm_volume': 12
        },
        'N03_new_parent': {
            'base_hours': 7.5, 'work_ratio': 0.65, 'social_ratio': 0.08,
            'engagement_start': 0.70, 'engagement_end': 0.68, 'comm_volume': 20
        }
    }
    return patterns.get(persona, patterns['S01_anchor'])

def generate_daily_data(employee_id, date, day_idx, persona, base_patterns, individual_traits):
    """ì¼ë³„ ë°ì´í„° ìƒì„±"""
    
    # ìš”ì¼ íš¨ê³¼
    weekday = date.weekday()
    weekday_multipliers = {
        0: 0.95,  # ì›”ìš”ì¼ - ì•½ê°„ ë‚®ìŒ
        1: 1.0,   # í™”ìš”ì¼ - ê¸°ì¤€
        2: 1.05,  # ìˆ˜ìš”ì¼ - ì•½ê°„ ë†’ìŒ
        3: 1.0,   # ëª©ìš”ì¼ - ê¸°ì¤€
        4: 0.9    # ê¸ˆìš”ì¼ - ë‚®ìŒ
    }
    weekday_mult = weekday_multipliers.get(weekday, 1.0)
    
    # ì‹œê°„ ì§„í–‰ì— ë”°ë¥¸ ë³€í™” (í˜ë¥´ì†Œë‚˜ë³„)
    try:
        total_days = len(calendar.business_days)
    except NameError:
        total_days = len(business_days)
    
    progress = min(day_idx / total_days, 1.0)
    
    # ê¸°ë³¸ íŒ¨í„´ì—ì„œ ê°œì¸ íŠ¹ì„± ì ìš©
    base_hours = base_patterns['base_hours'] * individual_traits['work_intensity'] * weekday_mult
    base_hours += np.random.normal(0, 0.5 * individual_traits['volatility_multiplier'])
    base_hours = max(4.0, min(16.0, base_hours))
    
    # ì—…ë¬´ ëª°ì…ë„ (ì‹œê°„ì— ë”°ë¥¸ ë³€í™”)
    engagement_start = base_patterns['engagement_start']
    engagement_end = base_patterns['engagement_end']
    current_engagement = engagement_start + (engagement_end - engagement_start) * progress
    current_engagement *= individual_traits['work_intensity']
    current_engagement += np.random.normal(0, 0.1 * individual_traits['volatility_multiplier'])
    current_engagement = max(0.1, min(1.0, current_engagement))
    
    # ê³µê°„ ì‚¬ìš© ë¹„ìœ¨ ìƒì„±
    work_ratio = base_patterns['work_ratio'] * individual_traits['routine_preference']
    social_ratio = base_patterns['social_ratio'] * individual_traits['social_tendency']
    
    # ë‚˜ë¨¸ì§€ ë¹„ìœ¨ë“¤
    meeting_ratio = 0.15 + np.random.normal(0, 0.03)
    break_ratio = 0.08 + np.random.normal(0, 0.02)
    shared_ratio = max(0.01, 1.0 - work_ratio - social_ratio - meeting_ratio - break_ratio)
    
    # ì •ê·œí™”
    total_ratio = work_ratio + meeting_ratio + social_ratio + break_ratio + shared_ratio
    work_ratio /= total_ratio
    meeting_ratio /= total_ratio
    social_ratio /= total_ratio
    break_ratio /= total_ratio
    shared_ratio /= total_ratio
    
    # ì†Œí†µëŸ‰
    comm_volume = base_patterns['comm_volume'] * individual_traits['social_tendency'] * weekday_mult
    comm_volume += np.random.normal(0, 5)
    comm_volume = max(0, int(comm_volume))
    
    # ê¸°íƒ€ ì§€í‘œë“¤
    cafeteria_usage = 1.0 + np.random.normal(0, 0.3)
    cafeteria_usage = max(0, min(3, cafeteria_usage))
    
    convenience_usage = 1.5 + np.random.normal(0, 0.5)
    convenience_usage = max(0, min(8, convenience_usage))
    
    meeting_participation = 0.7 + np.random.normal(0, 0.15)
    meeting_participation = max(0.0, min(1.0, meeting_participation))
    
    return {
        'employee_id': employee_id,
        'date': date,
        'work_focused_hours': work_ratio * base_hours,
        'meeting_collaboration_hours': meeting_ratio * base_hours,
        'social_dining_hours': social_ratio * base_hours,
        'break_relaxation_hours': break_ratio * base_hours,
        'shared_work_hours': shared_ratio * base_hours,
        'system_login_hours': base_hours,
        'internal_comm_volume': comm_volume,
        'cafeteria_usage': cafeteria_usage,
        'convenience_food_usage': convenience_usage,
        'meeting_participation': meeting_participation,
        'digital_work_engagement': current_engagement
    }

# Chronos ë°ì´í„° ìƒì„± ì‹œìŠ¤í…œ ì™„ë£Œ
print("\n=== ğŸ”¥ ìˆ˜ì •ëœ Chronos ë°ì´í„° ìƒì„± ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ ===")
print("ğŸš€ ì£¼ìš” ê°œì„  ì‚¬í•­:")
print("âœ… ê°œì¸ë³„ ëœë¤ì„± ë³µêµ¬ (ì‹œë“œ ë³µì› ë²„ê·¸ ìˆ˜ì •)")
print("âœ… ì‹¤ì œ í‡´ì‚¬ ì •ë³´(Attrition) í™œìš©")
print("âœ… í‡´ì‚¬ì íŠ¹ë³„ í–‰ë™ íŒ¨í„´ ì¶”ê°€")
print("âœ… í˜ë¥´ì†Œë‚˜ ê°„ ì°¨ì´ ê°•í™”")
print("\nğŸ› ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì£¼ìš” í•¨ìˆ˜:")
print("- generate_attrition_aware_chronos_dataset(): ğŸ†• í‡´ì‚¬ ì¸ì‹ ë°ì´í„° ìƒì„±")
print("- generate_consistent_chronos_dataset(): ê¸°ì¡´ ì¼ê´€ì„± ë°ì´í„° ìƒì„±")
print("- generate_realistic_variables_consistent(): ê°œë³„ ì§ì› ë³€ìˆ˜ ìƒì„±")
print("- validate_chronos_dataset(): ë°ì´í„° ê²€ì¦")
print("- visualize_chronos_patterns(): ë°ì´í„° ì‹œê°í™”")
print("\nğŸ“Š ìƒì„±ë˜ëŠ” ë³€ìˆ˜ë“¤:")
print("- ê¸°ë³¸ ì •ë³´: employee_id, date, day_of_week, day_index, persona_code, attrition_status")
print("- ê³µê°„ë³„ ë¹„ìœ¨: work_focused_ratio, meeting_collaboration_ratio, social_dining_ratio, break_relaxation_ratio, shared_work_ratio")
print("- ê³µê°„ë³„ ì‹œê°„: work_focused_hours, meeting_collaboration_hours, social_dining_hours, break_relaxation_hours, shared_work_hours") 
print("- ì‹œìŠ¤í…œ ë³€ìˆ˜: system_login_hours, internal_comm_volume")
print("- ì‹ìƒí™œ ë³€ìˆ˜: cafeteria_usage, convenience_food_usage")
print("\nğŸ¯ í‡´ì‚¬ì íŠ¹ë³„ íŒ¨í„´:")
print("- ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ì—…ë¬´ ì§‘ì¤‘ë„ ì ì§„ì  ê°ì†Œ")
print("- íœ´ì‹ ì‹œê°„ ë° í¸ì˜ì  ìŒì‹ ì‚¬ìš© ì¦ê°€")
print("- ì†Œí†µëŸ‰ ë° ì¹´í˜í…Œë¦¬ì•„ ì‚¬ìš© ê°ì†Œ")
print("- ë¡œê·¸ì¸ ì‹œê°„ ë¶ˆê·œì¹™ì„± ì¦ê°€")

# ğŸ§ª ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
print("\n=== ğŸ§ª ìˆ˜ì •ëœ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
try:
    # ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ (10ëª…)
    print("ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...")
    test_data = generate_attrition_aware_chronos_dataset(num_employees=10)
    
    if len(test_data) > 0:
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ! ìƒì„±ëœ ë°ì´í„°: {test_data.shape}")
        
        # í‡´ì‚¬ì/ì¬ì§ì ì°¨ì´ í™•ì¸
        attrition_comparison = test_data.groupby('attrition_status')[
            ['work_focused_ratio', 'internal_comm_volume', 'convenience_food_usage']
        ].mean()
        
        print("\nğŸ“Š í‡´ì‚¬ì vs ì¬ì§ì í‰ê·  ë¹„êµ:")
        print(attrition_comparison.round(3))
        
        # ê°œì¸ë³„ ì°¨ì´ í™•ì¸
        individual_variance = test_data.groupby('employee_id')['work_focused_ratio'].std()
        print(f"\nğŸ² ê°œì¸ë³„ ë³€ë™ì„± (work_focused_ratio í‘œì¤€í¸ì°¨):")
        print(f"í‰ê· : {individual_variance.mean():.4f}, ë²”ìœ„: [{individual_variance.min():.4f}, {individual_variance.max():.4f}]")
        
        if individual_variance.mean() > 0.01:
            print("âœ… ê°œì¸ë³„ ëœë¤ì„± ë³µêµ¬ ì„±ê³µ!")
        else:
            print("âŒ ê°œì¸ë³„ ëœë¤ì„±ì´ ì—¬ì „íˆ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
except Exception as e:
    print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

print("\nğŸ‰ ìˆ˜ì •ëœ Chronos ë°ì´í„° ìƒì„± ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
print("ì´ì œ generate_attrition_aware_chronos_dataset() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬")
print("í‡´ì‚¬ìì™€ ì¬ì§ì ê°„ì˜ ì˜ë¯¸ìˆëŠ” ì°¨ì´ê°€ ìˆëŠ” ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

