# ============================================================================
# ì…€ 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë° í™˜ê²½ ì„¤ì •
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
import torch.nn.functional as F

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
import optuna
from optuna.trial import TrialState

# ê¸°íƒ€ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.utils.class_weight import compute_class_weight
from tqdm import tqdm
import os
import json

# ì‹œë“œ ì„¤ì •
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

# í”Œë¡¯ ì„¤ì •
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# Optuna ë¡œê¹… ì„¤ì •
optuna.logging.set_verbosity(optuna.logging.WARNING)

# ============================================================================
# ì…€ 2: ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ì •ë³´ í™•ì¸
# ============================================================================

class EmployeeAttritionDataProcessor:
    def __init__(self, sequence_length=6, aggregation_unit='week'):
        """
        Args:
            sequence_length (int): ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ê¸¸ì´ (ìµœì í™” ëŒ€ìƒ)
            aggregation_unit (str): ì§‘ê³„ ë‹¨ìœ„ ('day', 'week', 'month')
        """
        self.sequence_length = sequence_length
        self.aggregation_unit = aggregation_unit
        self.scaler = StandardScaler()
        self.excluded_ratio_columns = [
            'work_focused_ratio', 'meeting_collaboration_ratio', 
            'social_dining_ratio', 'break_relaxation_ratio', 'shared_work_ratio'
        ]
        self.feature_columns = []
        
        print(f"ğŸ”§ ê¸°ë³¸ ì„¤ì •: {sequence_length}{aggregation_unit[0]} ì‹œí€€ìŠ¤, {aggregation_unit} ë‹¨ìœ„ ì§‘ê³„")
        
    def load_data(self, timeseries_path, personas_path):
        """ë°ì´í„° ë¡œë”©"""
        print("=" * 50)
        print("ë°ì´í„° ë¡œë”© ì¤‘...")
        print("=" * 50)
        
        # ì‹œê³„ì—´ ë°ì´í„° ë¡œë“œ
        self.ts_data = pd.read_csv(timeseries_path)
        print(f"âœ… ì‹œê³„ì—´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.ts_data.shape}")
        
        # ì§ì› ì†ì„± ë°ì´í„° ë¡œë“œ
        self.personas_data = pd.read_csv(personas_path)
        print(f"âœ… ì§ì› ì†ì„± ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.personas_data.shape}")
        
        return self.ts_data.head(), self.personas_data.head()

# ë°ì´í„° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
processor = EmployeeAttritionDataProcessor(
    sequence_length=6,  # ê¸°ë³¸ê°’ (ìµœì í™” ëŒ€ìƒ)
    aggregation_unit='week'
)

# ë°ì´í„° ë¡œë”© (íŒŒì¼ ê²½ë¡œë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)
ts_sample, personas_sample = processor.load_data(
    'data/IBM_HR_timeseries.csv', 
    'data/IBM_HR_personas_assigned.csv'
)

print("\nğŸ“‹ ì‹œê³„ì—´ ë°ì´í„° ìƒ˜í”Œ:")
print(ts_sample)

# ============================================================================
# ì…€ 3: ìë™ ì»¬ëŸ¼ ê°ì§€ ë° ë°ì´í„° ë§¤ì¹­
# ============================================================================

def detect_columns(processor):
    """ì»¬ëŸ¼ ìë™ ê°ì§€ ë° ë§¤ì¹­"""
    print("=" * 50)
    print("ì»¬ëŸ¼ ìë™ ê°ì§€ ì¤‘...")
    print("=" * 50)
    
    # ë‚ ì§œ ì»¬ëŸ¼ ìë™ ê°ì§€
    date_columns = [col for col in processor.ts_data.columns 
                   if any(keyword in col.lower() for keyword in ['date', 'time', 'timestamp'])]
    
    if date_columns:
        processor.date_column = date_columns[0]
        print(f"ğŸ—“ï¸  ê°ì§€ëœ ë‚ ì§œ ì»¬ëŸ¼: {processor.date_column}")
    else:
        raise ValueError("âŒ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    # ì§ì› ID ì»¬ëŸ¼ ìë™ ê°ì§€
    employee_id_candidates = [col for col in processor.ts_data.columns 
                             if any(keyword in col.lower() for keyword in ['employee', 'id', 'number'])]
    
    if employee_id_candidates:
        processor.employee_id_col = employee_id_candidates[0]
        print(f"ğŸ‘¤ ê°ì§€ëœ ì‹œê³„ì—´ ì§ì› ID ì»¬ëŸ¼: {processor.employee_id_col}")
    else:
        raise ValueError("âŒ ì§ì› ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    # ì§ì› ì†ì„± ë°ì´í„°ì—ì„œ ë§¤ì¹­ë˜ëŠ” ID ì»¬ëŸ¼ ì°¾ê¸°
    personas_id_candidates = [col for col in processor.personas_data.columns 
                             if any(keyword in col.lower() for keyword in ['employee', 'id', 'number'])]
    
    max_overlap = 0
    best_match_col = None
    
    for col in personas_id_candidates:
        try:
            overlap = len(set(processor.ts_data[processor.employee_id_col]).intersection(
                         set(processor.personas_data[col])))
            if overlap > max_overlap:
                max_overlap = overlap
                best_match_col = col
        except:
            continue
            
    if best_match_col:
        processor.personas_id_col = best_match_col
        print(f"âœ… ìµœì  ë§¤ì¹­ ì»¬ëŸ¼: {processor.personas_id_col} ({max_overlap}ëª… ê²¹ì¹¨)")
    else:
        raise ValueError("âŒ ì§ì› ì†ì„± ë°ì´í„°ì—ì„œ ë§¤ì¹­ë˜ëŠ” ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Attrition ì»¬ëŸ¼ ì°¾ê¸°
    attrition_cols = [col for col in processor.personas_data.columns 
                     if 'attrition' in col.lower()]
    
    if attrition_cols:
        processor.attrition_col = attrition_cols[0]
        print(f"ğŸ¯ ê°ì§€ëœ Attrition ì»¬ëŸ¼: {processor.attrition_col}")
    else:
        raise ValueError("âŒ Attrition ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return processor

# ì»¬ëŸ¼ ê°ì§€ ì‹¤í–‰
processor = detect_columns(processor)

# ============================================================================
# ì…€ 4: ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œê°„ ë²”ìœ„ ë¶„ì„
# ============================================================================

def preprocess_data(processor):
    """ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œê°„ ë²”ìœ„ ë¶„ì„"""
    print("=" * 50)
    print("ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    print("=" * 50)
    
    # ë‚ ì§œ ë³€í™˜
    processor.ts_data[processor.date_column] = pd.to_datetime(processor.ts_data[processor.date_column])
    
    # 2023-2024ë…„ ë°ì´í„°ë§Œ í•„í„°ë§
    start_date = datetime(2023, 1, 1)
    end_date = datetime(2024, 12, 31)
    
    original_shape = processor.ts_data.shape
    processor.ts_data = processor.ts_data[
        (processor.ts_data[processor.date_column] >= start_date) & 
        (processor.ts_data[processor.date_column] <= end_date)
    ].copy()
    
    print(f"ğŸ“… 2023-2024ë…„ í•„í„°ë§: {original_shape} â†’ {processor.ts_data.shape}")
    
    # Attrition ë¼ë²¨ì„ 0/1ë¡œ ë³€í™˜
    def convert_attrition(value):
        if pd.isna(value):
            return 0
        value_str = str(value).lower().strip()
        if value_str in ['yes', 'y', 'true', '1', '1.0']:
            return 1
        else:
            return 0
            
    processor.personas_data['attrition_binary'] = processor.personas_data[processor.attrition_col].apply(convert_attrition)
    
    attrition_dist = processor.personas_data['attrition_binary'].value_counts()
    print(f"\nğŸ¯ Attrition ë¶„í¬:")
    print(f"   ì¬ì§(0): {attrition_dist.get(0, 0)}ëª…")
    print(f"   í‡´ì‚¬(1): {attrition_dist.get(1, 0)}ëª…")
    print(f"   í‡´ì‚¬ìœ¨: {attrition_dist.get(1, 0) / len(processor.personas_data) * 100:.1f}%")
    
    return processor

# ì „ì²˜ë¦¬ ì‹¤í–‰
processor = preprocess_data(processor)

# ============================================================================
# ì…€ 5: í”¼ì²˜ ì„ íƒ ë° ë‹¨ìˆœ ì§‘ê³„
# ============================================================================

def identify_and_prepare_features(processor):
    """í”¼ì²˜ ì‹ë³„ ë° ë‹¨ìˆœ ì§‘ê³„ (í†µê³„ëŸ‰ í™•ì¥ ì—†ìŒ)"""
    print("=" * 50)
    print("í”¼ì²˜ ì‹ë³„ ë° ë‹¨ìˆœ ì§‘ê³„ ì¤‘...")
    print("=" * 50)
    
    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì‹ë³„
    numeric_columns = processor.ts_data.select_dtypes(include=[np.number]).columns.tolist()
    
    # ì œì™¸í•  ì»¬ëŸ¼ë“¤ ì œê±°
    exclude_columns = [processor.employee_id_col] + processor.excluded_ratio_columns
    exclude_columns = [col for col in exclude_columns if col in numeric_columns]
    
    processor.feature_columns = [col for col in numeric_columns if col not in exclude_columns]
    
    print(f"ğŸ” ì „ì²´ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: {len(numeric_columns)}ê°œ")
    print(f"âŒ ì œì™¸ëœ ì»¬ëŸ¼: {exclude_columns}")
    print(f"âœ… ì‚¬ìš©í•  í”¼ì²˜: {len(processor.feature_columns)}ê°œ")
    
    return processor

def create_simple_aggregated_data(processor):
    """ë‹¨ìˆœ ì‹œê°„ ì§‘ê³„ (í‰ê· ë§Œ ì‚¬ìš©, í†µê³„ëŸ‰ í™•ì¥ ì—†ìŒ)"""
    print("=" * 50)
    print(f"{processor.aggregation_unit} ë‹¨ìœ„ ë‹¨ìˆœ ì§‘ê³„ ì¤‘...")
    print("=" * 50)
    
    # ì§‘ê³„ ë‹¨ìœ„ë³„ ì²˜ë¦¬
    if processor.aggregation_unit == 'day':
        processor.ts_data['time_period'] = processor.ts_data[processor.date_column].dt.date
        period_range = pd.date_range('2023-01-01', '2024-12-31', freq='D')
        period_format = lambda x: x.date()
        
    elif processor.aggregation_unit == 'week':
        processor.ts_data['year'] = processor.ts_data[processor.date_column].dt.year
        processor.ts_data['week'] = processor.ts_data[processor.date_column].dt.isocalendar().week
        processor.ts_data['time_period'] = processor.ts_data['year'].astype(str) + '-W' + processor.ts_data['week'].astype(str).str.zfill(2)
        
        period_range = pd.date_range('2023-01-02', '2024-12-30', freq='W-MON')
        period_format = lambda x: f"{x.year}-W{x.isocalendar().week:02d}"
        
    else:  # month
        processor.ts_data['time_period'] = processor.ts_data[processor.date_column].dt.to_period('M').astype(str)
        period_range = pd.period_range('2023-01', '2024-12', freq='M')
        period_format = lambda x: str(x)
    
    # ì‹œê°„ë³„ ë‹¨ìˆœ ì§‘ê³„ (í‰ê· ë§Œ)
    agg_data = processor.ts_data.groupby([processor.employee_id_col, 'time_period'])[processor.feature_columns].mean().reset_index()
    
    print(f"ğŸ“Š ì§‘ê³„ ì „ ë°ì´í„°: {processor.ts_data.shape}")
    print(f"ğŸ“Š ì§‘ê³„ í›„ ë°ì´í„°: {agg_data.shape}")
    print(f"ğŸ“Š í”¼ì²˜ ìˆ˜: {len(processor.feature_columns)}ê°œ (ë‹¨ìˆœ í‰ê· )")
    
    # ëª¨ë“  ì§ì›-ì‹œê°„ ì¡°í•© ìƒì„±
    all_periods = [period_format(p) for p in period_range]
    all_employees = agg_data[processor.employee_id_col].unique()
    
    print(f"ğŸ‘¥ ê³ ìœ  ì§ì› ìˆ˜: {len(all_employees)}")
    print(f"ğŸ“… ì´ {processor.aggregation_unit} ìˆ˜: {len(all_periods)}")
    
    # ì™„ì „í•œ ì‹œê°„ ì¸ë±ìŠ¤ ìƒì„±
    complete_index = pd.MultiIndex.from_product(
        [all_employees, all_periods], 
        names=[processor.employee_id_col, 'time_period']
    ).to_frame(index=False)
    
    # ë³‘í•© ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    processor.aggregated_data = pd.merge(
        complete_index, 
        agg_data, 
        on=[processor.employee_id_col, 'time_period'], 
        how='left'
    )
    
    # ê²°ì¸¡ì¹˜ë¥¼ ì§ì›ë³„ í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°
    missing_before = processor.aggregated_data.isnull().sum().sum()
    
    for col in processor.feature_columns:
        processor.aggregated_data[col] = processor.aggregated_data.groupby(processor.employee_id_col)[col].transform(
            lambda x: x.fillna(x.mean()) if not x.isna().all() else x.fillna(0)
        )
    
    missing_after = processor.aggregated_data.isnull().sum().sum()
    
    print(f"ğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬: {missing_before} â†’ {missing_after}")
    print(f"âœ… ìµœì¢… ì§‘ê³„ ë°ì´í„°: {processor.aggregated_data.shape}")
    
    return processor

# í”¼ì²˜ ì‹ë³„ ë° ì§‘ê³„ ì‹¤í–‰
processor = identify_and_prepare_features(processor)
processor = create_simple_aggregated_data(processor)

# ============================================================================
# ì…€ 6: ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± (íŒŒë¼ë¯¸í„°í™”)
# ============================================================================

def create_sequences_with_params(processor, sequence_length=None):
    """íŒŒë¼ë¯¸í„°í™”ëœ ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±"""
    if sequence_length is not None:
        processor.sequence_length = sequence_length
    
    # ì§ì› ì†ì„± ë°ì´í„°ì™€ ë³‘í•©
    merged_data = pd.merge(
        processor.aggregated_data,
        processor.personas_data[[processor.personas_id_col, 'attrition_binary']],
        left_on=processor.employee_id_col,
        right_on=processor.personas_id_col,
        how='inner'
    )
    
    sequences = []
    labels = []
    employee_ids = []
    
    valid_employees = 0
    total_sequences = 0
    
    for employee_id in merged_data[processor.employee_id_col].unique():
        employee_data = merged_data[
            merged_data[processor.employee_id_col] == employee_id
        ].sort_values('time_period')
        
        available_periods = len(employee_data)
        
        if available_periods >= processor.sequence_length:
            valid_employees += 1
            
            sequence_data = employee_data[processor.feature_columns].values
            label = employee_data['attrition_binary'].iloc[0]
            
            # ìµœê·¼ ë°ì´í„° ìœ„ì£¼ë¡œ ì‹œí€€ìŠ¤ ìƒì„±
            sequences.append(sequence_data[-processor.sequence_length:])
            labels.append(label)
            employee_ids.append(employee_id)
            total_sequences += 1
    
    X = np.array(sequences, dtype=np.float32)
    y = np.array(labels, dtype=np.int64)
    employee_ids_seq = np.array(employee_ids)
    
    return X, y, employee_ids_seq, valid_employees, total_sequences

# ê¸°ë³¸ ì‹œí€€ìŠ¤ ìƒì„±
processor.X, processor.y, processor.employee_ids_seq, valid_emp, total_seq = create_sequences_with_params(processor)

print(f"âœ… ê¸°ë³¸ ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ:")
print(f"   ìœ íš¨ ì§ì›: {valid_emp}ëª…")
print(f"   ì‹œí€€ìŠ¤ ìˆ˜: {total_seq}ê°œ")
print(f"   ì‹œí€€ìŠ¤ í˜•íƒœ: {processor.X.shape}")
print(f"   í‡´ì‚¬ìœ¨: {np.mean(processor.y) * 100:.1f}%")

# ============================================================================
# ì…€ 7: ëª¨ë¸ ì •ì˜ (íŒŒë¼ë¯¸í„°í™”)
# ============================================================================

class GRUModel(nn.Module):
    """íŒŒë¼ë¯¸í„°í™”ëœ GRU ëª¨ë¸"""
    
    def __init__(self, input_size, hidden_size=32, num_layers=1, dropout=0.2):
        super(GRUModel, self).__init__()
        
        self.gru = nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0,
            batch_first=True
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, 2)
        )
    
    def forward(self, x):
        gru_out, _ = self.gru(x)
        last_output = gru_out[:, -1, :]
        output = self.classifier(last_output)
        return output

class CNN1DModel(nn.Module):
    """íŒŒë¼ë¯¸í„°í™”ëœ 1D CNN ëª¨ë¸"""
    
    def __init__(self, input_size, num_filters=32, kernel_sizes=[2, 3, 4], dropout=0.2):
        super(CNN1DModel, self).__init__()
        
        self.conv_layers = nn.ModuleList()
        for kernel_size in kernel_sizes:
            conv_layer = nn.Sequential(
                nn.Conv1d(input_size, num_filters, kernel_size, padding=kernel_size//2),
                nn.ReLU(),
                nn.BatchNorm1d(num_filters),
                nn.Conv1d(num_filters, num_filters, kernel_size, padding=kernel_size//2),
                nn.ReLU(),
                nn.BatchNorm1d(num_filters),
                nn.AdaptiveMaxPool1d(1)
            )
            self.conv_layers.append(conv_layer)
        
        combined_features = len(kernel_sizes) * num_filters
        self.classifier = nn.Sequential(
            nn.Linear(combined_features, 64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, 2)
        )
    
    def forward(self, x):
        x = x.transpose(1, 2)
        
        conv_outputs = []
        for conv_layer in self.conv_layers:
            conv_out = conv_layer(x).squeeze(-1)
            conv_outputs.append(conv_out)
        
        combined = torch.cat(conv_outputs, dim=1)
        output = self.classifier(combined)
        return output

class GRU_CNN_HybridModel(nn.Module):
    """íŒŒë¼ë¯¸í„°í™”ëœ GRU+CNN í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸"""
    
    def __init__(self, input_size, gru_hidden=32, cnn_filters=16, kernel_sizes=[2, 3], dropout=0.2):
        super(GRU_CNN_HybridModel, self).__init__()
        
        # GRU ë¸Œëœì¹˜
        self.gru = nn.GRU(
            input_size=input_size,
            hidden_size=gru_hidden,
            num_layers=1,
            dropout=dropout,
            batch_first=True
        )
        self.gru_dropout = nn.Dropout(dropout)
        
        # CNN ë¸Œëœì¹˜
        self.conv_layers = nn.ModuleList()
        for kernel_size in kernel_sizes:
            conv_layer = nn.Sequential(
                nn.Conv1d(input_size, cnn_filters, kernel_size, padding=kernel_size//2),
                nn.ReLU(),
                nn.BatchNorm1d(cnn_filters),
                nn.AdaptiveMaxPool1d(1)
            )
            self.conv_layers.append(conv_layer)
        
        # ë¶„ë¥˜ê¸°
        combined_features = gru_hidden + len(kernel_sizes) * cnn_filters
        self.classifier = nn.Sequential(
            nn.Linear(combined_features, 64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(32, 2)
        )
        
        # ì–´í…ì…˜
        self.attention = nn.Sequential(
            nn.Linear(gru_hidden, 1),
            nn.Softmax(dim=1)
        )
    
    def forward(self, x):
        # GRU + ì–´í…ì…˜
        gru_out, _ = self.gru(x)
        attention_weights = self.attention(gru_out)
        gru_features = torch.sum(gru_out * attention_weights, dim=1)
        gru_features = self.gru_dropout(gru_features)
        
        # CNN
        x_cnn = x.transpose(1, 2)
        cnn_outputs = []
        for conv_layer in self.conv_layers:
            conv_out = conv_layer(x_cnn).squeeze(-1)
            cnn_outputs.append(conv_out)
        
        cnn_features = torch.cat(cnn_outputs, dim=1)
        
        # ê²°í•© ë° ë¶„ë¥˜
        combined_features = torch.cat([gru_features, cnn_features], dim=1)
        output = self.classifier(combined_features)
        return output

print("ğŸ§  íŒŒë¼ë¯¸í„°í™”ëœ ëª¨ë¸ ì •ì˜ ì™„ë£Œ")

# ============================================================================
# ì…€ 8: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ëª©ì  í•¨ìˆ˜
# ============================================================================

def prepare_data_for_optimization(X, y, employee_ids, test_size=0.2, val_size=0.2):
    """ìµœì í™”ìš© ë°ì´í„° ë¶„í• """
    unique_employees = np.unique(employee_ids)
    employee_labels = [y[employee_ids == emp][0] for emp in unique_employees]
    
    train_employees, test_employees = train_test_split(
        unique_employees, test_size=test_size, random_state=42, stratify=employee_labels
    )
    
    train_emp_labels = [y[employee_ids == emp][0] for emp in train_employees]
    train_employees, val_employees = train_test_split(
        train_employees, test_size=val_size/(1-test_size), random_state=42, stratify=train_emp_labels
    )
    
    # ì¸ë±ìŠ¤ ìƒì„±
    train_idx = np.isin(employee_ids, train_employees)
    val_idx = np.isin(employee_ids, val_employees)
    test_idx = np.isin(employee_ids, test_employees)
    
    # ë°ì´í„° ë¶„í• 
    X_train, y_train = X[train_idx], y[train_idx]
    X_val, y_val = X[val_idx], y[val_idx]
    X_test, y_test = X[test_idx], y[test_idx]
    
    # ì •ê·œí™”
    scaler = StandardScaler()
    n_samples, n_timesteps, n_features = X_train.shape
    X_train_reshaped = X_train.reshape(-1, n_features)
    
    scaler.fit(X_train_reshaped)
    
    X_train_scaled = scaler.transform(X_train_reshaped).reshape(n_samples, n_timesteps, n_features)
    X_val_scaled = scaler.transform(X_val.reshape(-1, n_features)).reshape(X_val.shape)
    X_test_scaled = scaler.transform(X_test.reshape(-1, n_features)).reshape(X_test.shape)
    
    # PyTorch í…ì„œë¡œ ë³€í™˜
    X_train_tensor = torch.FloatTensor(X_train_scaled)
    y_train_tensor = torch.LongTensor(y_train)
    X_val_tensor = torch.FloatTensor(X_val_scaled)
    y_val_tensor = torch.LongTensor(y_val)
    X_test_tensor = torch.FloatTensor(X_test_scaled)
    y_test_tensor = torch.LongTensor(y_test)
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜
    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
    class_weights_tensor = torch.FloatTensor(class_weights).to(device)
    
    return (X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, 
            X_test_tensor, y_test_tensor, class_weights_tensor, scaler)

def train_model_for_optimization(model, X_train, y_train, X_val, y_val, class_weights, 
                                lr=0.001, epochs=30, batch_size=64, patience=10):
    """ìµœì í™”ìš© ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜"""
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_dataset = TensorDataset(X_train, y_train)
    val_dataset = TensorDataset(X_val, y_val)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    # í•™ìŠµ ì„¤ì •
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
    
    best_val_loss = float('inf')
    patience_counter = 0
    best_model_state = None
    
    for epoch in range(epochs):
        # í•™ìŠµ
        model.train()
        train_loss = 0.0
        for batch_X, batch_y in train_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            train_loss += loss.item()
        
        # ê²€ì¦
        model.eval()
        val_loss = 0.0
        val_predictions = []
        val_labels = []
        
        with torch.no_grad():
            for batch_X, batch_y in val_loader:
                batch_X, batch_y = batch_X.to(device), batch_y.to(device)
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)
                val_loss += loss.item()
                
                probs = F.softmax(outputs, dim=1)
                val_predictions.extend(probs[:, 1].cpu().numpy())
                val_labels.extend(batch_y.cpu().numpy())
        
        avg_val_loss = val_loss / len(val_loader)
        scheduler.step(avg_val_loss)
        
        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            best_model_state = model.state_dict().copy()
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            break
    
    # ìµœê³  ëª¨ë¸ ë¡œë“œ
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    # ìµœì¢… ê²€ì¦ ì ìˆ˜ ê³„ì‚°
    model.eval()
    val_predictions = []
    val_labels = []
    
    with torch.no_grad():
        for batch_X, batch_y in val_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            outputs = model(batch_X)
            probs = F.softmax(outputs, dim=1)
            val_predictions.extend(probs[:, 1].cpu().numpy())
            val_labels.extend(batch_y.cpu().numpy())
    
    try:
        auc_score = roc_auc_score(val_labels, val_predictions)
    except:
        auc_score = 0.5
    
    return auc_score

def objective_hybrid(trial):
    """GRU+CNN í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìµœì í™” ëª©ì í•¨ìˆ˜"""
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
    sequence_length = trial.suggest_int('sequence_length', 4, 12)
    gru_hidden = trial.suggest_int('gru_hidden', 16, 128, step=16)
    cnn_filters = trial.suggest_int('cnn_filters', 8, 64, step=8)
    dropout = trial.suggest_float('dropout', 0.1, 0.5)
    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])
    
    # ì‹œí€€ìŠ¤ ìƒì„± (ìƒˆë¡œìš´ í”„ë¡œì„¸ì„œ ì‚¬ìš©)
    X, y, employee_ids, valid_emp, total_seq = create_sequences_with_params(processor, sequence_length)
    
    if total_seq < 50:  # ì‹œí€€ìŠ¤ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ
        return 0.5
    
    # ë°ì´í„° ì¤€ë¹„
    try:
        (X_train, y_train, X_val, y_val, 
         X_test, y_test, class_weights, scaler) = prepare_data_for_optimization(X, y, employee_ids)
    except:
        return 0.5
    
    # ëª¨ë¸ ìƒì„±
    input_size = len(processor.feature_columns)
    model = GRU_CNN_HybridModel(
        input_size=input_size,
        gru_hidden=gru_hidden,
        cnn_filters=cnn_filters,
        kernel_sizes=[2, 3],  # ê³ ì •
        dropout=dropout
    ).to(device)
    
    # í•™ìŠµ ë° í‰ê°€
    auc_score = train_model_for_optimization(
        model, X_train, y_train, X_val, y_val, class_weights,
        lr=lr, epochs=25, batch_size=batch_size, patience=8
    )
    
    return auc_score

print("ğŸ¯ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ëª©ì í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ")

# ============================================================================
# ì…€ 9: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰
# ============================================================================

def run_hyperparameter_optimization(n_trials=50):
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰"""
    print("ğŸš€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
    print("=" * 50)
    print(f"ì´ {n_trials}íšŒ ì‹œë„ë¡œ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰ ì¤‘...")
    
    # Optuna ìŠ¤í„°ë”” ìƒì„±
    study = optuna.create_study(
        direction='maximize',
        sampler=optuna.samplers.TPESampler(seed=42),
        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)
    )
    
    # ìµœì í™” ì‹¤í–‰
    study.optimize(objective_hybrid, n_trials=n_trials, show_progress_bar=True)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ† ìµœì í™” ì™„ë£Œ!")
    print("=" * 50)
    print(f"âœ… ìµœê³  AUC ìŠ¤ì½”ì–´: {study.best_value:.4f}")
    print(f"ğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°:")
    
    for key, value in study.best_params.items():
        print(f"   {key}: {value}")
    
    # ì‹œë„ë³„ ê²°ê³¼ ì‹œê°í™”
    plot_optimization_results(study)
    
    return study

def plot_optimization_results(study):
    """ìµœì í™” ê²°ê³¼ ì‹œê°í™”"""
    
    # ì‹œë„ë³„ AUC ì ìˆ˜
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. ì‹œë„ë³„ ì ìˆ˜ ë³€í™”
    trial_numbers = [trial.number for trial in study.trials if trial.value is not None]
    trial_values = [trial.value for trial in study.trials if trial.value is not None]
    
    axes[0, 0].plot(trial_numbers, trial_values, 'o-', alpha=0.7)
    axes[0, 0].axhline(y=study.best_value, color='r', linestyle='--', alpha=0.7, label=f'Best: {study.best_value:.4f}')
    axes[0, 0].set_title('Optimization Progress')
    axes[0, 0].set_xlabel('Trial')
    axes[0, 0].set_ylabel('AUC Score')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„ (ìƒìœ„ íŒŒë¼ë¯¸í„°ë“¤)
    if len(study.trials) > 10:
        try:
            importance = optuna.importance.get_param_importances(study)
            params = list(importance.keys())[:6]  # ìƒìœ„ 6ê°œ
            values = [importance[param] for param in params]
            
            axes[0, 1].barh(params, values)
            axes[0, 1].set_title('Parameter Importance')
            axes[0, 1].set_xlabel('Importance')
        except:
            axes[0, 1].text(0.5, 0.5, 'Importance calculation failed', 
                           ha='center', va='center', transform=axes[0, 1].transAxes)
    
    # 3. sequence_length vs AUC
    seq_lengths = []
    seq_aucs = []
    for trial in study.trials:
        if trial.value is not None and 'sequence_length' in trial.params:
            seq_lengths.append(trial.params['sequence_length'])
            seq_aucs.append(trial.value)
    
    if seq_lengths:
        axes[1, 0].scatter(seq_lengths, seq_aucs, alpha=0.6)
        axes[1, 0].set_title('Sequence Length vs AUC')
        axes[1, 0].set_xlabel('Sequence Length')
        axes[1, 0].set_ylabel('AUC Score')
        axes[1, 0].grid(True, alpha=0.3)
    
    # 4. learning_rate vs AUC
    lrs = []
    lr_aucs = []
    for trial in study.trials:
        if trial.value is not None and 'lr' in trial.params:
            lrs.append(trial.params['lr'])
            lr_aucs.append(trial.value)
    
    if lrs:
        axes[1, 1].scatter(lrs, lr_aucs, alpha=0.6)
        axes[1, 1].set_xscale('log')
        axes[1, 1].set_title('Learning Rate vs AUC')
        axes[1, 1].set_xlabel('Learning Rate')
        axes[1, 1].set_ylabel('AUC Score')
        axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# ìµœì í™” ì‹¤í–‰ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì ì ˆíˆ ì¡°ì •)
study = run_hyperparameter_optimization(n_trials=30)  # 30íšŒ ì‹œë„

# ============================================================================
# ì…€ 10: ìµœì  ëª¨ë¸ ìƒì„± ë° ì „ì²´ í•™ìŠµ
# ============================================================================

def create_and_train_best_model(study, processor):
    """ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ìƒì„± ë° ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ"""
    print("ğŸ† ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ")
    print("=" * 50)
    
    best_params = study.best_params
    print("ğŸ“‹ ì‚¬ìš©í•  ìµœì  íŒŒë¼ë¯¸í„°:")
    for key, value in best_params.items():
        print(f"   {key}: {value}")
    
    # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±
    X, y, employee_ids, valid_emp, total_seq = create_sequences_with_params(
        processor, best_params['sequence_length']
    )
    
    print(f"\nğŸ“Š ìµœì  ì‹œí€€ìŠ¤ ì •ë³´:")
    print(f"   ì‹œí€€ìŠ¤ ê¸¸ì´: {best_params['sequence_length']}")
    print(f"   ì´ ì‹œí€€ìŠ¤: {total_seq}ê°œ")
    print(f"   ì‹œí€€ìŠ¤ í˜•íƒœ: {X.shape}")
    
    # ë°ì´í„° ë¶„í• 
    (X_train, y_train, X_val, y_val, 
     X_test, y_test, class_weights, scaler) = prepare_data_for_optimization(X, y, employee_ids)
    
    # ìµœì  ëª¨ë¸ ìƒì„±
    input_size = len(processor.feature_columns)
    best_model = GRU_CNN_HybridModel(
        input_size=input_size,
        gru_hidden=best_params['gru_hidden'],
        cnn_filters=best_params['cnn_filters'],
        kernel_sizes=[2, 3],
        dropout=best_params['dropout']
    ).to(device)
    
    print(f"\nğŸ§  ìµœì  ëª¨ë¸ ì •ë³´:")
    print(f"   GRU Hidden: {best_params['gru_hidden']}")
    print(f"   CNN Filters: {best_params['cnn_filters']}")
    print(f"   Dropout: {best_params['dropout']}")
    print(f"   íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in best_model.parameters()):,}")
    
    # ë” ê¸´ í•™ìŠµ
    print(f"\nğŸš€ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    final_auc = train_model_for_optimization(
        best_model, X_train, y_train, X_val, y_val, class_weights,
        lr=best_params['lr'], 
        epochs=50,  # ë” ê¸´ í•™ìŠµ
        batch_size=best_params['batch_size'], 
        patience=15
    )
    
    print(f"âœ… ìµœì¢… ê²€ì¦ AUC: {final_auc:.4f}")
    
    return best_model, (X_train, y_train, X_val, y_val, X_test, y_test), scaler, best_params

# ìµœì  ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
best_model, data_splits, best_scaler, best_params = create_and_train_best_model(study, processor)

# ============================================================================
# ì…€ 11: ìµœì¢… ëª¨ë¸ í‰ê°€
# ============================================================================

def evaluate_final_model(model, data_splits, model_name="Best Hybrid Model"):
    """ìµœì¢… ëª¨ë¸ í‰ê°€"""
    X_train, y_train, X_val, y_val, X_test, y_test = data_splits
    
    model.eval()
    
    def evaluate_split(X, y, split_name):
        dataset = TensorDataset(X, y)
        loader = DataLoader(dataset, batch_size=64, shuffle=False)
        
        all_predictions = []
        all_probabilities = []
        all_labels = []
        
        with torch.no_grad():
            for batch_X, batch_y in loader:
                batch_X, batch_y = batch_X.to(device), batch_y.to(device)
                outputs = model(batch_X)
                probabilities = F.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)
                
                all_predictions.extend(predicted.cpu().numpy())
                all_probabilities.extend(probabilities[:, 1].cpu().numpy())
                all_labels.extend(batch_y.cpu().numpy())
        
        all_predictions = np.array(all_predictions)
        all_probabilities = np.array(all_probabilities)
        all_labels = np.array(all_labels)
        
        accuracy = np.mean(all_predictions == all_labels)
        try:
            auc_score = roc_auc_score(all_labels, all_probabilities)
        except:
            auc_score = 0.5
        
        print(f"\nğŸ“Š {split_name} ê²°ê³¼:")
        print(f"   ì •í™•ë„: {accuracy:.4f}")
        print(f"   AUC: {auc_score:.4f}")
        
        if split_name == "Test":
            print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
            print(classification_report(all_labels, all_predictions, target_names=['ì¬ì§', 'í‡´ì‚¬']))
            
            cm = confusion_matrix(all_labels, all_probabilities > 0.5)
            print(f"\nğŸ” í˜¼ë™ í–‰ë ¬:")
            print(cm)
        
        return {
            'accuracy': accuracy,
            'auc': auc_score,
            'predictions': all_predictions,
            'probabilities': all_probabilities,
            'labels': all_labels
        }
    
    print(f"ğŸ¯ {model_name} ìµœì¢… í‰ê°€")
    print("=" * 50)
    
    train_results = evaluate_split(X_train, y_train, "Train")
    val_results = evaluate_split(X_val, y_val, "Validation") 
    test_results = evaluate_split(X_test, y_test, "Test")
    
    return {
        'train': train_results,
        'val': val_results,
        'test': test_results
    }

# ìµœì¢… í‰ê°€ ì‹¤í–‰
final_results = evaluate_final_model(best_model, data_splits)

# ROC ê³¡ì„  ê·¸ë¦¬ê¸°
def plot_final_roc_curve(results):
    """ìµœì¢… ROC ê³¡ì„  ì‹œê°í™”"""
    plt.figure(figsize=(10, 8))
    
    for split_name, result in results.items():
        fpr, tpr, _ = roc_curve(result['labels'], result['probabilities'])
        auc_score = result['auc']
        
        plt.plot(fpr, tpr, label=f'{split_name.title()} (AUC = {auc_score:.3f})', marker='o', markersize=3)
    
    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Final Model ROC Curves')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

plot_final_roc_curve(final_results)

# ============================================================================
# ì…€ 12: ê°œë³„ ì§ì› ì˜ˆì¸¡ í•¨ìˆ˜ (ìµœì í™” ë²„ì „)
# ============================================================================

def predict_employee_with_best_model(employee_id, processor, model, scaler, best_params):
    """ìµœì í™”ëœ ëª¨ë¸ë¡œ ê°œë³„ ì§ì› ì˜ˆì¸¡"""
    
    # í•´ë‹¹ ì§ì›ì˜ ë°ì´í„° ì°¾ê¸°
    employee_data = processor.aggregated_data[
        processor.aggregated_data[processor.employee_id_col] == employee_id
    ].sort_values('time_period')
    
    sequence_length = best_params['sequence_length']
    
    if len(employee_data) < sequence_length:
        raise ValueError(f"ì§ì› {employee_id}ì˜ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                        f"ìµœì†Œ {sequence_length}{processor.aggregation_unit[0]} í•„ìš” "
                        f"(í˜„ì¬: {len(employee_data)}{processor.aggregation_unit[0]})")
    
    # ì‹œí€€ìŠ¤ ìƒì„± (ìµœê·¼ ë°ì´í„° ì‚¬ìš©)
    sequence_data = employee_data[processor.feature_columns].values[-sequence_length:]
    
    # ì •ê·œí™”
    sequence_scaled = scaler.transform(sequence_data.reshape(-1, len(processor.feature_columns)))
    sequence_scaled = sequence_scaled.reshape(1, sequence_length, -1)
    
    # PyTorch í…ì„œë¡œ ë³€í™˜
    sequence_tensor = torch.FloatTensor(sequence_scaled).to(device)
    
    # ì˜ˆì¸¡
    model.eval()
    with torch.no_grad():
        outputs = model(sequence_tensor)
        probabilities = F.softmax(outputs, dim=1)
        attrition_prob = probabilities[0, 1].item()
        prediction = torch.argmax(outputs, dim=1).item()
    
    return {
        'employee_id': employee_id,
        'attrition_probability': attrition_prob,
        'prediction': prediction,
        'risk_level': 'High' if attrition_prob > 0.7 else 'Medium' if attrition_prob > 0.3 else 'Low',
        'sequence_length_used': sequence_length
    }

# ìƒ˜í”Œ ì˜ˆì¸¡ ìˆ˜í–‰
print("\nğŸ”® ìµœì í™”ëœ ëª¨ë¸ë¡œ ìƒ˜í”Œ ì§ì› ì˜ˆì¸¡")
print("=" * 50)

sample_employees = processor.aggregated_data[processor.employee_id_col].unique()[:10]
sample_predictions = []

for emp_id in sample_employees:
    try:
        result = predict_employee_with_best_model(emp_id, processor, best_model, best_scaler, best_params)
        sample_predictions.append(result)
    except Exception as e:
        print(f"âš ï¸  ì§ì› {emp_id} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

# ê²°ê³¼ ì¶œë ¥
if sample_predictions:
    predictions_df = pd.DataFrame(sample_predictions)
    print("\nğŸ“‹ ìƒ˜í”Œ ì§ì› ì˜ˆì¸¡ ê²°ê³¼:")
    print(predictions_df.sort_values('attrition_probability', ascending=False))
    
    risk_dist = predictions_df['risk_level'].value_counts()
    print(f"\nğŸ“Š ìœ„í—˜ë„ ë¶„í¬:")
    for risk, count in risk_dist.items():
        print(f"   {risk}: {count}ëª… ({count/len(predictions_df)*100:.1f}%)")

# ============================================================================
# ì…€ 13: ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ë° ì‹œê°í™”
# ============================================================================

from sklearn.metrics import precision_recall_curve, f1_score, precision_score, recall_score
from sklearn.metrics import average_precision_score, matthews_corrcoef

def detailed_performance_analysis(results, model_name="Best Hybrid Model"):
    """ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ë° ì‹œê°í™”"""
    
    print(f"ğŸ¯ {model_name} ìƒì„¸ ì„±ëŠ¥ ë¶„ì„")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²°ê³¼ ì‚¬ìš©
    test_results = results['test']
    y_true = test_results['labels']
    y_pred = test_results['predictions'] 
    y_prob = test_results['probabilities']
    
    # 1. ê¸°ë³¸ ë¶„ë¥˜ ë©”íŠ¸ë¦­ ê³„ì‚°
    accuracy = test_results['accuracy']
    auc_score = test_results['auc']
    f1 = f1_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    
    # íŠ¹ì´ë„ (Specificity) ê³„ì‚°
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    
    # Matthews Correlation Coefficient
    mcc = matthews_corrcoef(y_true, y_pred)
    
    # Average Precision Score
    avg_precision = average_precision_score(y_true, y_prob)
    
    print("ğŸ“Š ì¢…í•© ì„±ëŠ¥ ì§€í‘œ:")
    print(f"   ğŸ¯ Accuracy:     {accuracy:.4f}")
    print(f"   ğŸš€ AUC Score:    {auc_score:.4f}")
    print(f"   âš–ï¸  F1-Score:     {f1:.4f}")
    print(f"   ğŸ“ Precision:    {precision:.4f}")
    print(f"   ğŸ” Recall:       {recall:.4f}")
    print(f"   ğŸ›¡ï¸  Specificity:  {specificity:.4f}")
    print(f"   ğŸ”— MCC:          {mcc:.4f}")
    print(f"   ğŸ“ˆ Avg Precision: {avg_precision:.4f}")
    
    # 2. í˜¼ë™ í–‰ë ¬ ìƒì„¸ ë¶„ì„
    cm = confusion_matrix(y_true, y_pred)
    print(f"\nğŸ” í˜¼ë™ í–‰ë ¬ ìƒì„¸ ë¶„ì„:")
    print(f"   True Negative (TN):  {tn:4d} - ì¬ì§ ì˜ˆì¸¡ì´ ë§ì€ ê²½ìš°")
    print(f"   False Positive (FP): {fp:4d} - í‡´ì‚¬ ì˜ˆì¸¡í–ˆì§€ë§Œ ì‹¤ì œ ì¬ì§")
    print(f"   False Negative (FN): {fn:4d} - ì¬ì§ ì˜ˆì¸¡í–ˆì§€ë§Œ ì‹¤ì œ í‡´ì‚¬")
    print(f"   True Positive (TP):  {tp:4d} - í‡´ì‚¬ ì˜ˆì¸¡ì´ ë§ì€ ê²½ìš°")
    
    # 3. ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í•´ì„
    total_employees = len(y_true)
    actual_attrition = np.sum(y_true)
    predicted_attrition = np.sum(y_pred)
    
    print(f"\nğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í•´ì„:")
    print(f"   ğŸ“Š ì „ì²´ ì§ì› ìˆ˜:        {total_employees:4d}ëª…")
    print(f"   ğŸ“‰ ì‹¤ì œ í‡´ì‚¬ì:         {actual_attrition:4d}ëª… ({actual_attrition/total_employees*100:.1f}%)")
    print(f"   ğŸ¯ ì˜ˆì¸¡ í‡´ì‚¬ì:         {predicted_attrition:4d}ëª… ({predicted_attrition/total_employees*100:.1f}%)")
    print(f"   âœ… í‡´ì‚¬ ì •í™• ì˜ˆì¸¡:      {tp:4d}ëª… (ì‹¤ì œ í‡´ì‚¬ì ì¤‘ {tp/actual_attrition*100:.1f}%)")
    print(f"   âŒ í‡´ì‚¬ ë†“ì¹œ ê²½ìš°:      {fn:4d}ëª… (ì‹¤ì œ í‡´ì‚¬ì ì¤‘ {fn/actual_attrition*100:.1f}%)")
    print(f"   âš ï¸  ì˜ëª»ëœ í‡´ì‚¬ ì˜ˆì¸¡:   {fp:4d}ëª… (ì¬ì§ì ì¤‘ {fp/(total_employees-actual_attrition)*100:.1f}%)")
    
    return {
        'accuracy': accuracy, 'auc': auc_score, 'f1': f1, 'precision': precision,
        'recall': recall, 'specificity': specificity, 'mcc': mcc, 'avg_precision': avg_precision,
        'confusion_matrix': cm, 'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp
    }

def plot_detailed_performance(results, metrics_dict):
    """ìƒì„¸ ì„±ëŠ¥ ì‹œê°í™”"""
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    test_results = results['test']
    y_true = test_results['labels']
    y_pred = test_results['predictions']
    y_prob = test_results['probabilities']
    cm = metrics_dict['confusion_matrix']
    
    # 1. í˜¼ë™ í–‰ë ¬ íˆíŠ¸ë§µ
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['ì¬ì§', 'í‡´ì‚¬'], yticklabels=['ì¬ì§', 'í‡´ì‚¬'],
                ax=axes[0, 0])
    axes[0, 0].set_title('Confusion Matrix')
    axes[0, 0].set_xlabel('Predicted Label')
    axes[0, 0].set_ylabel('True Label')
    
    # 2. ì •ê·œí™”ëœ í˜¼ë™ í–‰ë ¬
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',
                xticklabels=['ì¬ì§', 'í‡´ì‚¬'], yticklabels=['ì¬ì§', 'í‡´ì‚¬'],
                ax=axes[0, 1])
    axes[0, 1].set_title('Normalized Confusion Matrix')
    axes[0, 1].set_xlabel('Predicted Label')
    axes[0, 1].set_ylabel('True Label')
    
    # 3. ROC ê³¡ì„  (ëª¨ë“  split)
    for split_name, result in results.items():
        fpr, tpr, _ = roc_curve(result['labels'], result['probabilities'])
        auc_score = result['auc']
        axes[0, 2].plot(fpr, tpr, label=f'{split_name.title()} (AUC={auc_score:.3f})', marker='o', markersize=3)
    
    axes[0, 2].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')
    axes[0, 2].set_xlabel('False Positive Rate')
    axes[0, 2].set_ylabel('True Positive Rate')
    axes[0, 2].set_title('ROC Curves')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)
    
    # 4. Precision-Recall ê³¡ì„ 
    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)
    avg_precision = average_precision_score(y_true, y_prob)
    
    axes[1, 0].plot(recall, precision, marker='o', markersize=3, 
                    label=f'AP={avg_precision:.3f}')
    axes[1, 0].set_xlabel('Recall')
    axes[1, 0].set_ylabel('Precision')
    axes[1, 0].set_title('Precision-Recall Curve')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # 5. ì„ê³„ê°’ë³„ ì„±ëŠ¥ ë³€í™”
    thresholds_range = np.arange(0.1, 1.0, 0.05)
    f1_scores = []
    precisions = []
    recalls = []
    
    for threshold in thresholds_range:
        y_pred_thresh = (y_prob >= threshold).astype(int)
        f1_scores.append(f1_score(y_true, y_pred_thresh))
        precisions.append(precision_score(y_true, y_pred_thresh))
        recalls.append(recall_score(y_true, y_pred_thresh))
    
    axes[1, 1].plot(thresholds_range, f1_scores, 'o-', label='F1-Score', markersize=3)
    axes[1, 1].plot(thresholds_range, precisions, 's-', label='Precision', markersize=3)
    axes[1, 1].plot(thresholds_range, recalls, '^-', label='Recall', markersize=3)
    axes[1, 1].axvline(x=0.5, color='r', linestyle='--', alpha=0.7, label='Default (0.5)')
    axes[1, 1].set_xlabel('Threshold')
    axes[1, 1].set_ylabel('Score')
    axes[1, 1].set_title('Performance vs Threshold')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    # 6. ë©”íŠ¸ë¦­ ìš”ì•½ ë°” ì°¨íŠ¸
    metric_names = ['Accuracy', 'F1-Score', 'Precision', 'Recall', 'Specificity', 'AUC']
    metric_values = [
        metrics_dict['accuracy'], metrics_dict['f1'], metrics_dict['precision'],
        metrics_dict['recall'], metrics_dict['specificity'], metrics_dict['auc']
    ]
    
    bars = axes[1, 2].bar(metric_names, metric_values, alpha=0.7, 
                         color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral', 'gold'])
    axes[1, 2].set_title('Performance Metrics Summary')
    axes[1, 2].set_ylabel('Score')
    axes[1, 2].set_ylim(0, 1)
    
    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bar, value in zip(bars, metric_values):
        axes[1, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{value:.3f}', ha='center', va='bottom')
    
    # xì¶• ë ˆì´ë¸” íšŒì „
    axes[1, 2].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.show()

def find_optimal_threshold(y_true, y_prob):
    """ìµœì  ì„ê³„ê°’ ì°¾ê¸°"""
    print("\nğŸ¯ ìµœì  ì„ê³„ê°’ ë¶„ì„")
    print("=" * 40)
    
    thresholds_range = np.arange(0.1, 0.95, 0.05)
    best_f1 = 0
    best_threshold = 0.5
    
    print("Threshold  F1-Score  Precision  Recall   Specificity")
    print("-" * 55)
    
    for threshold in thresholds_range:
        y_pred_thresh = (y_prob >= threshold).astype(int)
        
        f1 = f1_score(y_true, y_pred_thresh)
        precision = precision_score(y_true, y_pred_thresh)
        recall = recall_score(y_true, y_pred_thresh)
        
        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_thresh).ravel()
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        print(f"  {threshold:.2f}      {f1:.3f}     {precision:.3f}      {recall:.3f}      {specificity:.3f}")
        
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = threshold
    
    print("-" * 55)
    print(f"ğŸ† ìµœì  ì„ê³„ê°’: {best_threshold:.2f} (F1-Score: {best_f1:.3f})")
    
    return best_threshold, best_f1

def business_impact_analysis(metrics_dict):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„"""
    print("\nğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„")
    print("=" * 40)
    
    tp, fp, fn, tn = metrics_dict['tp'], metrics_dict['fp'], metrics_dict['fn'], metrics_dict['tn']
    
    # ê°€ì •: í‡´ì‚¬ì 1ëª…ë‹¹ ëŒ€ì²´ ë¹„ìš© (ì„ì˜ ì„¤ì •)
    replacement_cost = 50000  # 50,000 ë‹¬ëŸ¬
    intervention_cost = 5000   # 5,000 ë‹¬ëŸ¬ (ì˜ˆë°© ì¡°ì¹˜ ë¹„ìš©)
    
    # ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
    print("ğŸ“Š ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„:")
    print(f"   ê°€ì • - í‡´ì‚¬ì ëŒ€ì²´ ë¹„ìš©: ${replacement_cost:,}")
    print(f"   ê°€ì • - ì˜ˆë°© ì¡°ì¹˜ ë¹„ìš©: ${intervention_cost:,}")
    print()
    
    # ëª¨ë¸ ì—†ì´ (ì•„ë¬´ ì¡°ì¹˜ ì—†ìŒ)
    cost_without_model = (tp + fn) * replacement_cost
    
    # ëª¨ë¸ ì‚¬ìš©ì‹œ
    cost_with_model = (
        fn * replacement_cost +  # ë†“ì¹œ í‡´ì‚¬ìë“¤
        (tp + fp) * intervention_cost  # ì˜ˆë°© ì¡°ì¹˜ ëŒ€ìƒë“¤
    )
    
    savings = cost_without_model - cost_with_model
    roi = (savings / (cost_with_model if cost_with_model > 0 else 1)) * 100
    
    print(f"ğŸ’° ë¹„ìš© ë¶„ì„:")
    print(f"   ëª¨ë¸ ë¯¸ì‚¬ìš©ì‹œ ë¹„ìš©:  ${cost_without_model:,}")
    print(f"   ëª¨ë¸ ì‚¬ìš©ì‹œ ë¹„ìš©:    ${cost_with_model:,}")
    print(f"   ì ˆì•½ ë¹„ìš©:          ${savings:,}")
    print(f"   ROI:               {roi:.1f}%")
    print()
    
    print(f"ğŸ“ˆ íš¨ê³¼ì„± ë¶„ì„:")
    print(f"   ì˜ˆë°© ê°€ëŠ¥í•œ í‡´ì‚¬:    {tp}ëª… / {tp + fn}ëª… ({tp/(tp+fn)*100:.1f}%)")
    print(f"   ë¶ˆí•„ìš”í•œ ê°œì…:       {fp}ëª… (ë¹„ìš© ì†ì‹¤: ${fp * intervention_cost:,})")
    print(f"   ë†“ì¹œ í‡´ì‚¬ì:        {fn}ëª… (ë¹„ìš© ì†ì‹¤: ${fn * replacement_cost:,})")

# ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰
detailed_metrics = detailed_performance_analysis(final_results)

# ì‹œê°í™” ì‹¤í–‰
plot_detailed_performance(final_results, detailed_metrics)

# ìµœì  ì„ê³„ê°’ ì°¾ê¸°
optimal_threshold, optimal_f1 = find_optimal_threshold(
    final_results['test']['labels'], 
    final_results['test']['probabilities']
)

# ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„
business_impact_analysis(detailed_metrics)

# ============================================================================
# ì…€ 14: ìµœì í™” ê²°ê³¼ ì €ì¥ ë° ìµœì¢… ìš”ì•½
# ============================================================================

def save_optimization_results(study, best_model, best_params, processor, scaler, detailed_metrics, save_dir='optimized_models'):
    """ìµœì í™” ê²°ê³¼ ë° ìƒì„¸ ì„±ëŠ¥ ì €ì¥"""
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"ğŸ’¾ ìµœì í™” ê²°ê³¼ ì €ì¥ ì¤‘... (ê²½ë¡œ: {save_dir})")
    
    # ëª¨ë¸ ì €ì¥
    model_path = os.path.join(save_dir, 'best_hybrid_model.pth')
    torch.save(best_model.state_dict(), model_path)
    print(f"   âœ… ìµœì  ëª¨ë¸ ì €ì¥: {model_path}")
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    params_path = os.path.join(save_dir, 'best_params.json')
    with open(params_path, 'w') as f:
        json.dump(best_params, f, indent=2)
    print(f"   âœ… ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥: {params_path}")
    
    # ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ ì €ì¥
    performance_path = os.path.join(save_dir, 'performance_metrics.json')
    # numpy íƒ€ì…ì„ ì¼ë°˜ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    metrics_to_save = {}
    for key, value in detailed_metrics.items():
        if isinstance(value, np.ndarray):
            metrics_to_save[key] = value.tolist()
        elif isinstance(value, (np.integer, np.floating)):
            metrics_to_save[key] = float(value)
        else:
            metrics_to_save[key] = value
    
    with open(performance_path, 'w') as f:
        json.dump(metrics_to_save, f, indent=2)
    print(f"   âœ… ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ ì €ì¥: {performance_path}")
    
    # ìŠ¤í„°ë”” ì €ì¥
    study_path = os.path.join(save_dir, 'optimization_study.pkl')
    import pickle
    with open(study_path, 'wb') as f:
        pickle.dump(study, f)
    print(f"   âœ… ìµœì í™” ìŠ¤í„°ë”” ì €ì¥: {study_path}")
    
    # í”„ë¡œì„¸ì„œ ì •ë³´ ì €ì¥
    processor_info = {
        'scaler': scaler,
        'feature_columns': processor.feature_columns,
        'sequence_length': best_params['sequence_length'],
        'aggregation_unit': best_params.get('aggregation_unit', processor.aggregation_unit),
        'employee_id_col': processor.employee_id_col,
        'date_column': processor.date_column,
        'excluded_ratio_columns': processor.excluded_ratio_columns
    }
    
    processor_path = os.path.join(save_dir, 'processor_info.pkl')
    with open(processor_path, 'wb') as f:
        pickle.dump(processor_info, f)
    print(f"   âœ… í”„ë¡œì„¸ì„œ ì •ë³´ ì €ì¥: {processor_path}")
    
    # ëª¨ë¸ ì‚¬ìš© ê°€ì´ë“œ ìƒì„±
    guide_path = os.path.join(save_dir, 'model_usage_guide.md')
    create_usage_guide(guide_path, best_params, detailed_metrics)
    print(f"   âœ… ì‚¬ìš© ê°€ì´ë“œ ì €ì¥: {guide_path}")
    
    print("ğŸ’¾ ì €ì¥ ì™„ë£Œ!")

def create_usage_guide(file_path, best_params, metrics):
    """ëª¨ë¸ ì‚¬ìš© ê°€ì´ë“œ ìƒì„±"""
    guide_content = f"""# ì§ì› í‡´ì‚¬ ì˜ˆì¸¡ ëª¨ë¸ ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½
- **AUC Score**: {metrics['auc']:.4f}
- **F1-Score**: {metrics['f1']:.4f}
- **Precision**: {metrics['precision']:.4f}
- **Recall**: {metrics['recall']:.4f}
- **Accuracy**: {metrics['accuracy']:.4f}

## ğŸ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°
- **Sequence Length**: {best_params['sequence_length']}
- **Aggregation Unit**: {best_params.get('aggregation_unit', 'week')}
- **GRU Hidden**: {best_params['gru_hidden']}
- **CNN Filters**: {best_params['cnn_filters']}
- **Dropout**: {best_params['dropout']:.3f}
- **Learning Rate**: {best_params['lr']:.2e}
- **Batch Size**: {best_params['batch_size']}

## ğŸ” ëª¨ë¸ í•´ì„
### Confusion Matrix
- True Negative: {metrics['tn']} (ì¬ì§ ì •í™• ì˜ˆì¸¡)
- False Positive: {metrics['fp']} (í‡´ì‚¬ ì˜¤ì˜ˆì¸¡)
- False Negative: {metrics['fn']} (í‡´ì‚¬ ë†“ì¹¨)
- True Positive: {metrics['tp']} (í‡´ì‚¬ ì •í™• ì˜ˆì¸¡)

### ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸
- **í‡´ì‚¬ ê°ì§€ìœ¨**: {metrics['tp']/(metrics['tp']+metrics['fn'])*100:.1f}% (ì‹¤ì œ í‡´ì‚¬ì ì¤‘ ëª¨ë¸ì´ ê°ì§€í•œ ë¹„ìœ¨)
- **ì˜¤íƒë¥ **: {metrics['fp']/(metrics['fp']+metrics['tn'])*100:.1f}% (ì¬ì§ì ì¤‘ í‡´ì‚¬ë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ë¹„ìœ¨)

## ğŸ’¼ ì‹¤ì „ í™œìš© ë°©ë²•

### 1. ìœ„í—˜ë„ ê¸°ì¤€
- **High Risk (0.7~1.0)**: ì¦‰ì‹œ ë©´ë‹´ ë° ê°œì… í•„ìš”
- **Medium Risk (0.3~0.7)**: ì£¼ì˜ ê´€ì°° ë° ëª¨ë‹ˆí„°ë§
- **Low Risk (0.0~0.3)**: ì•ˆì • ìƒíƒœ

### 2. ì£¼ê¸°ì  ëª¨ë‹ˆí„°ë§
- ë§¤ì£¼ ëª¨ë“  ì§ì›ì˜ í‡´ì‚¬ í™•ë¥  ê³„ì‚°
- ìœ„í—˜ë„ ë³€í™” ì¶”ì´ ê´€ì°°
- ì„ê³„ê°’ ì´ìƒ ì§ì›ì— ëŒ€í•œ ì„ ì œì  ì¡°ì¹˜

### 3. ëª¨ë¸ í™œìš© íŒ
- ë‹¨ì¼ ì˜ˆì¸¡ë³´ë‹¤ëŠ” ì¶”ì„¸ ë³€í™”ì— ì£¼ëª©
- ë‹¤ë¥¸ HR ì§€í‘œì™€ í•¨ê»˜ ì¢…í•© íŒë‹¨
- ì •ê¸°ì ì¸ ëª¨ë¸ ì¬í•™ìŠµ ê¶Œì¥ (ë¶„ê¸°ë³„)

## ğŸš€ ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡ ì½”ë“œ ì˜ˆì‹œ
```python
import torch
import pickle

# ëª¨ë¸ ë¡œë”©
model = GRU_CNN_HybridModel(input_size, **best_params)
model.load_state_dict(torch.load('best_hybrid_model.pth'))
model.eval()

# í”„ë¡œì„¸ì„œ ë¡œë”©
with open('processor_info.pkl', 'rb') as f:
    processor_info = pickle.load(f)

# ì˜ˆì¸¡ ìˆ˜í–‰
result = predict_employee_with_best_model(
    employee_id, processor, model, scaler, best_params
)
print(f"í‡´ì‚¬ í™•ë¥ : {{result['attrition_probability']:.3f}}")"""
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(guide_content)

print("ğŸ¯ ìµœì í™”ëœ ëª¨ë¸ë¡œ ìƒ˜í”Œ ì§ì› ì˜ˆì¸¡")
print("=" * 50)

sample_employees = processor.aggregated_data[processor.employee_id_col].unique()[:10]
sample_predictions = []

for emp_id in sample_employees:
    try:
        result = predict_employee_with_best_model(emp_id, processor, best_model, best_scaler, best_params)
        sample_predictions.append(result)
    except Exception as e:
        print(f"âš ï¸  ì§ì› {emp_id} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

# ê²°ê³¼ ì¶œë ¥
if sample_predictions:
    predictions_df = pd.DataFrame(sample_predictions)
    print("\nğŸ“‹ ìƒ˜í”Œ ì§ì› ì˜ˆì¸¡ ê²°ê³¼:")
    print(predictions_df.sort_values('attrition_probability', ascending=False))
    
    risk_dist = predictions_df['risk_level'].value_counts()
    print(f"\nğŸ“Š ìœ„í—˜ë„ ë¶„í¬:")
    for risk, count in risk_dist.items():
        print(f"   {risk}: {count}ëª… ({count/len(predictions_df)*100:.1f}%)")

# ============================================================================
# ì…€ 15: ì „ì²´ ì§ì› ì‹œê³„ì—´ ì˜ˆì¸¡ ë° ê²°ê³¼ ì €ì¥
# ============================================================================

def predict_all_employees_and_save(processor, model, scaler, best_params, save_path='Data analysis/data/employee_attrition_predictions.csv'):
    """ì „ì²´ ì§ì›ì— ëŒ€í•œ ì‹œê³„ì—´ ì˜ˆì¸¡ ìˆ˜í–‰ ë° CSV ì €ì¥"""
    print("ğŸ”® ì „ì²´ 1470ëª… ì§ì› ì‹œê³„ì—´ ì˜ˆì¸¡ ìˆ˜í–‰")
    print("=" * 50)
    
    # ì „ì²´ ì§ì› ID ê°€ì ¸ì˜¤ê¸° (ì‹œê³„ì—´ ë°ì´í„°ì™€ ì§ì› ì†ì„± ë°ì´í„° ëª¨ë‘ì—ì„œ)
    timeseries_employees = set(processor.aggregated_data[processor.employee_id_col].unique())
    personas_employees = set(processor.personas_data[processor.personas_id_col].unique())
    
    # ë‘ ë°ì´í„°ì…‹ì— ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ì§ì›ë“¤
    common_employees = timeseries_employees.intersection(personas_employees)
    
    # ì‹œê³„ì—´ ë°ì´í„°ì—ë§Œ ìˆëŠ” ì§ì›ë“¤ (ì†ì„± ì •ë³´ ì—†ìŒ)
    timeseries_only = timeseries_employees - personas_employees
    
    # ì†ì„± ë°ì´í„°ì—ë§Œ ìˆëŠ” ì§ì›ë“¤ (ì‹œê³„ì—´ ì •ë³´ ì—†ìŒ)
    personas_only = personas_employees - timeseries_employees
    
    print(f"ğŸ“Š ë°ì´í„° í˜„í™©:")
    print(f"   ì‹œê³„ì—´ ë°ì´í„° ì§ì› ìˆ˜: {len(timeseries_employees)}ëª…")
    print(f"   ì†ì„± ë°ì´í„° ì§ì› ìˆ˜: {len(personas_employees)}ëª…")
    print(f"   ê³µí†µ ì§ì› ìˆ˜: {len(common_employees)}ëª…")
    print(f"   ì‹œê³„ì—´ë§Œ ìˆëŠ” ì§ì›: {len(timeseries_only)}ëª…")
    print(f"   ì†ì„±ë§Œ ìˆëŠ” ì§ì›: {len(personas_only)}ëª…")
    
    # ì „ì²´ ì§ì› ë¦¬ìŠ¤íŠ¸ (ëª¨ë“  ì§ì› í¬í•¨ - 1470ëª… ëª©í‘œ)
    all_employees = list(timeseries_employees.union(personas_employees))
    print(f"ğŸ“Š ì˜ˆì¸¡ ëŒ€ìƒ ì´ ì§ì› ìˆ˜: {len(all_employees)}ëª…")
    
    if len(all_employees) >= 1470:
        print(f"âœ… ëª©í‘œ 1470ëª… ë‹¬ì„±! (ì‹¤ì œ: {len(all_employees)}ëª…)")
    else:
        print(f"âš ï¸  ëª©í‘œ 1470ëª… ë¯¸ë‹¬ (ì‹¤ì œ: {len(all_employees)}ëª…)")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    all_predictions = []
    successful_predictions = 0
    failed_predictions = 0
    
    print("ğŸš€ ì˜ˆì¸¡ ì§„í–‰ ì¤‘...")
    
    # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ tqdm ì‚¬ìš©
    for i, emp_id in enumerate(tqdm(all_employees, desc="ì§ì›ë³„ ì˜ˆì¸¡")):
        try:
            # ì‹œê³„ì—´ ë°ì´í„°ê°€ ìˆëŠ” ì§ì›ì¸ì§€ í™•ì¸
            if emp_id in timeseries_employees:
                # ê°œë³„ ì§ì› ì˜ˆì¸¡ ìˆ˜í–‰ (ì‹œê³„ì—´ ê¸°ë°˜ ì˜ˆì¸¡)
                result = predict_employee_with_best_model(emp_id, processor, model, scaler, best_params)
                result['prediction_method'] = 'Timeseries Model'
                all_predictions.append(result)
                successful_predictions += 1
            else:
                # ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì†ì„± ë°ì´í„°ë§Œìœ¼ë¡œ ì²˜ë¦¬
                raise ValueError(f"ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ì–´ ì†ì„± ê¸°ë°˜ ì˜ˆì¸¡ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            
        except Exception as e:
            # ì˜ˆì¸¡ ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì €ì¥
            # ì†ì„± ë°ì´í„°ì—ì„œ ì‹¤ì œ attrition ì •ë³´ê°€ ìˆë‹¤ë©´ ì‚¬ìš©
            actual_attrition = None
            if emp_id in personas_employees:
                try:
                    persona_row = processor.personas_data[processor.personas_data[processor.personas_id_col] == emp_id]
                    if not persona_row.empty and 'attrition_binary' in persona_row.columns:
                        actual_attrition = persona_row['attrition_binary'].iloc[0]
                except:
                    pass
            
            # ì˜ˆì¸¡ ë°©ë²• ê²°ì •
            if emp_id not in timeseries_employees and emp_id in personas_employees:
                prediction_method = 'Attribute-based (No timeseries)'
                prediction_status = 'Success - Attribute only'
            else:
                prediction_method = 'Failed'
                prediction_status = 'Failed - Prediction error'
            
            failed_result = {
                'employee_id': emp_id,
                'attrition_probability': 0.5 if actual_attrition is None else float(actual_attrition),  # ë¶ˆí™•ì‹¤í•œ ê²½ìš° 0.5
                'prediction': 0 if actual_attrition is None else int(actual_attrition),  # ì‹¤ì œ ê°’ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                'risk_level': 'Unknown' if actual_attrition is None else ('High' if actual_attrition == 1 else 'Low'),
                'sequence_length_used': best_params['sequence_length'] if emp_id in timeseries_employees else 0,
                'prediction_method': prediction_method,
                'prediction_status': prediction_status,
                'error_message': str(e) if prediction_status.startswith('Failed') else 'No timeseries data available'
            }
            all_predictions.append(failed_result)
            failed_predictions += 1
    
    print(f"\nğŸ“Š ì˜ˆì¸¡ ì™„ë£Œ ìš”ì•½:")
    print(f"   âœ… ì„±ê³µ: {successful_predictions}ëª…")
    print(f"   âŒ ì‹¤íŒ¨: {failed_predictions}ëª…")
    print(f"   ğŸ“ˆ ì„±ê³µë¥ : {successful_predictions/len(all_employees)*100:.1f}%")
    
    # DataFrameìœ¼ë¡œ ë³€í™˜
    predictions_df = pd.DataFrame(all_predictions)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
    column_order = ['employee_id', 'attrition_probability', 'prediction', 'risk_level', 
                   'sequence_length_used', 'prediction_method']
    
    # ì¶”ê°€ ì •ë³´ ì»¬ëŸ¼ í¬í•¨
    column_order.extend(['prediction_status', 'error_message'])
    predictions_df['prediction_method'] = predictions_df.get('prediction_method', 'Timeseries Model')
    predictions_df['prediction_status'] = predictions_df.get('prediction_status', 'Success')
    predictions_df['error_message'] = predictions_df.get('error_message', '')
    
    predictions_df = predictions_df[column_order]
    
    # í‡´ì‚¬ í™•ë¥  ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    predictions_df = predictions_df.sort_values('attrition_probability', ascending=False)
    
    # CSV íŒŒì¼ë¡œ ì €ì¥
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    predictions_df.to_csv(save_path, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path}")
    print(f"   ğŸ“„ ì €ì¥ëœ ë ˆì½”ë“œ ìˆ˜: {len(predictions_df)}ê°œ")
    
    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print(f"\nğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
    
    # ì„±ê³µí•œ ì˜ˆì¸¡ë§Œìœ¼ë¡œ í†µê³„ ê³„ì‚°
    successful_df = predictions_df[predictions_df.get('prediction_status', 'Success') == 'Success']
    
    if len(successful_df) > 0:
        print(f"   í‰ê·  í‡´ì‚¬ í™•ë¥ : {successful_df['attrition_probability'].mean():.3f}")
        print(f"   ìµœê³  í‡´ì‚¬ í™•ë¥ : {successful_df['attrition_probability'].max():.3f}")
        print(f"   ìµœì € í‡´ì‚¬ í™•ë¥ : {successful_df['attrition_probability'].min():.3f}")
        
        # ìœ„í—˜ë„ë³„ ë¶„í¬
        risk_dist = successful_df['risk_level'].value_counts()
        print(f"\nğŸ¯ ìœ„í—˜ë„ë³„ ë¶„í¬:")
        for risk, count in risk_dist.items():
            if risk != 'Unknown':
                print(f"   {risk}: {count}ëª… ({count/len(successful_df)*100:.1f}%)")
        
        # ìƒìœ„ 10ëª… ì¶œë ¥
        print(f"\nğŸš¨ í‡´ì‚¬ ìœ„í—˜ ìƒìœ„ 10ëª…:")
        top_10 = successful_df.head(10)[['employee_id', 'attrition_probability', 'risk_level']]
        for idx, row in top_10.iterrows():
            print(f"   ì§ì› {row['employee_id']}: {row['attrition_probability']:.3f} ({row['risk_level']})")
    
    return predictions_df

# ì „ì²´ ì§ì› ì˜ˆì¸¡ ì‹¤í–‰ ë° ì €ì¥
print("\n" + "="*70)
print("ğŸ¯ ì „ì²´ ì§ì› ì‹œê³„ì—´ ì˜ˆì¸¡ ë° ê²°ê³¼ ì €ì¥ ì‹œì‘")
print("="*70)

# ë³€ìˆ˜ ì¡´ì¬ í™•ì¸
print("ğŸ” ë³€ìˆ˜ ì¡´ì¬ í™•ì¸:")
print(f"   processor ì¡´ì¬: {'processor' in locals()}")
print(f"   best_model ì¡´ì¬: {'best_model' in locals()}")
print(f"   best_scaler ì¡´ì¬: {'best_scaler' in locals()}")
print(f"   best_params ì¡´ì¬: {'best_params' in locals()}")

try:
    final_predictions_df = predict_all_employees_and_save(
        processor, 
        best_model, 
        best_scaler, 
        best_params,
        save_path='Data analysis/data/employee_attrition_predictions.csv'
    )
except Exception as e:
    print(f"âŒ ì˜ˆì¸¡ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
    import traceback
    traceback.print_exc()
    final_predictions_df = None

if final_predictions_df is not None:
    print(f"\nğŸ‰ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
    print(f"   ğŸ“Š ì´ {len(final_predictions_df)}ëª…ì˜ ì§ì› ì˜ˆì¸¡ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: Data analysis/data/employee_attrition_predictions.csv")
else:
    print(f"\nâŒ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨!")
    print(f"   ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")