{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e07601",
   "metadata": {},
   "source": [
    "Cell 1: Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c3f68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# === 1) Imports & Config ===\n",
    "# All code comments are in English.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ---- File paths (change to your local files if needed) ----\n",
    "DATA_TS = Path(\"../data/IBM_HR_timeseries.csv\")\n",
    "DATA_PERSONA = Path(\"../data/IBM_HR_personas_assigned.csv\")\n",
    "\n",
    "# ---- Columns to EXCLUDE from modeling (user-specified) ----\n",
    "EXCLUDED_COLS = {\n",
    "    \"focused_ratio\",\n",
    "    \"meeting_collaboration_ratio\",\n",
    "    \"social_dining_ratio\",\n",
    "    \"break_relaxation_ratio\",\n",
    "    \"shared_work_ratio\",\n",
    "}\n",
    "\n",
    "# ---- Reproducibility ----\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "# ---- Device ----\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1bd2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected columns: emp_col_ts='employee_id', emp_col_persona='EmployeeNumber', date_col='date', attr_col='Attrition'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsjon\\AppData\\Local\\Temp\\ipykernel_24016\\3509783793.py:67: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  ts[date_col] = pd.to_datetime(ts[date_col], errors='coerce', infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numeric features (excluded specified ratio columns):\n",
      "['day_of_week', 'day_index', 'work_focused_ratio', 'system_login_hours', 'work_focused_hours', 'meeting_collaboration_hours', 'social_dining_hours', 'break_relaxation_hours', 'shared_work_hours', 'internal_comm_volume', 'cafeteria_usage', 'convenience_food_usage']\n",
      "Final tensor (N, T, F): (1470, 24, 12)\n",
      "Class balance: {0: 1233, 1: 237}\n"
     ]
    }
   ],
   "source": [
    "# === 2) Preprocessing: build monthly panel (2023-01..2024-12) → tensor (N, T=24, F) & labels ===\n",
    "\n",
    "def detect_date_col(df: pd.DataFrame) -> str:\n",
    "    # Pick common names first; else a mostly-parsable datetime column\n",
    "    common = {'date','record_date','timestamp','dt','day','month','period'}\n",
    "    for c in df.columns:\n",
    "        if c.lower() in common: \n",
    "            return c\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            p = pd.to_datetime(df[c], errors='coerce', infer_datetime_format=True)\n",
    "            if p.notna().mean() > 0.7:\n",
    "                return c\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise ValueError(\"No date-like column found.\")\n",
    "\n",
    "def detect_emp_id(df: pd.DataFrame) -> str:\n",
    "    # Regex on common employee id names\n",
    "    pats = r'(^employee[_\\s-]*id$)|(^emp.*id$)|(^employeenumber$)|(^worker[_-]*id$)'\n",
    "    for c in df.columns:\n",
    "        if re.search(pats, c, flags=re.I):\n",
    "            return c\n",
    "    # Fallback: reasonable cardinality\n",
    "    nun = df.nunique(dropna=False)\n",
    "    candidates = nun[(nun>10) & (nun < max(11, len(df)//2))].index.tolist()\n",
    "    return candidates[0] if candidates else df.columns[0]\n",
    "\n",
    "def to_binary_attrition(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    s = str(v).strip().lower()\n",
    "    if s in (\"yes\",\"y\",\"true\",\"1\"): return 1\n",
    "    if s in (\"no\",\"n\",\"false\",\"0\"): return 0\n",
    "    try:\n",
    "        return int(float(s))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# ---- Load ----\n",
    "ts = pd.read_csv(DATA_TS)\n",
    "persona = pd.read_csv(DATA_PERSONA)\n",
    "\n",
    "# ---- Detect keys ----\n",
    "emp_col_ts = detect_emp_id(ts)\n",
    "date_col = detect_date_col(ts)\n",
    "\n",
    "# Persona: pick the column with max overlap to time-series employee ids\n",
    "ts_ids = set(ts[emp_col_ts].astype(str).unique())\n",
    "best_col, best_overlap = None, -1.0\n",
    "for c in persona.columns:\n",
    "    overlap = len(ts_ids.intersection(set(persona[c].astype(str).unique()))) / max(1, len(ts_ids))\n",
    "    if overlap > best_overlap:\n",
    "        best_overlap, best_col = overlap, c\n",
    "emp_col_persona = best_col\n",
    "\n",
    "# Attrition column\n",
    "attr_cands = [c for c in persona.columns if c.lower() in (\"attrition\",\"churn\",\"resigned\",\"left_company\")]\n",
    "if not attr_cands:\n",
    "    attr_cands = [c for c in persona.columns if \"attrition\" in c.lower()]\n",
    "assert attr_cands, \"No 'attrition' column found in personas.\"\n",
    "attr_col = attr_cands[0]\n",
    "\n",
    "print(f\"Detected columns: emp_col_ts='{emp_col_ts}', emp_col_persona='{emp_col_persona}', date_col='{date_col}', attr_col='{attr_col}'\")\n",
    "\n",
    "# ---- Monthly panel (2023-01 .. 2024-12) ----\n",
    "ts = ts.copy()\n",
    "ts[date_col] = pd.to_datetime(ts[date_col], errors='coerce', infer_datetime_format=True)\n",
    "ts = ts.dropna(subset=[date_col])\n",
    "ts['month'] = ts[date_col].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "start = pd.Timestamp(\"2023-01-01\"); end = pd.Timestamp(\"2024-12-31\")\n",
    "ts = ts[(ts['month']>=start) & (ts['month']<=end)]\n",
    "\n",
    "# ---- Numeric columns, exclude user-specified ratio columns and keys ----\n",
    "exclude = {emp_col_ts, date_col, 'month'} | EXCLUDED_COLS\n",
    "num_cols = [c for c in ts.columns if c not in exclude and np.issubdtype(ts[c].dtype, np.number)]\n",
    "# Try coercion for numeric-like strings (safety)\n",
    "for c in list(num_cols):\n",
    "    if not np.issubdtype(ts[c].dtype, np.number):\n",
    "        ts[c] = pd.to_numeric(ts[c], errors='coerce')\n",
    "# Drop all-NaN columns\n",
    "num_cols = [c for c in num_cols if ts[c].notna().any()]\n",
    "\n",
    "print(\"Using numeric features (excluded specified ratio columns):\")\n",
    "print(num_cols)\n",
    "\n",
    "# ---- Aggregate to employee-month mean ----\n",
    "agg = ts.groupby([emp_col_ts,'month'])[num_cols].mean().reset_index()\n",
    "\n",
    "# ---- Reindex to full 24 months per employee ----\n",
    "all_months = pd.date_range(start=start, end=end, freq='MS')\n",
    "panels = []\n",
    "for emp, g in agg.groupby(emp_col_ts):\n",
    "    g = g.set_index('month').reindex(all_months)\n",
    "    g[emp_col_ts] = emp\n",
    "    panels.append(g.reset_index().rename(columns={'index':'month'}))\n",
    "panel = pd.concat(panels, ignore_index=True).sort_values([emp_col_ts,'month'])\n",
    "\n",
    "# ---- Fill within employee (ffill/bfill then zeros) ----\n",
    "for c in num_cols:\n",
    "    panel[c] = panel.groupby(emp_col_ts)[c].ffill().bfill()\n",
    "panel[num_cols] = panel[num_cols].fillna(0.0)\n",
    "\n",
    "# ---- Build tensor (N, T=24, F) ----\n",
    "employees = panel[emp_col_ts].drop_duplicates().tolist()\n",
    "T = len(all_months); F = len(num_cols)\n",
    "X_seq = np.zeros((len(employees), T, F), dtype=np.float32)\n",
    "emp_to_idx = {e:i for i,e in enumerate(employees)}\n",
    "for e, g in panel.groupby(emp_col_ts):\n",
    "    i = emp_to_idx[e]\n",
    "    g = g.sort_values('month')\n",
    "    X_seq[i, :, :] = g[num_cols].values.astype(np.float32)\n",
    "\n",
    "# ---- Labels ----\n",
    "labels = persona[[emp_col_persona, attr_col]].copy()\n",
    "labels['attrition_bin'] = labels[attr_col].apply(to_binary_attrition).astype('Int64')\n",
    "labels = labels.dropna(subset=['attrition_bin']).rename(columns={emp_col_persona: emp_col_ts})\n",
    "label_map = labels.set_index(emp_col_ts)['attrition_bin'].to_dict()\n",
    "y = np.array([int(label_map.get(e, np.nan)) for e in employees])\n",
    "mask = ~np.isnan(y)\n",
    "X_seq = X_seq[mask]; y = y[mask].astype(int)\n",
    "employees = [e for e,m in zip(employees, mask) if m]\n",
    "\n",
    "print(\"Final tensor (N, T, F):\", X_seq.shape)\n",
    "print(\"Class balance:\", {int(k):int(v) for k,v in pd.Series(y).value_counts().to_dict().items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66b4c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test sizes: 999 177 294\n"
     ]
    }
   ],
   "source": [
    "# === 3) Employee-level Train/Test split + scaling ===\n",
    "\n",
    "groups = np.array(employees)\n",
    "\n",
    "# Group-aware split (avoid leakage across employees)\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(cv.split(X_seq, y, groups=groups))\n",
    "\n",
    "X_train, y_train = X_seq[train_idx], y[train_idx]\n",
    "X_test,  y_test  = X_seq[test_idx],  y[test_idx]\n",
    "emp_train = [employees[i] for i in train_idx]\n",
    "emp_test  = [employees[i] for i in test_idx]\n",
    "\n",
    "# Validation split from train (stratified)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=RANDOM_STATE)\n",
    "tr_idx, va_idx = next(sss.split(X_train, y_train))\n",
    "X_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n",
    "X_va, y_va = X_train[va_idx], y_train[va_idx]\n",
    "\n",
    "# Standardize features based on train only (flatten time axis)\n",
    "F = X_tr.shape[2]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr.reshape(-1, F))\n",
    "X_tr = scaler.transform(X_tr.reshape(-1, F)).reshape(X_tr.shape)\n",
    "X_va = scaler.transform(X_va.reshape(-1, F)).reshape(X_va.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, F)).reshape(X_test.shape)\n",
    "\n",
    "print(\"Train/Val/Test sizes:\", X_tr.shape[0], X_va.shape[0], X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebf1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4) Dataset & Models (GRU / 1D-CNN) ===\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
    "                          dropout=0.0 if num_layers==1 else dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "    def forward(self, x):  # x: [B, T, F]\n",
    "        out, h = self.gru(x)        # h: [num_layers, B, H]\n",
    "        h_last = h[-1]              # [B, H]\n",
    "        z = self.dropout(h_last)\n",
    "        return self.fc(z).squeeze(1)\n",
    "\n",
    "class CNN1DClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Expect input as [B, F, T]\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "    def forward(self, x):  # x: [B, T, F]\n",
    "        x = x.permute(0, 2, 1)      # -> [B, F, T]\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x).squeeze(-1)  # [B, H]\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aeaf4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=1.1638 | val_f1=0.2261\n",
      "Epoch 02 | train_loss=1.1467 | val_f1=0.2299\n",
      "Epoch 03 | train_loss=1.1418 | val_f1=0.2273\n",
      "Epoch 04 | train_loss=1.1363 | val_f1=0.2326\n",
      "Epoch 05 | train_loss=1.1294 | val_f1=0.2472\n",
      "Epoch 06 | train_loss=1.1346 | val_f1=0.2418\n",
      "Epoch 07 | train_loss=1.1254 | val_f1=0.2222\n",
      "Epoch 08 | train_loss=1.1210 | val_f1=0.2174\n",
      "Epoch 09 | train_loss=1.1137 | val_f1=0.2245\n",
      "Epoch 10 | train_loss=1.1115 | val_f1=0.2022\n",
      "Epoch 11 | train_loss=1.1093 | val_f1=0.2198\n",
      "Epoch 12 | train_loss=1.1026 | val_f1=0.2000\n",
      "Epoch 13 | train_loss=1.1103 | val_f1=0.2222\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "# === 5) Training utilities + Train + Predict ===\n",
    "\n",
    "def get_class_weight_pos(y_np: np.ndarray) -> float:\n",
    "    # Positive class weight = (#neg / #pos)\n",
    "    pos = (y_np == 1).sum()\n",
    "    neg = (y_np == 0).sum()\n",
    "    return float(neg / max(1, pos)) if pos > 0 else 1.0\n",
    "\n",
    "def train_model(model, X_tr, y_tr, X_va, y_va, epochs=40, lr=1e-3, batch_size=64, patience=8):\n",
    "    # Early stopping by validation F1\n",
    "    train_ds = SeqDataset(X_tr, y_tr)\n",
    "    val_ds   = SeqDataset(X_va, y_va)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    pos_weight = get_class_weight_pos(y_tr)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight, device=DEVICE))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_state = None\n",
    "    best_f1 = -1.0\n",
    "    no_improve = 0\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        tr_losses = []\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            logit = model(xb)\n",
    "            loss = criterion(logit, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tr_losses.append(loss.item())\n",
    "\n",
    "        # Validate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            yv_true, yv_prob = [], []\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                logit = model(xb)\n",
    "                prob = torch.sigmoid(logit).cpu().numpy()\n",
    "                yv_prob.append(prob)\n",
    "                yv_true.append(yb.numpy())\n",
    "            yv_true = np.concatenate(yv_true)\n",
    "            yv_prob = np.concatenate(yv_prob)\n",
    "            yv_pred = (yv_prob >= 0.5).astype(int)\n",
    "            f1 = f1_score(yv_true, yv_pred, zero_division=0)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | train_loss={np.mean(tr_losses):.4f} | val_f1={f1:.4f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "def predict_proba(model, X):\n",
    "    ds = SeqDataset(X, np.zeros(len(X)))\n",
    "    loader = DataLoader(ds, batch_size=256, shuffle=False)\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            p = torch.sigmoid(model(xb)).cpu().numpy()\n",
    "            probs.append(p)\n",
    "    return np.concatenate(probs)\n",
    "\n",
    "# ---- Choose and train model ----\n",
    "MODEL_TYPE = \"gru\"   # change to \"cnn\" to use 1D-CNN\n",
    "\n",
    "input_dim = X_tr.shape[2]\n",
    "if MODEL_TYPE.lower() == \"gru\":\n",
    "    model = GRUClassifier(input_dim=input_dim, hidden_dim=64, num_layers=1, dropout=0.1)\n",
    "elif MODEL_TYPE.lower() == \"cnn\":\n",
    "    model = CNN1DClassifier(input_dim=input_dim, hidden_dim=64, dropout=0.1)\n",
    "else:\n",
    "    raise ValueError(\"MODEL_TYPE must be 'gru' or 'cnn'\")\n",
    "\n",
    "model = train_model(model, X_tr, y_tr, X_va, y_va, epochs=40, lr=1e-3, batch_size=64, patience=8)\n",
    "\n",
    "# ---- Predict on test ----\n",
    "proba_test = predict_proba(model, X_test)\n",
    "pred_test = (proba_test >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c803d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.5748, 'Precision': 0.1885, 'Recall': 0.4694, 'F1': 0.269, 'ROC_AUC': 0.5458, 'PR_AUC': 0.1873}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8488    0.5959    0.7002       245\n",
      "           1     0.1885    0.4694    0.2690        49\n",
      "\n",
      "    accuracy                         0.5748       294\n",
      "   macro avg     0.5187    0.5327    0.4846       294\n",
      "weighted avg     0.7388    0.5748    0.6284       294\n",
      "\n",
      "Saved: ./seq_scaler.joblib, ./seq_model_gru.pt, ./seq_predictions_test.csv\n"
     ]
    }
   ],
   "source": [
    "# === 6) Evaluation (and optional save) ===\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, pred_test),\n",
    "    \"Precision\": precision_score(y_test, pred_test, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, pred_test, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, pred_test, zero_division=0),\n",
    "    \"ROC_AUC\": roc_auc_score(y_test, proba_test) if len(np.unique(y_test))>1 else np.nan,\n",
    "    \"PR_AUC\": average_precision_score(y_test, proba_test) if len(np.unique(y_test))>1 else np.nan\n",
    "}\n",
    "print({k: (round(v,4) if isinstance(v, float) and not np.isnan(v) else v) for k,v in metrics.items()})\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, pred_test, labels=[0,1])\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title(f\"Confusion Matrix — Test ({MODEL_TYPE.upper()})\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xticks([0,1], [\"Stay (0)\", \"Leave (1)\"])\n",
    "plt.yticks([0,1], [\"Stay (0)\", \"Leave (1)\"])\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    plt.text(j, i, int(v), ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification report (test):\\n\")\n",
    "print(classification_report(y_test, pred_test, digits=4))\n",
    "\n",
    "# ---- Optional: save artifacts to current directory ----\n",
    "try:\n",
    "    import joblib\n",
    "    joblib.dump({\"scaler\": scaler, \"feature_names\": list(range(X_tr.shape[2]))}, \"./seq_scaler.joblib\")\n",
    "    torch.save(model.state_dict(), f\"./seq_model_{MODEL_TYPE}.pt\")\n",
    "    pd.DataFrame({\n",
    "        \"employee_id\": np.array(emp_test),\n",
    "        \"attrition_true\": y_test,\n",
    "        \"attrition_proba\": proba_test,\n",
    "        \"attrition_pred\": pred_test\n",
    "    }).to_csv(\"./seq_predictions_test.csv\", index=False)\n",
    "    print(\"Saved: ./seq_scaler.joblib, ./seq_model_%s.pt, ./seq_predictions_test.csv\" % MODEL_TYPE)\n",
    "except Exception as e:\n",
    "    print(\"Save skipped due to:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58d2e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train N: 999 Val N: 177 Test N: 294\n",
      "Sequence length T: 24 Feature dim F: 12\n",
      "Class balance (train): {0: 839, 1: 160}\n"
     ]
    }
   ],
   "source": [
    "# === A) Why so fast? Quick diagnostics ===\n",
    "print(\"Train N:\", X_tr.shape[0], \"Val N:\", X_va.shape[0], \"Test N:\", X_test.shape[0])\n",
    "print(\"Sequence length T:\", X_tr.shape[1], \"Feature dim F:\", X_tr.shape[2])\n",
    "print(\"Class balance (train):\", {int(k): int(v) for k, v in pd.Series(y_tr).value_counts().to_dict().items()})\n",
    "\n",
    "# Check how many epochs actually ran (look for 'Early stopping!' in logs)\n",
    "# If you want to force longer training:\n",
    "FORCE_LONGER_TRAINING = False\n",
    "if FORCE_LONGER_TRAINING:\n",
    "    # Re-train with larger epochs/patience just to see it run longer\n",
    "    MODEL_TYPE = \"gru\"  # or \"cnn\"\n",
    "    input_dim = X_tr.shape[2]\n",
    "    model_long = GRUClassifier(input_dim, hidden_dim=128, num_layers=2, dropout=0.3) if MODEL_TYPE==\"gru\" \\\n",
    "                 else CNN1DClassifier(input_dim, hidden_dim=128, dropout=0.3)\n",
    "    model_long = train_model(model_long, X_tr, y_tr, X_va, y_va,\n",
    "                             epochs=200, lr=1e-3, batch_size=32, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb227062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold on val: 0.35 (F1=0.2786)\n",
      "Confusion matrix @th=0.35\n",
      "[[  7 238]\n",
      " [  0  49]]\n",
      "\n",
      "Precision: 0.1707 Recall: 1.0 F1: 0.2917\n",
      "ROC-AUC: 0.5458 PR-AUC: 0.1873\n"
     ]
    }
   ],
   "source": [
    "# === B) Threshold tuning on validation (maximize F1) ===\n",
    "# Need predicted probabilities on validation\n",
    "proba_val = predict_proba(model, X_va)\n",
    "\n",
    "ths = np.linspace(0.05, 0.95, 19)\n",
    "best_f1, best_th = -1.0, 0.5\n",
    "for th in ths:\n",
    "    pred_val = (proba_val >= th).astype(int)\n",
    "    f1 = f1_score(y_va, pred_val, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_th = f1, th\n",
    "\n",
    "print(f\"Best threshold on val: {best_th:.2f} (F1={best_f1:.4f})\")\n",
    "\n",
    "# Apply to test\n",
    "proba_test = predict_proba(model, X_test)  # recompute to be explicit\n",
    "pred_test_opt = (proba_test >= best_th).astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "cm = confusion_matrix(y_test, pred_test_opt, labels=[0,1])\n",
    "print(\"Confusion matrix @th=%.2f\\n%s\" % (best_th, cm))\n",
    "print(\"\\nPrecision:\", round(precision_score(y_test, pred_test_opt, zero_division=0),4),\n",
    "      \"Recall:\", round(recall_score(y_test, pred_test_opt, zero_division=0),4),\n",
    "      \"F1:\", round(f1_score(y_test, pred_test_opt, zero_division=0),4))\n",
    "try:\n",
    "    print(\"ROC-AUC:\", round(roc_auc_score(y_test, proba_test),4),\n",
    "          \"PR-AUC:\", round(average_precision_score(y_test, proba_test),4))\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede5cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | val_f1=0.0571 | pos_weight=2.703\n",
      "Epoch 02 | val_f1=0.0000 | pos_weight=2.703\n",
      "Epoch 03 | val_f1=0.0000 | pos_weight=2.703\n",
      "Epoch 04 | val_f1=0.0000 | pos_weight=2.703\n",
      "Epoch 05 | val_f1=0.0000 | pos_weight=2.703\n",
      "Epoch 06 | val_f1=0.0000 | pos_weight=2.703\n",
      "Epoch 07 | val_f1=0.0000 | pos_weight=2.703\n",
      "Epoch 08 | val_f1=0.1143 | pos_weight=2.703\n",
      "Epoch 09 | val_f1=0.1143 | pos_weight=2.703\n",
      "Epoch 10 | val_f1=0.1081 | pos_weight=2.703\n",
      "Epoch 11 | val_f1=0.1143 | pos_weight=2.703\n",
      "Epoch 12 | val_f1=0.1111 | pos_weight=2.703\n",
      "Epoch 13 | val_f1=0.1500 | pos_weight=2.703\n",
      "Epoch 14 | val_f1=0.1538 | pos_weight=2.703\n",
      "Epoch 15 | val_f1=0.1500 | pos_weight=2.703\n",
      "Epoch 16 | val_f1=0.1500 | pos_weight=2.703\n",
      "Epoch 17 | val_f1=0.1538 | pos_weight=2.703\n",
      "Epoch 18 | val_f1=0.1429 | pos_weight=2.703\n",
      "Epoch 19 | val_f1=0.1333 | pos_weight=2.703\n",
      "Epoch 20 | val_f1=0.1500 | pos_weight=2.703\n",
      "Epoch 21 | val_f1=0.2083 | pos_weight=2.703\n",
      "Epoch 22 | val_f1=0.1818 | pos_weight=2.703\n",
      "Epoch 23 | val_f1=0.1887 | pos_weight=2.703\n",
      "Epoch 24 | val_f1=0.2333 | pos_weight=2.703\n",
      "Epoch 25 | val_f1=0.1818 | pos_weight=2.703\n",
      "Epoch 26 | val_f1=0.2642 | pos_weight=2.703\n",
      "Epoch 27 | val_f1=0.1509 | pos_weight=2.703\n",
      "Epoch 28 | val_f1=0.3143 | pos_weight=2.703\n",
      "Epoch 29 | val_f1=0.3077 | pos_weight=2.703\n",
      "Epoch 30 | val_f1=0.2500 | pos_weight=2.703\n",
      "Epoch 31 | val_f1=0.3103 | pos_weight=2.703\n",
      "Epoch 32 | val_f1=0.2041 | pos_weight=2.703\n",
      "Epoch 33 | val_f1=0.2414 | pos_weight=2.703\n",
      "Epoch 34 | val_f1=0.2571 | pos_weight=2.703\n",
      "Epoch 35 | val_f1=0.2295 | pos_weight=2.703\n",
      "Epoch 36 | val_f1=0.2041 | pos_weight=2.703\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "# === C1) Train with softer positive weight (alpha<1) ===\n",
    "def train_model_weighted(model, X_tr, y_tr, X_va, y_va, epochs=40, lr=1e-3, batch_size=64, patience=8, alpha=0.5):\n",
    "    train_ds = SeqDataset(X_tr, y_tr); val_ds = SeqDataset(X_va, y_va)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    base = (y_tr==0).sum() / max(1,(y_tr==1).sum())\n",
    "    pos_weight = torch.tensor(base**alpha, device=DEVICE)  # soften weight\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_state, best_f1, no_improve = None, -1.0, 0\n",
    "    model = model.to(DEVICE)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad(); loss = criterion(model(xb), yb); loss.backward(); optimizer.step()\n",
    "        # val\n",
    "        model.eval()\n",
    "        yv_true, yv_prob = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yv_prob.append(torch.sigmoid(model(xb)).cpu().numpy())\n",
    "                yv_true.append(yb.numpy())\n",
    "        yv_true = np.concatenate(yv_true); yv_prob = np.concatenate(yv_prob)\n",
    "        f1 = f1_score(yv_true, (yv_prob>=0.5).astype(int), zero_division=0)\n",
    "        print(f\"Epoch {epoch:02d} | val_f1={f1:.4f} | pos_weight={pos_weight.item():.3f}\")\n",
    "        if f1>best_f1: best_f1, best_state, no_improve = f1, {k:v.cpu().clone() for k,v in model.state_dict().items()}, 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience: print(\"Early stopping!\"); break\n",
    "    if best_state is not None: model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "# Re-train quickly with softened weight\n",
    "MODEL_TYPE = \"gru\"\n",
    "input_dim = X_tr.shape[2]\n",
    "model_soft = GRUClassifier(input_dim, hidden_dim=64, num_layers=1, dropout=0.1) if MODEL_TYPE==\"gru\" \\\n",
    "             else CNN1DClassifier(input_dim, hidden_dim=64, dropout=0.1)\n",
    "model_soft = train_model_weighted(model_soft, X_tr, y_tr, X_va, y_va, epochs=40, alpha=0.6)\n",
    "proba_test_soft = predict_proba(model_soft, X_test)\n",
    "# You can also apply the tuned threshold from Cell B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aaa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === C2) (대안) Focal Loss로 재학습 — FP 줄이기 시도 ===\n",
    "class FocalLossBCEWithLogits(nn.Module):\n",
    "    def __init__(self, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
    "    def forward(self, logits, targets):\n",
    "        bce = self.bce(logits, targets)\n",
    "        p = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets==1, p, 1-p).clamp_min(1e-6)\n",
    "        focal = (1 - pt) ** self.gamma * bce\n",
    "        return focal.mean()\n",
    "\n",
    "def train_model_focal(model, X_tr, y_tr, X_va, y_va, epochs=40, lr=1e-3, batch_size=64, patience=8, gamma=2.0):\n",
    "    train_ds = SeqDataset(X_tr, y_tr); val_ds = SeqDataset(X_va, y_va)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    base = (y_tr==0).sum() / max(1,(y_tr==1).sum())\n",
    "    criterion = FocalLossBCEWithLogits(gamma=gamma, pos_weight=torch.tensor(base, device=DEVICE))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_state, best_f1, no_improve = None, -1.0, 0\n",
    "    model = model.to(DEVICE)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            loss = criterion(model(xb), yb)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        # val\n",
    "        model.eval()\n",
    "        yv_true, yv_prob = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yv_prob.append(torch.sigmoid(model(xb)).cpu().numpy())\n",
    "                yv_true.append(yb.numpy())\n",
    "        yv_true = np.concatenate(yv_true); yv_prob = np.concatenate(yv_prob)\n",
    "        f1 = f1_score(yv_true, (yv_prob>=0.5).astype(int), zero_division=0)\n",
    "        print(f\"Epoch {epoch:02d} | val_f1={f1:.4f}\")\n",
    "        if f1>best_f1: best_f1, best_state, no_improve = f1, {k:v.cpu().clone() for k,v in model.state_dict().items()}, 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience: print(\"Early stopping!\"); break\n",
    "    if best_state is not None: model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "# 사용 예\n",
    "# model_focal = GRUClassifier(input_dim=X_tr.shape[2], hidden_dim=64)\n",
    "# model_focal = train_model_focal(model_focal, X_tr, y_tr, X_va, y_va, gamma=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c24a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
